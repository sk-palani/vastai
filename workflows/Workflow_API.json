{
  "25"   : {
    "inputs"     : {
      "text_0" : "The image shows a woman standing in front of a glass wall, wearing a red dress with a square neckline and elbow-length sleeves. Her hair is long and wavy, cascading over her shoulders. She is wearing subtle makeup with defined eyeliner, mascara, and a bold red lipstick. The woman's eyes are open, and she has a neutral expression. The background consists of a reflective glass wall, creating a mirrored effect that doubles the visual elements of the image. The overall setting appears to be modern and urban, with a muted, overcast sky visible through the glass.",
      "text"   : [
        "484",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "26"   : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2581",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "30"   : {
    "inputs"     : {
      "text" : "A closeup professional photoshoot analog photograph of a shy and alluring dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.2), deep rich complexion with a scattering of freckles across cheeks and nose, \n\nfilm, film grain, kdkpt400, kodak, portra400, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "41"   : {
    "inputs"     : {
      "crop"        : "center",
      "clip_vision" : [
        "1517",
        0
      ],
      "image"       : [
        "2109",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "42"   : {
    "inputs"     : {
      "strength"           : 0.48,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "1412",
        0
      ],
      "style_model"        : [
        "43",
        0
      ],
      "clip_vision_output" : [
        "41",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "43"   : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "44"   : {
    "inputs"     : {
      "conditioning_to_strength" : 0.5000000000000001,
      "conditioning_to"          : [
        "1412",
        0
      ],
      "conditioning_from"        : [
        "42",
        0
      ]
    },
    "class_type" : "ConditioningAverage",
    "_meta"      : {
      "title" : "ConditioningAverage"
    }
  },
  "55"   : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2703",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "110"  : {
    "inputs"     : {
      "text_0" : "The outfit in the photo is a deep red, floor-length dress with a square neckline and short sleeves. The material appears to be a smooth, possibly stretchy fabric, likely made of a blend of cotton and polyester for comfort and flexibility. The fit of the dress is tailored, hugging the body in a structured manner, creating a flattering silhouette.",
      "text"   : [
        "485",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "122"  : {
    "inputs"     : {
      "any" : [
        "581",
        1
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "124"  : {
    "inputs"     : {
      "boolean" : [
        "122",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "143"  : {
    "inputs"     : {
      "images" : [
        "1831",
        0
      ]
    },
    "class_type" : "Image to Seed",
    "_meta"      : {
      "title" : "Image to Seed"
    }
  },
  "146"  : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "154"  : {
    "inputs"     : {
      "pixels" : [
        "2303",
        0
      ],
      "vae"    : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEEncode",
    "_meta"      : {
      "title" : "VAE Encode"
    }
  },
  "193"  : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "195"  : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "232"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "##",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "233"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "**",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [**]"
    }
  },
  "235"  : {
    "inputs"     : {
      "boolean_a" : [
        "286",
        0
      ],
      "boolean_b" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic Comparison OR",
    "_meta"      : {
      "title" : "Logic Comparison OR"
    }
  },
  "240"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "saree",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [Saree]"
    }
  },
  "241"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "back",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "242"  : {
    "inputs"     : {
      "text_a"  : [
        "247",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "240",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "243"  : {
    "inputs"     : {
      "text_a"  : [
        "265",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "255",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "244"  : {
    "inputs"     : {
      "value" : "Photo taken from the back of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "245"  : {
    "inputs"     : {
      "string_a"  : [
        "243",
        0
      ],
      "string_b"  : [
        "258",
        0
      ],
      "delimiter" : ""
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "247"  : {
    "inputs"     : {
      "value" : "wearing indian saree with intricate details"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "249"  : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "245",
        0
      ],
      "text_b"           : [
        "242",
        0
      ],
      "text_c"           : [
        "253",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "251"  : {
    "inputs"     : {
      "text" : [
        "254",
        0
      ]
    },
    "class_type" : "ShowText|LP",
    "_meta"      : {
      "title" : "Show Text [LP]"
    }
  },
  "252"  : {
    "inputs"     : {
      "join_with"   : ",",
      "string_list" : [
        "251",
        0
      ]
    },
    "class_type" : "StringListToString",
    "_meta"      : {
      "title" : "String List to String"
    }
  },
  "253"  : {
    "inputs"     : {
      "string"  : [
        "252",
        0
      ],
      "find"    : "_",
      "replace" : ","
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "254"  : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "__(.*)__",
      "mode"             : "All Groups",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "255"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "side",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "258"  : {
    "inputs"     : {
      "text_a"  : [
        "244",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "262"  : {
    "inputs"     : {
      "value" : ""
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "On False"
    }
  },
  "265"  : {
    "inputs"     : {
      "value" : "Photo taken from the side of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "266"  : {
    "inputs"     : {
      "boolean" : true
    },
    "class_type" : "Logic Boolean Primitive",
    "_meta"      : {
      "title" : "Red Lipstick?"
    }
  },
  "268"  : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "2110",
        0
      ],
      "b"          : [
        "1921",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "271"  : {
    "inputs"     : {
      "string"  : "the subject is portrayed at __{{ age }}__ years of age,  ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "272"  : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "\\((.*)\\)",
      "mode"             : "First Group",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "275"  : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "2544",
        0
      ],
      "b"          : [
        "1920",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "277"  : {
    "inputs"     : {
      "value" : 15
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "L"
    }
  },
  "278"  : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "283"  : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "284",
        0
      ],
      "text_b"           : [
        "272",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "284"  : {
    "inputs"     : {
      "value" : "0"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "285"  : {
    "inputs"     : {
      "value" : "+"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "286"  : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "288"  : {
    "inputs"     : {
      "text" : [
        "289",
        0
      ]
    },
    "class_type" : "ShowTextBridge|LP",
    "_meta"      : {
      "title" : "Show Text Bridge [LP]"
    }
  },
  "289"  : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\++)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "290"  : {
    "inputs"     : {
      "string" : [
        "296",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "293"  : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "500",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "294"  : {
    "inputs"     : {
      "string" : [
        "293",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "295"  : {
    "inputs"     : {
      "int" : 5
    },
    "class_type" : "Int Literal",
    "_meta"      : {
      "title" : "Int Literal"
    }
  },
  "296"  : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "289",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "322"  : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "sketch",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [sketch]"
    }
  },
  "325"  : {
    "inputs"     : {
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "Logic NOT"
    }
  },
  "331"  : {
    "inputs"     : {
      "select"   : 1,
      "sel_mode" : false,
      "input1"   : [
        "278",
        0
      ],
      "input2"   : [
        "334",
        0
      ],
      "input3"   : [
        "335",
        0
      ],
      "input4"   : [
        "277",
        0
      ]
    },
    "class_type" : "ImpactSwitch",
    "_meta"      : {
      "title" : "Switch (Any)"
    }
  },
  "334"  : {
    "inputs"     : {
      "value" : 4
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "S"
    }
  },
  "335"  : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "M"
    }
  },
  "339"  : {
    "inputs"     : {
      "noise_scale"   : [
        "622",
        0
      ],
      "blend_opacity" : 11,
      "image"         : [
        "363",
        0
      ],
      "mask"          : [
        "2193",
        0
      ]
    },
    "class_type" : "NoisePlusBlend",
    "_meta"      : {
      "title" : "Noise Plus Blend"
    }
  },
  "342"  : {
    "inputs"     : {
      "value1" : 0.72,
      "value2" : 0.54
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "Detailer Denoise (0.56 :: 0.80)"
    }
  },
  "343"  : {
    "inputs"     : {
      "value1" : 0.52,
      "value2" : 0.37
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "Input+DetailerDenoise[0.62,0.56]"
    }
  },
  "356"  : {
    "inputs"     : {
      "image" : [
        "1848",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "362"  : {
    "inputs"     : {
      "value" : 23
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Age"
    }
  },
  "363"  : {
    "inputs"     : {
      "center_x"            : 0.3,
      "center_y"            : 0.5,
      "saturation"          : 0.9,
      "vignette_intensity"  : 0.010000000000000002,
      "grain_method"        : "filmgrainer",
      "grain_power"         : 0.08,
      "grain_scale"         : 0.2,
      "grain_sat"           : 0.3,
      "filmgrainer_shadows" : 0.15000000000000002,
      "filmgrainer_highs"   : 0.10000000000000002,
      "blur_strength"       : 1,
      "blur_focus_spread"   : 0.30000000000000004,
      "focal_depth"         : 0.10000000000000002,
      "image"               : [
        "482",
        0
      ],
      "depth_map"           : [
        "2727",
        0
      ]
    },
    "class_type" : "LayerFilter: FilmV2",
    "_meta"      : {
      "title" : "LayerFilter: Film V2"
    }
  },
  "389"  : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "394"  : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSize+",
    "_meta"      : {
      "title" : "üîß Get Image Size"
    }
  },
  "405"  : {
    "inputs"     : {
      "text" : "\n(dark pimple marks in the left cheek:0.8), tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3), and her hair is long, curly. She has minimal makeup, with a focus on sharp black eyeliner and nude matte warm brown lipstick on her sexy pouty lips.\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, cleavage.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "440"  : {
    "inputs"     : {
      "cyan_red"      : 0.01,
      "magenta_green" : 0,
      "yellow_blue"   : 0.02,
      "image"         : [
        "356",
        0
      ]
    },
    "class_type" : "LayerColor: ColorBalance",
    "_meta"      : {
      "title" : "LayerColor: ColorBalance"
    }
  },
  "441"  : {
    "inputs"     : {
      "expand"                 : 1,
      "incremental_expandrate" : 0,
      "tapered_corners"        : false,
      "flip_input"             : false,
      "blur_radius"            : 0,
      "lerp_alpha"             : 0,
      "decay_factor"           : 0,
      "fill_holes"             : false,
      "mask"                   : [
        "545",
        0
      ]
    },
    "class_type" : "GrowMaskWithBlur",
    "_meta"      : {
      "title" : "Grow Mask With Blur"
    }
  },
  "445"  : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "454"  : {
    "inputs"     : {
      "image" : [
        "440",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "455"  : {
    "inputs"     : {
      "x"           : 0,
      "y"           : 0,
      "operation"   : "or",
      "destination" : [
        "457",
        0
      ],
      "source"      : [
        "456",
        0
      ]
    },
    "class_type" : "MaskComposite",
    "_meta"      : {
      "title" : "MaskComposite"
    }
  },
  "456"  : {
    "inputs"     : {
      "shape"        : "square",
      "frames"       : 1,
      "location_x"   : 0,
      "location_y"   : 0,
      "grow"         : 1,
      "frame_width"  : [
        "445",
        1
      ],
      "frame_height" : [
        "445",
        2
      ],
      "shape_width"  : 16,
      "shape_height" : [
        "445",
        2
      ]
    },
    "class_type" : "CreateShapeMask",
    "_meta"      : {
      "title" : "Create Shape Mask"
    }
  },
  "457"  : {
    "inputs"     : {
      "red"       : 255,
      "green"     : 0,
      "blue"      : 207,
      "threshold" : 10,
      "image"     : [
        "454",
        0
      ]
    },
    "class_type" : "MaskFromColor+",
    "_meta"      : {
      "title" : "üîß Mask From Color"
    }
  },
  "459"  : {
    "inputs"     : {
      "mask" : [
        "455",
        0
      ]
    },
    "class_type" : "MaskToImage",
    "_meta"      : {
      "title" : "Convert Mask to Image"
    }
  },
  "461"  : {
    "inputs"     : {
      "op" : "IsZero",
      "a"  : 1
    },
    "class_type" : "CM_IntUnaryCondition",
    "_meta"      : {
      "title" : "IntUnaryCondition"
    }
  },
  "478"  : {
    "inputs"     : {
      "image" : [
        "2703",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "482"  : {
    "inputs"     : {
      "noise_radius"   : 1,
      "preserve_edges" : 1,
      "sharpen"        : 0.5,
      "ratio"          : 0.5,
      "image"          : [
        "478",
        0
      ]
    },
    "class_type" : "ImageSmartSharpen+",
    "_meta"      : {
      "title" : "üîß Image Smart Sharpen"
    }
  },
  "484"  : {
    "inputs"     : {
      "question"          : "Describe this photo in essential details concisely with detais about the background, camera angle of the shot, intrinsic details about hair style, jewelry and outfit. Also, describe about facial expression including the make-up, eyes and lipstick, avoid mentioning blurred and try to find details in the background. ",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 1024,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "485"  : {
    "inputs"     : {
      "question"          : "Describe the outfit in the photo in essential details with detais about the color, material, texture of the materials, fit etc.",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 768,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "494"  : {
    "inputs"     : {
      "text" : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry,\n\n\nnude, dark texture areola and erect nipples,  (nsfw:0.7),  \n\n\nsee-through blouse and saree, deep-cleavage, jewelry, (Hip-Chain:1.2), \n\ncolorful silk saree with expensive hand-made embroidery designs, backless blouse,\n\nsexy heart-shaped clothing cutout in the back revealing buttcrack,\n\nsee-through saree, Floral prints embroidery,    Belly Piercing,\n\nwearing Glasses\n\nSitting on the knees, in front of mirror,  Happy facial expression,colorful lace top with expensive hand-made embroidery designs backless blouse,  \n\nSexy Hip-Chain,Sexy Waist-Chain, Sexy crop-top made of jasmine flowers,\n\nA tattoo of a baby elephant is visible on the left chest area. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "495"  : {
    "inputs"     : {
      "text" : " hip chain, waist chain, hands behind the back, crop top overhang,\n\nand light freckles scattered across her cheeks and nose. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "496"  : {
    "inputs"     : {
      "text" : "aidmafluxproultra, aidmaimageupgrader"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "500"  : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\-\\-)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "511"  : {
    "inputs"     : {
      "text_0" : "The subject is having a pouting facial expression",
      "text"   : [
        "2555",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "513"  : {
    "inputs"     : {
      "text"   : "loving \npouting\nshy\nhappy\nvery happy\nsilly\naroused\nflirting\nseductive\nprovocative\nsurprised\nopen mouth",
      "amount" : 1,
      "seed"   : [
        "2240",
        0
      ]
    },
    "class_type" : "TextRandomMultiline",
    "_meta"      : {
      "title" : "Text Random Multiline"
    }
  },
  "514"  : {
    "inputs"     : {
      "text_0" : "the subject is portrayed at 23 years of age,  ",
      "text"   : [
        "271",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "515"  : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "1945",
        0
      ],
      "text_b"           : [
        "2555",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "516"  : {
    "inputs"     : {
      "text_0" : ", She is wearing outfit through which the subtle outline of her bra is visible. Around her waist is a delicate waist chain, and a platinum diamond belly piercing accentuates her abdomen. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Medium breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a pouting facial expression",
      "text"   : [
        "515",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "542"  : {
    "inputs"     : {
      "images" : [
        "1888",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "545"  : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.5,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "356",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "559"  : {
    "inputs"     : {
      "text" : "aidmafluxproultra, aidmaimageupgrader, sinfully stylish, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "560"  : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, moles, natural blemishes, Rough skin texture, Skin imperfections ,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "564"  : {
    "inputs"     : {
      "model_name" : "deepseek-ai/Janus-Pro-1B"
    },
    "class_type" : "JanusProModelLoader|Mie",
    "_meta"      : {
      "title" : "Janus Pro Model Loader üêë"
    }
  },
  "567"  : {
    "inputs"     : {
      "text" : "a professional digital Storybook Illustration art style of a shy and cute dark-skinned Indian v1dhya5 woman with  a extremely beautiful  face with (black bindi on the forehead:1.2), "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "568"  : {
    "inputs"     : {
      "text" : "A professionally color-graded RAW photograph of a shy sexy and alluring dark brown almond  skin tone young Indian v1dhya5 woman with extremely beautiful face  with black bindi on the forehead, , photo taken using using a  high-end professional camera , posing glamorously like she is with her lover who is taking the photo,  \n\nThe makeup is minimal but bold and glamorous, featuring black bindi on the forehead and a dramatic eye makeup with dark eyeliner / kohl and mascara, along with defined eyebrows. Her sexy pouty lips are painted a vivid red   . Her lips are narrow, plump, and wet-looking, subtly curved for a sensual appearance., adding a touch of elegance and intensity to their appearance. The skin has a healthy glow, accentuated by subtle matte makeup techniques. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "570"  : {
    "inputs"     : {
      "text_0" : "Inputs/Next/IMG_20251126_084248_199.jpg",
      "text"   : [
        "1806",
        3
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "571"  : {
    "inputs"     : {
      "text1"     : "A dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.4), deep rich complexion with a scattering of freckles across cheeks and nose,",
      "text2"     : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry",
      "text3"     : "looking at the cameras,\ntranslucent   outfit with see though sleeves, showing the profile of the dark blue bra wearing with dark blue strap peeking outside.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "573"  : {
    "inputs"     : {
      "text_0" : "A professionally color-graded photograph of Indian v1dhya5 woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 23 years of age,,The photo shows a woman standing in front of a glass wall, wearing a red dress with a square neckline and elbow-length sleeves. Her hair is long and wavy, cascading over her shoulders. She is wearing subtle makeup with defined eyeliner, mascara, and a bold red lipstick. The woman's eyes are open, and she has a neutral expression. The background consists of a reflective glass wall, creating a mirrored effect that doubles the visual elements of the photo. The overall setting appears to be modern and urban, with a muted, overcast sky visible through the glass.,Photograph of , She is wearing outfit through which the subtle outline of her bra is visible. Around her waist is a delicate waist chain, and a platinum diamond belly piercing accentuates her abdomen. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Medium breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a pouting facial expression. incorporating visible light sources within the scene. shot on Fujifilm X-T5. with highly saturated vivid colors",
      "text"   : [
        "788",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "581"  : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2609",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "832",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "588"  : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2655",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "589"  : {
    "inputs"     : {
      "conditioning" : [
        "588",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "599"  : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2655",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "609"  : {
    "inputs"     : {
      "clip_l"   : [
        "669",
        0
      ],
      "t5xxl"    : [
        "788",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2655",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "622"  : {
    "inputs"     : {
      "float_value"    : [
        "2100",
        0
      ],
      "multiply_value" : 0.181818
    },
    "class_type" : "FloatMultiplication",
    "_meta"      : {
      "title" : "Float Multiplication"
    }
  },
  "623"  : {
    "inputs"     : {
      "value1" : 0.94,
      "value2" : 0.8
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "Input+DetailerDenoise[0.62,0.56]"
    }
  },
  "650"  : {
    "inputs"     : {
      "text" : [
        "249",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "660"  : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2713",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "669"  : {
    "inputs"     : {
      "text1"     : "Detailed female hands, Diamond ring in one finger. No Nailpolish,",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "731"  : {
    "inputs"     : {
      "preprocessor" : "DWPreprocessor",
      "resolution"   : [
        "764",
        0
      ],
      "image"        : [
        "744",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "734"  : {
    "inputs"     : {
      "type"        : "openpose",
      "control_net" : [
        "2231",
        0
      ]
    },
    "class_type" : "SetUnionControlNetType",
    "_meta"      : {
      "title" : "SetUnionControlNetType"
    }
  },
  "735"  : {
    "inputs"     : {
      "conditioning" : [
        "736",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "736"  : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "CLIP Text Encode (Prompt)"
    }
  },
  "737"  : {
    "inputs"     : {
      "clip_l"   : [
        "2187",
        0
      ],
      "t5xxl"    : [
        "743",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "743"  : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "aidmarealisticskin, Skin imperfections, fluxenhancer",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "744"  : {
    "inputs"     : {
      "image" : [
        "2109",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "764"  : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "744",
        1
      ],
      "b"    : [
        "744",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "768"  : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.mp3",
      "any"    : [
        "122",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "788"  : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2105",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "826"  : {
    "inputs"     : {
      "mask" : [
        "829",
        1
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "828"  : {
    "inputs"     : {
      "width"  : 168,
      "height" : 38,
      "red"    : 0,
      "green"  : 0,
      "blue"   : 0
    },
    "class_type" : "Image Blank",
    "_meta"      : {
      "title" : "Image Blank"
    }
  },
  "829"  : {
    "inputs"     : {
      "text"             : [
        "1936",
        0
      ],
      "font"             : "SevenSegment.ttf",
      "size"             : 38,
      "color"            : "#b66244FF",
      "background_color" : "#00000000",
      "shadow_distance"  : 0,
      "shadow_blur"      : 0,
      "shadow_color"     : "#ADADAD",
      "horizontal_align" : "right",
      "vertical_align"   : "bottom",
      "offset_x"         : -4,
      "offset_y"         : -2,
      "direction"        : "ltr",
      "img_composite"    : [
        "828",
        0
      ]
    },
    "class_type" : "DrawText+",
    "_meta"      : {
      "title" : "üîß Draw Text"
    }
  },
  "832"  : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "bilinear",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : [
        "1937",
        0
      ],
      "y_offset"       : [
        "1938",
        0
      ],
      "rotation"       : -90,
      "opacity"        : 0,
      "base_image"     : [
        "1585",
        0
      ],
      "overlay_image"  : [
        "829",
        0
      ],
      "optional_mask"  : [
        "826",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "840"  : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1918",
        0
      ],
      "b"          : [
        "1595",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "897"  : {
    "inputs"     : {
      "text1"     : "detailed fabric texture",
      "text2"     : [
        "485",
        0
      ],
      "text3"     : "slightly translucent elements in the intricate outfit with see though sleeves, showing the profile of the 36DD Cup size  bra wearing underneath.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "931"  : {
    "inputs"     : {
      "any_01" : [
        "2403",
        0
      ],
      "any_03" : [
        "2362",
        0
      ],
      "any_04" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "950"  : {
    "inputs"     : {
      "text" : "professionally color-graded RAW photograph, __AGE__ Indian v1dhya5 busty woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "953"  : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2595",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1271" : {
    "inputs"     : {
      "upscale_method" : "lanczos",
      "megapixels"     : 1.5000000000000002,
      "image"          : [
        "2303",
        0
      ]
    },
    "class_type" : "ImageScaleToTotalPixels",
    "_meta"      : {
      "title" : "ImageScaleToTotalPixels"
    }
  },
  "1281" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "245",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1282" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "242",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1283" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "249",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1284" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "253",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1285" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "296",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1286" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "293",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1287" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "235",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1288" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2100",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1289" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2102",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1294" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "622",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1295" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2103",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1306" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "1595",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1318" : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "897",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1331" : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1343" : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (vertical, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1344" : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (horizontal, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1345" : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "$$",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "1354" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "124",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1357" : {
    "inputs"     : {
      "lut_name" : "Presetpro  - Kodacrome 64.cube",
      "strength" : 0.27,
      "log"      : true,
      "image"    : [
        "931",
        0
      ]
    },
    "class_type" : "ProPostApplyLUT",
    "_meta"      : {
      "title" : "ProPostApplyLUT"
    }
  },
  "1366" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_dydvk_00001_.png&type=temp&subfolder=&rand=0.6167302449244433"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_dydvk_00002_.png&type=temp&subfolder=&rand=0.09225655521641907"
          }
        ]
      },
      "image_a"          : [
        "1400",
        0
      ],
      "image_b"          : [
        "2675",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1386" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ppizi_00001_.png&type=temp&subfolder=&rand=0.3422397216225489"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ppizi_00002_.png&type=temp&subfolder=&rand=0.40816010930242785"
          }
        ]
      },
      "image_a"          : [
        "2165",
        0
      ],
      "image_b"          : [
        "1831",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1390" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_gjyhy_00001_.png&type=temp&subfolder=&rand=0.2502751219646535"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_gjyhy_00002_.png&type=temp&subfolder=&rand=0.6006419618954358"
          }
        ]
      },
      "image_a"          : [
        "2675",
        0
      ],
      "image_b"          : [
        "1831",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1400" : {
    "inputs"     : {
      "brightness" : 0.93,
      "contrast"   : 1.16,
      "saturation" : 1,
      "image"      : [
        "2675",
        0
      ]
    },
    "class_type" : "LayerColor: BrightnessContrastV2",
    "_meta"      : {
      "title" : "Brightness Contrast V2"
    }
  },
  "1405" : {
    "inputs"     : {
      "value" : 1.21212
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "<<Speed - Accuracy>> (default 0.9)"
    }
  },
  "1412" : {
    "inputs"     : {
      "strength"      : 0.6,
      "start_percent" : 0,
      "end_percent"   : 0.6,
      "positive"      : [
        "737",
        0
      ],
      "negative"      : [
        "735",
        0
      ],
      "control_net"   : [
        "734",
        0
      ],
      "image"         : [
        "731",
        0
      ],
      "vae"           : [
        "2889",
        0
      ]
    },
    "class_type" : "ControlNetApplyAdvanced",
    "_meta"      : {
      "title" : "Apply ControlNet"
    }
  },
  "1479" : {
    "inputs"     : {
      "text" : " , Skin imperfections ,    natural blemishes, Rough skin texture, d351 d4rk, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "1495" : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1496" : {
    "inputs"     : {
      "images" : [
        "2362",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1497" : {
    "inputs"     : {
      "images" : [
        "2158",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1498" : {
    "inputs"     : {
      "images" : [
        "2117",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1517" : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "1566" : {
    "inputs"     : {
      "any_01" : [
        "2328",
        0
      ],
      "any_02" : [
        "2165",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1585" : {
    "inputs"     : {
      "radius"          : 0.7,
      "amount"          : 1.2,
      "reduce_noise"    : 0.15,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0.2,
      "image"           : [
        "1357",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "Nettet√© optimis√©e"
    }
  },
  "1595" : {
    "inputs"     : {
      "expression" : "c*(a-b)",
      "a"          : [
        "290",
        0
      ],
      "b"          : [
        "294",
        0
      ],
      "c"          : [
        "295",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1611" : {
    "inputs"     : {
      "any_02" : [
        "2362",
        0
      ],
      "any_03" : [
        "2085",
        0
      ],
      "any_05" : [
        "2704",
        0
      ],
      "any_06" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1615" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_cxvxc_00001_.png&type=temp&subfolder=&rand=0.03318459017878128"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_cxvxc_00002_.png&type=temp&subfolder=&rand=0.013682001004128641"
          }
        ]
      },
      "image_a"          : [
        "2669",
        0
      ],
      "image_b"          : [
        "1837",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1616" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yxpdl_00001_.png&type=temp&subfolder=&rand=0.5520216030135556"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yxpdl_00002_.png&type=temp&subfolder=&rand=0.18225903146127298"
          }
        ]
      },
      "image_a"          : [
        "1831",
        0
      ],
      "image_b"          : [
        "356",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1617" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_aqyva_00001_.png&type=temp&subfolder=&rand=0.7023575616644507"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_aqyva_00002_.png&type=temp&subfolder=&rand=0.09396197715433618"
          }
        ]
      },
      "image_a"          : [
        "2713",
        0
      ],
      "image_b"          : [
        "1611",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1619" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_onkpn_00001_.png&type=temp&subfolder=&rand=0.4359698077660561"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_onkpn_00002_.png&type=temp&subfolder=&rand=0.0906330341473428"
          }
        ]
      },
      "image_a"          : [
        "832",
        0
      ],
      "image_b"          : [
        "2109",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1629" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yqghz_00001_.png&type=temp&subfolder=&rand=0.7345863516660965"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yqghz_00002_.png&type=temp&subfolder=&rand=0.415421304818957"
          }
        ]
      },
      "image_a"          : [
        "2704",
        0
      ],
      "image_b"          : [
        "1888",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1636" : {
    "inputs"     : {
      "image" : [
        "931",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1637" : {
    "inputs"     : {
      "value" : 0.56
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Color_Correct"
    }
  },
  "1710" : {
    "inputs"     : {
      "value" : 1.58
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1740" : {
    "inputs"     : {
      "value" : 1.47
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1803" : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -728427055991069
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1805" : {
    "inputs"     : {
      "directory_path"    : "Inputs/Next",
      "patterns"          : "*.jpg|*.png|*.jpeg",
      "rescan_each_queue" : true
    },
    "class_type" : "FileCounter|LP",
    "_meta"      : {
      "title" : "File Counter [LP]"
    }
  },
  "1806" : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -825064779812975
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1807" : {
    "inputs"     : {
      "any" : [
        "1803",
        0
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "1812" : {
    "inputs"     : {
      "boolean" : [
        "1807",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "1813" : {
    "inputs"     : {
      "OutputDirectory" : "Inputs/Processed",
      "OverwriteFile"   : [
        "124",
        0
      ],
      "FilePaths"       : [
        "1838",
        0
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1814" : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1805",
        0
      ],
      "b"          : [
        "1924",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1815" : {
    "inputs"     : {
      "text_0" : "Inputs/Next",
      "text"   : [
        "1806",
        2
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1817" : {
    "inputs"     : {
      "text_0" : "Inputs/Next/",
      "text"   : [
        "1818",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1818" : {
    "inputs"     : {
      "string_a"  : "Inputs/Next",
      "string_b"  : [
        "1806",
        4
      ],
      "delimiter" : "/"
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "1819" : {
    "inputs"     : {
      "condition"  : [
        "1814",
        0
      ],
      "when_true"  : [
        "1818",
        0
      ],
      "when_false" : [
        "1806",
        2
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1820" : {
    "inputs"     : {
      "OutputDirectory" : [
        "1819",
        0
      ],
      "OverwriteFile"   : true,
      "FilePaths"       : [
        "1806",
        3
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1823" : {
    "inputs"     : {
      "text_0" : "Inputs/Next/IMG_20251126_083104_482.jpg",
      "text"   : [
        "1803",
        3
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1831" : {
    "inputs"     : {
      "condition"  : [
        "193",
        0
      ],
      "when_true"  : [
        "1343",
        0
      ],
      "when_false" : [
        "1344",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1832" : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "sequential_by_modified_date",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : 1122254537135867
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1835" : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1941",
        0
      ],
      "b"          : [
        "1925",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1837" : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        0
      ],
      "when_false" : [
        "1832",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1838" : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        3
      ],
      "when_false" : [
        "1832",
        3
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1848" : {
    "inputs"     : {
      "megapixel"     : "2.0",
      "divisible_by"  : "8",
      "mode"          : "pad",
      "delta_percent" : [
        "2532",
        0
      ],
      "image"         : [
        "1913",
        0
      ]
    },
    "class_type" : "Image_Preparations",
    "_meta"      : {
      "title" : "Image Preparations"
    }
  },
  "1855" : {
    "inputs"     : {
      "expression" : "b+(a-0.46)*(24-b)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1856" : {
    "inputs"     : {
      "expression" : "c+(a-0.46)*(35-c)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1857" : {
    "inputs"     : {},
    "class_type" : "DisableNoise",
    "_meta"      : {
      "title" : "DisableNoise"
    }
  },
  "1858" : {
    "inputs"     : {
      "noise_seed" : [
        "2240",
        0
      ]
    },
    "class_type" : "RandomNoise",
    "_meta"      : {
      "title" : "RandomNoise"
    }
  },
  "1859" : {
    "inputs"     : {
      "model"        : [
        "1899",
        0
      ],
      "conditioning" : [
        "2108",
        0
      ]
    },
    "class_type" : "BasicGuider",
    "_meta"      : {
      "title" : "BasicGuider"
    }
  },
  "1860" : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : [
        "1893",
        0
      ],
      "denoise"   : [
        "2541",
        0
      ],
      "model"     : [
        "1899",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "1863" : {
    "inputs"     : {
      "noise"        : [
        "1858",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2892",
        0
      ],
      "sigmas"       : [
        "1877",
        0
      ],
      "latent_image" : [
        "1989",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler1"
    }
  },
  "1869" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2541",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "1870" : {
    "inputs"     : {
      "noise"        : [
        "1857",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2666",
        0
      ],
      "sigmas"       : [
        "1877",
        1
      ],
      "latent_image" : [
        "1871",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler2"
    }
  },
  "1871" : {
    "inputs"     : {
      "noise_seed"     : [
        "2212",
        0
      ],
      "noise_strength" : 1.3,
      "normalize"      : "false",
      "latent"         : [
        "1863",
        0
      ]
    },
    "class_type" : "InjectLatentNoise+",
    "_meta"      : {
      "title" : "üîß Inject Latent Noise"
    }
  },
  "1877" : {
    "inputs"     : {
      "denoise" : [
        "1944",
        0
      ],
      "sigmas"  : [
        "1860",
        0
      ]
    },
    "class_type" : "SplitSigmasDenoise",
    "_meta"      : {
      "title" : "SplitSigmasDenoise"
    }
  },
  "1885" : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1934",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "1888",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "1888" : {
    "inputs"     : {
      "samples" : [
        "1870",
        1
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "1889" : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.wav",
      "any"    : [
        "1888",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "1892" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zuklh_00001_.png&type=temp&subfolder=&rand=0.8306097832331905"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zuklh_00002_.png&type=temp&subfolder=&rand=0.12445685686261077"
          }
        ]
      },
      "image_a"          : [
        "1888",
        0
      ],
      "image_b"          : [
        "2669",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1893" : {
    "inputs"     : {
      "expression" : "1.26*(a+c*(b-a))",
      "a"          : [
        "1855",
        0
      ],
      "b"          : [
        "1856",
        0
      ],
      "c"          : [
        "1405",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1899" : {
    "inputs"     : {
      "max_shift"  : 1.8,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.45"
    }
  },
  "1902" : {
    "inputs"     : {
      "value1" : 29,
      "value2" : 43
    },
    "class_type" : "SeargeIntegerPair",
    "_meta"      : {
      "title" : "Range (31:43)"
    }
  },
  "1909" : {
    "inputs"     : {
      "dishonesty_factor" : -0.04,
      "start_percent"     : 0.25,
      "end_percent"       : 0.5,
      "sampler"           : [
        "2892",
        0
      ]
    },
    "class_type" : "LyingSigmaSampler",
    "_meta"      : {
      "title" : "Lying Sigma Sampler"
    }
  },
  "1913" : {
    "inputs"     : {
      "image" : [
        "1837",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1918" : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1919" : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1920" : {
    "inputs"     : {
      "value" : 1
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1921" : {
    "inputs"     : {
      "value" : 20
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1922" : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "1923",
        0
      ],
      "b"    : [
        "2544",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1923" : {
    "inputs"     : {
      "value" : 15
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "15"
    }
  },
  "1924" : {
    "inputs"     : {
      "value" : -268
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "One"
    }
  },
  "1925" : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1926" : {
    "inputs"     : {
      "value" : 1024
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1927" : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "389",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1928" : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "146",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1930" : {
    "inputs"     : {
      "file_prefix"   : [
        "1932",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1931" : {
    "inputs"     : {
      "int_" : [
        "143",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "1932" : {
    "inputs"     : {
      "text1" : "Detailed_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1933" : {
    "inputs"     : {
      "text1" : "AfterPass02_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1934" : {
    "inputs"     : {
      "file_prefix"   : [
        "1933",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1936" : {
    "inputs"     : {
      "file_prefix"   : "",
      "time_format"   : "%-d %-m %y",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1937" : {
    "inputs"     : {
      "a"         : [
        "1636",
        1
      ],
      "b"         : -38,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1938" : {
    "inputs"     : {
      "a"         : [
        "1636",
        2
      ],
      "b"         : -168,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1941" : {
    "inputs"     : {
      "min" : 1,
      "max" : 10
    },
    "class_type" : "RandomInt",
    "_meta"      : {
      "title" : "Random Int"
    }
  },
  "1942" : {
    "inputs"     : {
      "mode" : false,
      "a"    : [
        "478",
        1
      ],
      "b"    : [
        "478",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1944" : {
    "inputs"     : {
      "float_1" : 0.58,
      "float_2" : 0.9992
    },
    "class_type" : "TwoFloats",
    "_meta"      : {
      "title" : "<<Rough - Smooth>> (default 0.58)"
    }
  },
  "1945" : {
    "inputs"     : {
      "text" : ", She is wearing outfit through which the subtle outline of her bra is visible. Around her waist is a delicate waist chain, and a platinum diamond belly piercing accentuates her abdomen. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Medium breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "1948" : {
    "inputs"     : {
      "images" : [
        "731",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1955" : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.98,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "1978" : {
    "inputs"     : {
      "max_shift"  : 1.5,
      "base_shift" : 0.5,
      "width"      : [
        "445",
        1
      ],
      "height"     : [
        "445",
        2
      ],
      "model"      : [
        "2881",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "1988" : {
    "inputs"     : {
      "clip_l"   : "captivating professional photo of v1dhya5 woman in a serene outdoor setting, the overall mood of the photograph is calm and introspective, capturing a moment of introspection or contemplation, ",
      "t5xxl"    : [
        "788",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2881",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "1989" : {
    "inputs"     : {
      "sampler_name" : "euler",
      "scheduler"    : "beta",
      "steps"        : 24,
      "denoise"      : [
        "1999",
        0
      ],
      "noise_seed"   : [
        "2240",
        0
      ],
      "model"        : [
        "1978",
        0
      ],
      "conditioning" : [
        "1988",
        0
      ],
      "latent_image" : [
        "154",
        0
      ]
    },
    "class_type" : "FluxSampler",
    "_meta"      : {
      "title" : "Flux Sampler : Pass 01"
    }
  },
  "1993" : {
    "inputs"     : {
      "tile_size" : 0,
      "image"     : "none",
      "latent"    : [
        "1989",
        0
      ],
      "vae"       : [
        "2889",
        0
      ]
    },
    "class_type" : "ImagePreviewFromLatent+",
    "_meta"      : {
      "title" : "üîß Image Preview From Latent"
    }
  },
  "1999" : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.49,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2022" : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "Natural breast shape, Perfect hand and fingers and nails with pastel nail polish,wearing thin golden necklace,",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2025" : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2040",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2032" : {
    "inputs"     : {
      "max_shift"  : 1.6,
      "base_shift" : 0.4,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2866",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2034" : {
    "inputs"     : {
      "any_01" : [
        "2085",
        0
      ],
      "any_03" : [
        "2704",
        0
      ],
      "any_04" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2035" : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : false,
      "hair_mask"       : true,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2034",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2036" : {
    "inputs"     : {
      "combined"     : false,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2037",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2037" : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2035",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2038" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ikbsg_00001_.png&type=temp&subfolder=&rand=0.7007851909547227"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ikbsg_00002_.png&type=temp&subfolder=&rand=0.23960276674292924"
          }
        ]
      },
      "image_a"          : [
        "2040",
        0
      ],
      "image_b"          : [
        "2034",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2040" : {
    "inputs"     : {
      "guide_size"         : 768,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 18,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.29,
      "feather"            : 2,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2034",
        0
      ],
      "segs"               : [
        "2036",
        0
      ],
      "model"              : [
        "2032",
        0
      ],
      "clip"               : [
        "2867",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2043",
        0
      ],
      "negative"           : [
        "2045",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Body Detailer)"
    }
  },
  "2043" : {
    "inputs"     : {
      "clip_l"   : [
        "2759",
        0
      ],
      "t5xxl"    : [
        "2022",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2867",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2045" : {
    "inputs"     : {
      "conditioning" : [
        "2046",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2046" : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2867",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2047" : {
    "inputs"     : {
      "conditioning" : [
        "2048",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2048" : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2053" : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "560",
        0
      ],
      "text2"     : [
        "2054",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2054" : {
    "inputs"     : {
      "string_a"  : [
        "1318",
        0
      ],
      "string_b"  : "Natural wrinkles on the clothes fabric, Intricately designed highly detailed jewelery.",
      "delimiter" : ","
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "2058" : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "2060" : {
    "inputs"     : {
      "strength"           : 0.5,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "2067",
        0
      ],
      "style_model"        : [
        "2058",
        0
      ],
      "clip_vision_output" : [
        "2063",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "2062" : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "2063" : {
    "inputs"     : {
      "crop"        : "none",
      "clip_vision" : [
        "2062",
        0
      ],
      "image"       : [
        "2109",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "2065" : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2085",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2066" : {
    "inputs"     : {
      "any_02" : [
        "2704",
        0
      ],
      "any_03" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2067" : {
    "inputs"     : {
      "clip_l"   : [
        "2088",
        0
      ],
      "t5xxl"    : [
        "2053",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2071" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_rlazs_00001_.png&type=temp&subfolder=&rand=0.02832480915060498"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_rlazs_00002_.png&type=temp&subfolder=&rand=0.5921304550560572"
          }
        ]
      },
      "image_a"          : [
        "2076",
        0
      ],
      "image_b"          : [
        "2066",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2072" : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : true,
      "hair_mask"       : true,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2066",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2073" : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskPreview+",
    "_meta"      : {
      "title" : "üîß Mask Preview"
    }
  },
  "2074" : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2076" : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "nearest-exact",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : 0,
      "y_offset"       : 0,
      "rotation"       : 0,
      "opacity"        : 6,
      "base_image"     : [
        "2066",
        0
      ],
      "overlay_image"  : [
        "2574",
        0
      ],
      "optional_mask"  : [
        "2080",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "2079" : {
    "inputs"     : {
      "invert_mask" : true,
      "grow"        : -6,
      "blur"        : 5,
      "mask"        : [
        "2072",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2080" : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2081" : {
    "inputs"     : {
      "opacity"         : 100,
      "image"           : [
        "2066",
        0
      ],
      "color_ref_image" : [
        "1837",
        0
      ]
    },
    "class_type" : "LayerColor: ColorAdapter",
    "_meta"      : {
      "title" : "LayerColor: ColorAdapter"
    }
  },
  "2083" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_urndt_00001_.png&type=temp&subfolder=&rand=0.44837473431369146"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_urndt_00002_.png&type=temp&subfolder=&rand=0.021887645488137042"
          }
        ]
      },
      "image_a"          : [
        "2085",
        0
      ],
      "image_b"          : [
        "2066",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2085" : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 24,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.58,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2076",
        0
      ],
      "segs"               : [
        "2074",
        0
      ],
      "model"              : [
        "2086",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2060",
        0
      ],
      "negative"           : [
        "2047",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Clothing Detailer)"
    }
  },
  "2086" : {
    "inputs"     : {
      "max_shift"  : 1.5,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.5"
    }
  },
  "2088" : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "560",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2100" : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "343",
        0
      ],
      "when_false" : [
        "2101",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2101" : {
    "inputs"     : {
      "condition"  : [
        "233",
        0
      ],
      "when_true"  : [
        "623",
        0
      ],
      "when_false" : [
        "623",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2102" : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "342",
        0
      ],
      "when_false" : [
        "342",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2103" : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1919",
        0
      ],
      "when_false" : [
        "2104",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2104" : {
    "inputs"     : {
      "condition"  : [
        "840",
        0
      ],
      "when_true"  : [
        "331",
        0
      ],
      "when_false" : [
        "1595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2105" : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "26",
        0
      ],
      "when_false" : [
        "2581",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2106" : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "953",
        0
      ],
      "when_false" : [
        "2595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2108" : {
    "inputs"     : {
      "condition"  : [
        "235",
        0
      ],
      "when_true"  : [
        "44",
        0
      ],
      "when_false" : [
        "1412",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2109" : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1837",
        0
      ],
      "when_false" : [
        "1566",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2110" : {
    "inputs"     : {
      "condition"  : [
        "275",
        0
      ],
      "when_true"  : [
        "362",
        0
      ],
      "when_false" : [
        "1922",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2111" : {
    "inputs"     : {
      "condition"  : [
        "325",
        0
      ],
      "when_true"  : [
        "2164",
        0
      ],
      "when_false" : [
        "567",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2117" : {
    "inputs"     : {
      "any_02" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2152" : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2153" : {
    "inputs"     : {
      "mask" : [
        "2152",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2154" : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2153",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2158" : {
    "inputs"     : {
      "any_01" : [
        "2085",
        0
      ],
      "any_02" : [
        "2117",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2164" : {
    "inputs"     : {
      "text" : "A professionally color-graded photograph of Indian v1dhya5 woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2165" : {
    "inputs"     : {
      "megapixel"     : "2.0",
      "divisible_by"  : "8",
      "mode"          : "pad",
      "delta_percent" : 1,
      "image"         : [
        "2672",
        0
      ]
    },
    "class_type" : "Image_Preparations",
    "_meta"      : {
      "title" : "Image Preparations"
    }
  },
  "2178" : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "2187" : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : "(aidmarealisticskin:0.5)",
      "text3"     : " ",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2193" : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 1,
      "blur"        : 0,
      "mask"        : [
        "55",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2197" : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1400",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2198" : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "nearest-exact",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : 0,
      "y_offset"       : 0,
      "rotation"       : 0,
      "opacity"        : 100,
      "base_image"     : [
        "2570",
        0
      ],
      "overlay_image"  : [
        "1400",
        0
      ],
      "optional_mask"  : [
        "2197",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "2200" : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2201" : {
    "inputs"     : {
      "mask" : [
        "2200",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2202" : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2201",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2203" : {
    "inputs"     : {
      "image" : [
        "2202",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2204" : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2212" : {
    "inputs"     : {
      "input1" : [
        "2240",
        0
      ],
      "input2" : 2048
    },
    "class_type" : "LogicUtil_LogicGateBitwiseXor",
    "_meta"      : {
      "title" : "LogicUtil_Bitwise Xor"
    }
  },
  "2213" : {
    "inputs"     : {
      "clip_a"  : [
        "2644",
        1
      ],
      "clip_b"  : [
        "2276",
        1
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2224" : {
    "inputs"     : {
      "model_a" : [
        "2254",
        0
      ],
      "model_b" : [
        "2276",
        0
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2226" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "325",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "2228" : {
    "inputs"     : {
      "lora_name"      : "MysticXXX-v7.safetensors",
      "strength_model" : 0.75,
      "strength_clip"  : 0.75,
      "model"          : [
        "2292",
        0
      ],
      "clip"           : [
        "2291",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2229" : {
    "inputs"     : {
      "lora_name"      : "d351_d4rk_Desi_Espresso_Flux_Kohya_V3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2228",
        0
      ],
      "clip"           : [
        "2228",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "d351 d4rk"
    }
  },
  "2231" : {
    "inputs"     : {
      "control_net_name" : "flux_shakker_labs_union_pro-fp8_e4m3fn.safetensors"
    },
    "class_type" : "ControlNetLoader",
    "_meta"      : {
      "title" : "Load ControlNet Model"
    }
  },
  "2233" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2240",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "2237" : {
    "inputs"     : {
      "model_name" : "4xPurePhoto-Span.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2240" : {
    "inputs"     : {
      "mode"       : true,
      "seed"       : 384479297671366,
      "fixed_seed" : 0
    },
    "class_type" : "SeedSelector",
    "_meta"      : {
      "title" : "Seed Selector"
    }
  },
  "2245" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2246" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2247" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2250" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0.6,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2253" : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2296",
        0
      ],
      "clip"           : [
        "2296",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2254" : {
    "inputs"     : {
      "img_in."           : 1,
      "time_in."          : 1,
      "guidance_in"       : 1,
      "vector_in."        : 1,
      "txt_in."           : 1,
      "double_blocks.0."  : 1,
      "double_blocks.1."  : 1,
      "double_blocks.2."  : 1,
      "double_blocks.3."  : 1,
      "double_blocks.4."  : 1,
      "double_blocks.5."  : 1,
      "double_blocks.6."  : 1,
      "double_blocks.7."  : 1,
      "double_blocks.8."  : 1,
      "double_blocks.9."  : 1,
      "double_blocks.10." : 1,
      "double_blocks.11." : 1,
      "double_blocks.12." : 1,
      "double_blocks.13." : 1,
      "double_blocks.14." : 1,
      "double_blocks.15." : 1,
      "double_blocks.16." : 1,
      "double_blocks.17." : 1,
      "double_blocks.18." : 1,
      "single_blocks.0."  : 1,
      "single_blocks.1."  : 1,
      "single_blocks.2."  : 1,
      "single_blocks.3."  : 1,
      "single_blocks.4."  : 1,
      "single_blocks.5."  : 1,
      "single_blocks.6."  : 1,
      "single_blocks.7."  : 1,
      "single_blocks.8."  : 1,
      "single_blocks.9."  : 1,
      "single_blocks.10." : 1,
      "single_blocks.11." : 1,
      "single_blocks.12." : 1,
      "single_blocks.13." : 1,
      "single_blocks.14." : 1,
      "single_blocks.15." : 1,
      "single_blocks.16." : 1,
      "single_blocks.17." : 1,
      "single_blocks.18." : 1,
      "single_blocks.19." : 0,
      "single_blocks.20." : 0,
      "single_blocks.21." : 0,
      "single_blocks.22." : 0,
      "single_blocks.23." : 0,
      "single_blocks.24." : 0,
      "single_blocks.25." : 0,
      "single_blocks.26." : 0,
      "single_blocks.27." : 0,
      "single_blocks.28." : 0,
      "single_blocks.29." : 0,
      "single_blocks.30." : 0,
      "single_blocks.31." : 0,
      "single_blocks.32." : 0,
      "single_blocks.33." : 0,
      "single_blocks.34." : 0,
      "single_blocks.35." : 0,
      "single_blocks.36." : 0,
      "single_blocks.37." : 0,
      "final_layer."      : 1,
      "model1"            : [
        "2560",
        0
      ],
      "model2"            : [
        "2644",
        0
      ]
    },
    "class_type" : "ModelMergeFlux1",
    "_meta"      : {
      "title" : "ModelMergeFlux1"
    }
  },
  "2255" : {
    "inputs"     : {
      "lora_name"      : "AntiBlur.safetensors",
      "strength_model" : 1.5000000000000002,
      "strength_clip"  : 1.0000000000000002,
      "model"          : [
        "2256",
        0
      ],
      "clip"           : [
        "2256",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2256" : {
    "inputs"     : {
      "lora_name"      : "aidmaImageUprader-FLUX-v0.3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 1,
      "model"          : [
        "2229",
        0
      ],
      "clip"           : [
        "2229",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2257" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.85,
      "strength_clip"  : 0.6,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2258" : {
    "inputs"     : {
      "model_name" : "4xPurePhoto-Span.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2262" : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.8000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2250",
        0
      ],
      "clip"           : [
        "2250",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2267" : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.44,
      "strength_clip"  : 0.3,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmafluxproultra"
    }
  },
  "2268" : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.8,
      "strength_clip"  : 3.8,
      "model"          : [
        "2267",
        0
      ],
      "clip"           : [
        "2267",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2"
    }
  },
  "2273" : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA ::0.8:0.2"
    }
  },
  "2275" : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmafluxproultra"
    }
  },
  "2276" : {
    "inputs"     : {
      "lora_name"      : "Illustration Comic book_(FLUX)_06.safetensors",
      "strength_model" : 0.5,
      "strength_clip"  : 1.0000000000000002,
      "model"          : [
        "2262",
        0
      ],
      "clip"           : [
        "2262",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2277" : {
    "inputs"     : {
      "lora_name"      : "aidmaImageUprader-FLUX-v0.3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2275",
        0
      ],
      "clip"           : [
        "2275",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2291" : {
    "inputs"     : {
      "clip_a"  : [
        "2293",
        1
      ],
      "clip_b"  : [
        "2729",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2292" : {
    "inputs"     : {
      "model_a" : [
        "2293",
        0
      ],
      "model_b" : [
        "2729",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2293" : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.8,
      "model"          : [
        "2246",
        0
      ],
      "clip"           : [
        "2246",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2296" : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2247",
        0
      ],
      "clip"           : [
        "2247",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2297" : {
    "inputs"     : {
      "clip_a"  : [
        "2293",
        1
      ],
      "clip_b"  : [
        "2255",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2298" : {
    "inputs"     : {
      "model_a" : [
        "2293",
        0
      ],
      "model_b" : [
        "2255",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2300" : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.8,
      "strength_clip"  : 3.8,
      "model"          : [
        "2694",
        0
      ],
      "clip"           : [
        "2694",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2"
    }
  },
  "2302" : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 0.7,
      "model"          : [
        "2245",
        0
      ],
      "clip"           : [
        "2245",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Realism"
    }
  },
  "2303" : {
    "inputs"     : {
      "level"     : 1.2,
      "src_image" : [
        "2109",
        0
      ]
    },
    "class_type" : "ImageSaturation",
    "_meta"      : {
      "title" : "Adjust Saturation"
    }
  },
  "2304" : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2305" : {
    "inputs"     : {
      "conditioning" : [
        "2304",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2316" : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2317",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2317" : {
    "inputs"     : {
      "text1"     : "masterpiece professional potrait photograph of v1dhya5 indian",
      "text2"     : [
        "1479",
        0
      ],
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2319" : {
    "inputs"     : {
      "max_shift"  : 1.15,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2875",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2320" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kxfgj_00001_.png&type=temp&subfolder=&rand=0.025818970745877134"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kxfgj_00002_.png&type=temp&subfolder=&rand=0.31824973207013707"
          }
        ]
      },
      "image_a"          : [
        "2328",
        0
      ],
      "image_b"          : [
        "1837",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2321" : {
    "inputs"     : {
      "radius"          : 4,
      "amount"          : 0.8,
      "reduce_noise"    : 0.01,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0,
      "image"           : [
        "2332",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "SharpnessPro ¬∑ Nettet√© optimis√©e"
    }
  },
  "2325" : {
    "inputs"     : {
      "detail_amount"      : 0.32,
      "start"              : 0.2,
      "end"                : 0.8,
      "bias"               : 0.5,
      "exponent"           : 1,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : false,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "2892",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2328" : {
    "inputs"     : {
      "megapixel"     : "1.8",
      "divisible_by"  : "8",
      "mode"          : "pad",
      "delta_percent" : 0.5,
      "image"         : [
        "2321",
        0
      ]
    },
    "class_type" : "Image_Preparations",
    "_meta"      : {
      "title" : "Image Preparations"
    }
  },
  "2331" : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 18,
      "denoise"   : 0.26,
      "model"     : [
        "2875",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2332" : {
    "inputs"     : {
      "upscale_by"          : 0.95,
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 18,
      "cfg"                 : 1,
      "sampler_name"        : "euler",
      "scheduler"           : "beta",
      "denoise"             : 0.26,
      "mode_type"           : "Linear",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : false,
      "tiled_decode"        : false,
      "image"               : [
        "2165",
        0
      ],
      "model"               : [
        "2319",
        0
      ],
      "positive"            : [
        "2316",
        0
      ],
      "negative"            : [
        "2305",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2237",
        0
      ],
      "custom_sampler"      : [
        "2325",
        0
      ],
      "custom_sigmas"       : [
        "2331",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2339" : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2362",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2345" : {
    "inputs"     : {
      "any_01" : [
        "2040",
        0
      ],
      "any_02" : [
        "2085",
        0
      ],
      "any_04" : [
        "2704",
        0
      ],
      "any_05" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2346" : {
    "inputs"     : {
      "combined"     : false,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2347",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2347" : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2355",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2348" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pxibu_00001_.png&type=temp&subfolder=&rand=0.42114072001554237"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pxibu_00002_.png&type=temp&subfolder=&rand=0.29104901776194847"
          }
        ]
      },
      "image_a"          : [
        "2362",
        0
      ],
      "image_b"          : [
        "2345",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2351" : {
    "inputs"     : {
      "conditioning" : [
        "2352",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2352" : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2355" : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 2,
      "compute_device"  : "auto",
      "images"          : [
        "2345",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2361" : {
    "inputs"     : {
      "clip_l"   : [
        "2886",
        0
      ],
      "t5xxl"    : [
        "2885",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2362" : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 21,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : [
        "2553",
        0
      ],
      "feather"            : 2,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2345",
        0
      ],
      "segs"               : [
        "2346",
        0
      ],
      "model"              : [
        "2363",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2361",
        0
      ],
      "negative"           : [
        "2351",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Face Detailer) 23 Steps"
    }
  },
  "2363" : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2365" : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2403",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2371" : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2372" : {
    "inputs"     : {
      "conditioning" : [
        "2371",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2377" : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2404",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2384" : {
    "inputs"     : {
      "any_01" : [
        "2713",
        0
      ],
      "any_03" : [
        "2362",
        0
      ],
      "any_04" : [
        "2040",
        0
      ],
      "any_05" : [
        "2085",
        0
      ],
      "any_07" : [
        "2704",
        0
      ],
      "any_08" : [
        "1888",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2390" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kpoeh_00001_.png&type=temp&subfolder=&rand=0.2211496324112413"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kpoeh_00002_.png&type=temp&subfolder=&rand=0.22186804952240768"
          }
        ]
      },
      "image_a"          : [
        "2403",
        0
      ],
      "image_b"          : [
        "2384",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2393" : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 25,
      "denoise"   : 0.24,
      "model"     : [
        "2224",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2398" : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2403" : {
    "inputs"     : {
      "upscale_by"          : [
        "1740",
        0
      ],
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 16,
      "cfg"                 : 1,
      "sampler_name"        : "euler",
      "scheduler"           : "beta",
      "denoise"             : 0.3,
      "mode_type"           : "Chess",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : true,
      "tiled_decode"        : false,
      "image"               : [
        "2384",
        0
      ],
      "model"               : [
        "2398",
        0
      ],
      "positive"            : [
        "2377",
        0
      ],
      "negative"            : [
        "2372",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2258",
        0
      ],
      "custom_sampler"      : [
        "2524",
        0
      ],
      "custom_sigmas"       : [
        "2393",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2404" : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2523" : {
    "inputs"     : {
      "dishonesty_factor" : -0.02,
      "start_percent"     : 0.25000000000000006,
      "end_percent"       : 0.7500000000000001,
      "sampler"           : [
        "2892",
        0
      ]
    },
    "class_type" : "LyingSigmaSampler",
    "_meta"      : {
      "title" : "Lying Sigma Sampler"
    }
  },
  "2524" : {
    "inputs"     : {
      "detail_amount"      : 0.12,
      "start"              : 0.3,
      "end"                : 0.7,
      "bias"               : 0.5,
      "exponent"           : 1,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : false,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "2523",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2529" : {
    "inputs"     : {
      "expression" : "max(a,b)/min(a,b)",
      "a"          : [
        "1913",
        1
      ],
      "b"          : [
        "1913",
        2
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "2532" : {
    "inputs"     : {
      "condition"  : [
        "2535",
        0
      ],
      "when_true"  : [
        "2534",
        0
      ],
      "when_false" : [
        "2103",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2534" : {
    "inputs"     : {
      "a"         : [
        "2103",
        0
      ],
      "b"         : 0.5,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2535" : {
    "inputs"     : {
      "comparison" : "a >= b",
      "a"          : [
        "2529",
        0
      ],
      "b"          : [
        "2536",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "2536" : {
    "inputs"     : {
      "value" : 1.72
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Float Constant"
    }
  },
  "2541" : {
    "inputs"     : {
      "a"         : [
        "1955",
        0
      ],
      "b"         : 0.62,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2543" : {
    "inputs"     : {
      "int_" : [
        "2110",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "2544" : {
    "inputs"     : {
      "text" : [
        "283",
        0
      ]
    },
    "class_type" : "JWStringToInteger",
    "_meta"      : {
      "title" : "String to Integer"
    }
  },
  "2545" : {
    "inputs"     : {
      "strings"   : "Inputs/Next/Best\nInputs/Next/best",
      "multiline" : false,
      "select"    : 0
    },
    "class_type" : "ImpactStringSelector",
    "_meta"      : {
      "title" : "String Selector"
    }
  },
  "2552" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "2545",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "2553" : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 1,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2555" : {
    "inputs"     : {
      "text1"     : "The subject is having a ",
      "text2"     : [
        "513",
        0
      ],
      "text3"     : " facial expression",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2560" : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2257",
        0
      ],
      "clip"           : [
        "2257",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2567" : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "TT",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [TT]"
    }
  },
  "2570" : {
    "inputs"     : {
      "condition"  : [
        "2567",
        0
      ],
      "when_true"  : [
        "2154",
        0
      ],
      "when_false" : [
        "1831",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2574" : {
    "inputs"     : {
      "channel"            : "RGB",
      "black_point"        : 8,
      "white_point"        : 255,
      "gray_point"         : 1.02,
      "output_black_point" : 0,
      "output_white_point" : 255,
      "image"              : [
        "2081",
        0
      ]
    },
    "class_type" : "LayerColor: Levels",
    "_meta"      : {
      "title" : "LayerColor: Levels"
    }
  },
  "2579" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "1936",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "2580" : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "249",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2581" : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2580",
        0
      ],
      "text_b"           : [
        "484",
        0
      ],
      "text_c"           : [
        "2590",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2590" : {
    "inputs"     : {
      "prompt"           : [
        "515",
        0
      ],
      "camera"           : "Fujifilm X-T5",
      "composition_shot" : "None",
      "time_of_day"      : "None",
      "color_grading"    : "Vivid",
      "lighting"         : "Practical Lighting",
      "environment"      : "None"
    },
    "class_type" : "Magic Photo Prompter ü™Ñ",
    "_meta"      : {
      "title" : "Magic Photo Prompter ü™Ñ"
    }
  },
  "2595" : {
    "inputs"     : {
      "find"    : "__AGE__",
      "replace" : [
        "2598",
        0
      ],
      "text"    : [
        "950",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2598" : {
    "inputs"     : {
      "string"  : "__{{ age }}__ years old ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "2599" : {
    "inputs"     : {
      "text_0" : "professionally color-graded RAW photograph, 23 years old  Indian v1dhya5 busty woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, ",
      "text"   : [
        "2106",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2605" : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "788",
        0
      ],
      "text3"     : [
        "1318",
        0
      ],
      "delimiter" : "/n_________________________/n"
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "2608" : {
    "inputs"     : {
      "text_0" : "professionally color-graded RAW photograph, 23 years old  Indian v1dhya5 busty woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, /n_________________________/nA professionally color-graded photograph of Indian v1dhya5 woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 23 years of age,,The photo shows a woman standing in front of a glass wall, wearing a red dress with a square neckline and elbow-length sleeves. Her hair is long and wavy, cascading over her shoulders. She is wearing subtle makeup with defined eyeliner, mascara, and a bold red lipstick. The woman's eyes are open, and she has a neutral expression. The background consists of a reflective glass wall, creating a mirrored effect that doubles the visual elements of the photo. The overall setting appears to be modern and urban, with a muted, overcast sky visible through the glass.,Photograph of , She is wearing outfit through which the subtle outline of her bra is visible. Around her waist is a delicate waist chain, and a platinum diamond belly piercing accentuates her abdomen. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Medium breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a pouting facial expression. incorporating visible light sources within the scene. shot on Fujifilm X-T5. with highly saturated vivid colors/n_________________________/ndetailed fabric texture,The outfit in the photo is a deep red, floor-length dress with a square neckline and short sleeves. The material appears to be a smooth, possibly stretchy fabric, likely made of a blend of cotton and polyester for comfort and flexibility. The fit of the dress is tailored, hugging the body in a structured manner, creating a flattering silhouette.,slightly translucent elements in the intricate outfit with see though sleeves, showing the profile of the 36DD Cup size  bra wearing underneath.",
      "text"   : [
        "2605",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2609" : {
    "inputs"     : {
      "file_prefix"   : [
        "2611",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2611" : {
    "inputs"     : {
      "text1" : "Generated_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2612" : {
    "inputs"     : {
      "file_prefix"   : [
        "2614",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2614" : {
    "inputs"     : {
      "text1" : "Prompt_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2615" : {
    "inputs"     : {
      "path"                    : "./output/[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2612",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "file_extension"          : ".txt",
      "encoding"                : "utf-8",
      "filename_suffix"         : "",
      "text"                    : [
        "2605",
        0
      ]
    },
    "class_type" : "Save Text File",
    "_meta"      : {
      "title" : "Save Text File"
    }
  },
  "2618" : {
    "inputs"     : {
      "lora_name"      : "FC Flux Perfect Busts.safetensors",
      "strength_model" : 1.01,
      "strength_clip"  : 1,
      "model"          : [
        "2253",
        0
      ],
      "clip"           : [
        "2253",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2644" : {
    "inputs"     : {
      "lora_name"      : "BreastShaper_splendid_droplets_Flux_v3.0-000009.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 1,
      "model"          : [
        "2300",
        0
      ],
      "clip"           : [
        "2300",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2652" : {
    "inputs"     : {
      "text" : "aidmaimageupgrader, fluxenhancer, detailed hands, Perfect hand"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2655" : {
    "inputs"     : {
      "lora_name"      : "Detailed_Hands-000001.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2224",
        0
      ],
      "clip"           : [
        "2213",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2656" : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, slicked back hairstyle:1.2, high ponytail:1.3, pulled back hairstyle:1.2, Skin imperfections , Freckles, moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2666" : {
    "inputs"     : {
      "detail_amount"      : 0.2,
      "start"              : 0.4,
      "end"                : 0.75,
      "bias"               : 0.5,
      "exponent"           : 0.8,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : false,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "1909",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2669" : {
    "inputs"     : {
      "image" : [
        "2670",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2670" : {
    "inputs"     : {
      "samples" : [
        "1989",
        0
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "2671" : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2672" : {
    "inputs"     : {
      "shadow_brightness"      : 0.88,
      "shadow_saturation"      : 1,
      "shadow_hue"             : 0,
      "shadow_level_offset"    : 0,
      "shadow_range"           : 0.25,
      "highlight_brightness"   : 0.97,
      "highlight_saturation"   : 1,
      "highlight_hue"          : 0,
      "highlight_level_offset" : 0,
      "highlight_range"        : 0.25,
      "image"                  : [
        "2198",
        0
      ]
    },
    "class_type" : "LayerColor: Color of Shadow & Highlight",
    "_meta"      : {
      "title" : "LayerColor: Color of Shadow & Highlight"
    }
  },
  "2675" : {
    "inputs"     : {
      "strength"   : 100,
      "brightness" : 0,
      "contrast"   : 0,
      "saturation" : 0,
      "red"        : 27,
      "green"      : 17,
      "blue"       : 0,
      "mode"       : "RGB",
      "image"      : [
        "2570",
        0
      ]
    },
    "class_type" : "LayerColor: AutoAdjustV2",
    "_meta"      : {
      "title" : "LayerColor: AutoAdjust V2"
    }
  },
  "2694" : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2560",
        0
      ],
      "clip"           : [
        "2560",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2695" : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2273",
        0
      ],
      "clip"           : [
        "2273",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2703" : {
    "inputs"     : {
      "image" : [
        "1888",
        0
      ]
    },
    "class_type" : "ImpactImageBatchToImageList",
    "_meta"      : {
      "title" : "Image Batch to Image List"
    }
  },
  "2704" : {
    "inputs"     : {
      "images" : [
        "339",
        0
      ]
    },
    "class_type" : "ImageListToImageBatch",
    "_meta"      : {
      "title" : "Image List to Image Batch"
    }
  },
  "2713" : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : true,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 26,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.46,
      "feather"            : 2,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "1611",
        0
      ],
      "segs"               : [
        "2714",
        0
      ],
      "model"              : [
        "599",
        0
      ],
      "clip"               : [
        "2655",
        1
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "609",
        0
      ],
      "negative"           : [
        "589",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Hands Detailer)"
    }
  },
  "2714" : {
    "inputs"     : {
      "combined"     : false,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2715",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2715" : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2748",
        1
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2716" : {
    "inputs"     : {
      "mask_opacity" : 0.6,
      "mask_color"   : "255, 0, 227",
      "pass_through" : false,
      "image"        : [
        "1611",
        0
      ],
      "mask"         : [
        "2748",
        1
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2727" : {
    "inputs"     : {
      "preprocessor" : "DepthAnythingPreprocessor",
      "resolution"   : [
        "1942",
        0
      ],
      "image"        : [
        "2703",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "2728" : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_lxgpn_00001_.png&type=temp&subfolder=&rand=0.8878057190339189"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_lxgpn_00002_.png&type=temp&subfolder=&rand=0.677581110006607"
          }
        ]
      },
      "image_a"          : [
        "2727",
        0
      ],
      "image_b"          : [
        "482",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2729" : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2302",
        0
      ],
      "clip"           : [
        "2302",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2732" : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.9,
      "strength_clip"  : 3.9,
      "model"          : [
        "2277",
        0
      ],
      "clip"           : [
        "2277",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2"
    }
  },
  "2734" : {
    "inputs"     : {
      "question"          : "Describe the Facial expression of the subject, hair style, jewelry and outfit. Also, describe about  the make-up, eyes and lipstick",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 512,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "2736" : {
    "inputs"     : {
      "text_0" : "The subject in the image has a neutral expression, with her eyes slightly open and her lips closed, giving a calm and composed appearance. Her hair is long and wavy, cascading over her shoulders. She is wearing a simple yet elegant dress in a rich burgundy color, with a square neckline and three-quarter sleeves. The outfit is complemented by minimalistic makeup, with defined eyeliner and mascara enhancing her eyes, and a subtle lipstick that adds a touch of sophistication to her look.",
      "text"   : [
        "2734",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2744" : {
    "inputs"     : {
      "vae" : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "2745" : {
    "inputs"     : {
      "vae" : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "2748" : {
    "inputs"     : {
      "mask_bbox_padding" : 30,
      "resolution"        : 512,
      "mask_type"         : "original",
      "mask_expand"       : 8,
      "rand_seed"         : 88,
      "detect_thr"        : 0.36,
      "presence_thr"      : 0.6,
      "image"             : [
        "1611",
        0
      ]
    },
    "class_type" : "MeshGraphormer-DepthMapPreprocessor",
    "_meta"      : {
      "title" : "MeshGraphormer Hand Refiner"
    }
  },
  "2751" : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2756",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2753" : {
    "inputs"     : {
      "text_0" : "A professionally color-graded photograph of Indian v1dhya5 woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 23 years of age,,The subject has a cheerful facial expression with a smile, showing her teeth. Her hair is styled in a neat bun, secured with a blue hairband. She is wearing elegant earrings and a statement necklace. Her outfit is a deep maroon dress with white floral patterns, giving a traditional and stylish look. The makeup is subtle but enhances her features, with a touch of blush and mascara. Her eyes are accentuated with eyeliner, and she has a natural pink lipstick.",
      "text"   : [
        "2754",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2754" : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2755",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2755" : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "2751",
        0
      ],
      "when_false" : [
        "2756",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2756" : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "2734",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2759" : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : "Natural breast shape, Perfect hand and fingers and nails with pastel nail polish,wearing thin golden necklace,",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2862" : {
    "inputs"     : {
      "text" : "aidmafluxproultra, fluxenhancer, Skin imperfections ,   moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2863" : {
    "inputs"     : {
      "lora_name"      : "FC Flux Perfect Busts.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2268",
        0
      ],
      "clip"           : [
        "2268",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2866" : {
    "inputs"     : {
      "model_a" : [
        "2267",
        0
      ],
      "model_b" : [
        "2863",
        0
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2867" : {
    "inputs"     : {
      "clip_a"  : [
        "2267",
        1
      ],
      "clip_b"  : [
        "2863",
        1
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2869" : {
    "inputs"     : {
      "preview" : "",
      "source"  : [
        "241",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview Any"
    }
  },
  "2874" : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2732",
        0
      ],
      "clip"           : [
        "2732",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2875" : {
    "inputs"     : {
      "lora_name"      : "d351_Coffee_Krea_Kohya_V1_Unchained_prodigy-000012.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2618",
        0
      ],
      "clip"           : [
        "2618",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2881" : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.2,
      "strength_clip"  : 3.2,
      "model"          : [
        "2695",
        0
      ],
      "clip"           : [
        "2695",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2885" : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "aidmarealisticskin, Skin imperfections, fluxenhancer",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2886" : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : "(aidmarealisticskin:0.5)",
      "text3"     : " ",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2888" : {
    "inputs"     : {
      "stop_at_clip_layer" : -3,
      "clip"               : [
        "2893",
        0
      ]
    },
    "class_type" : "CLIPSetLastLayer",
    "_meta"      : {
      "title" : "CLIP Set Last Layer"
    }
  },
  "2889" : {
    "inputs"     : {
      "vae_name" : "ae.safetensors"
    },
    "class_type" : "VAELoader",
    "_meta"      : {
      "title" : "FLUX VAE"
    }
  },
  "2890" : {
    "inputs"     : {
      "q"    : 1.2,
      "k"    : 1.1,
      "v"    : 0.8,
      "out"  : 1.25,
      "clip" : [
        "2888",
        0
      ]
    },
    "class_type" : "CLIPAttentionMultiply",
    "_meta"      : {
      "title" : "CLIPAttentionMultiply"
    }
  },
  "2891" : {
    "inputs"     : {
      "block_number"         : 4,
      "downscale_factor"     : 2,
      "start_percent"        : 0,
      "end_percent"          : 0.5,
      "downscale_after_skip" : true,
      "downscale_method"     : "bislerp",
      "upscale_method"       : "bislerp",
      "model"                : [
        "2894",
        0
      ]
    },
    "class_type" : "PatchModelAddDownscale",
    "_meta"      : {
      "title" : "PatchModelAddDownscale"
    }
  },
  "2892" : {
    "inputs"     : {
      "sampler_name" : "euler_ancestral"
    },
    "class_type" : "KSamplerSelect",
    "_meta"      : {
      "title" : "KSamplerSelect"
    }
  },
  "2893" : {
    "inputs"     : {
      "clip_name1" : "ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors",
      "clip_name2" : "t5xxl_fp16.safetensors",
      "type"       : "flux",
      "device"     : "default"
    },
    "class_type" : "DualCLIPLoader",
    "_meta"      : {
      "title" : "DualCLIPLoader"
    }
  },
  "2894" : {
    "inputs"     : {
      "unet_name"    : "flux1-dev.safetensors",
      "weight_dtype" : "fp8_e4m3fn"
    },
    "class_type" : "UNETLoader",
    "_meta"      : {
      "title" : "Load Diffusion Model"
    }
  }
}