{
  "25"        : {
    "inputs"     : {
      "text_0" : "The image shows a woman with long, wavy, dark hair wearing a sleeveless turquoise crop top. She is accessorized with a delicate gold chain necklace and a pair of glasses perched on her head. Her makeup is natural, highlighting her eyes and lips subtly. The background is neutral and blurred, focusing attention on the woman's attire and accessories.",
      "text"   : [
        "484",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "26"        : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2581",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "30"        : {
    "inputs"     : {
      "text" : "A closeup professional photoshoot analog photograph of a shy and alluring dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.2), deep rich complexion with a scattering of freckles across cheeks and nose, \n\nfilm, film grain, kdkpt400, kodak, portra400, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "41"        : {
    "inputs"     : {
      "crop"        : "center",
      "clip_vision" : [
        "1517",
        0
      ],
      "image"       : [
        "2109",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "42"        : {
    "inputs"     : {
      "strength"           : 0.48,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "1412",
        0
      ],
      "style_model"        : [
        "43",
        0
      ],
      "clip_vision_output" : [
        "41",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "43"        : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "44"        : {
    "inputs"     : {
      "conditioning_to_strength" : 0.5000000000000001,
      "conditioning_to"          : [
        "1412",
        0
      ],
      "conditioning_from"        : [
        "42",
        0
      ]
    },
    "class_type" : "ConditioningAverage",
    "_meta"      : {
      "title" : "ConditioningAverage"
    }
  },
  "55"        : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2703",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "104"       : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : true,
      "body_mask"       : true,
      "clothes_mask"    : true,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1267",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "110"       : {
    "inputs"     : {
      "text_0" : "The outfit in the photo consists of a sleeveless, teal-colored crop top with thin straps. The material appears to be a smooth, stretchy fabric, possibly spandex or a similar blend, which provides a snug fit. The top has a deep neckline and a slightly scoop-shaped design, adding to its stylish look. The outfit is accessorized with a layered gold chain necklace, adding a touch of elegance to the overall appearance.",
      "text"   : [
        "485",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "122"       : {
    "inputs"     : {
      "any" : [
        "581",
        1
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "124"       : {
    "inputs"     : {
      "boolean" : [
        "122",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "143"       : {
    "inputs"     : {
      "images" : [
        "1831",
        0
      ]
    },
    "class_type" : "Image to Seed",
    "_meta"      : {
      "title" : "Image to Seed"
    }
  },
  "146"       : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "154"       : {
    "inputs"     : {
      "pixels" : [
        "2109",
        0
      ],
      "vae"    : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEEncode",
    "_meta"      : {
      "title" : "VAE Encode"
    }
  },
  "193"       : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "195"       : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "232"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "##",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "233"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "**",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [**]"
    }
  },
  "235"       : {
    "inputs"     : {
      "boolean_a" : [
        "286",
        0
      ],
      "boolean_b" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic Comparison OR",
    "_meta"      : {
      "title" : "Logic Comparison OR"
    }
  },
  "240"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "saree",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [Saree]"
    }
  },
  "241"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "back",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "242"       : {
    "inputs"     : {
      "text_a"  : [
        "247",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "240",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "243"       : {
    "inputs"     : {
      "text_a"  : [
        "265",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "255",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "244"       : {
    "inputs"     : {
      "value" : "Photo taken from the back of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "245"       : {
    "inputs"     : {
      "string_a"  : [
        "243",
        0
      ],
      "string_b"  : [
        "258",
        0
      ],
      "delimiter" : ""
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "247"       : {
    "inputs"     : {
      "value" : "wearing indian saree with intricate details"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "249"       : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "245",
        0
      ],
      "text_b"           : [
        "242",
        0
      ],
      "text_c"           : [
        "253",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "251"       : {
    "inputs"     : {
      "text" : [
        "254",
        0
      ]
    },
    "class_type" : "ShowText|LP",
    "_meta"      : {
      "title" : "Show Text [LP]"
    }
  },
  "252"       : {
    "inputs"     : {
      "join_with"   : ",",
      "string_list" : [
        "251",
        0
      ]
    },
    "class_type" : "StringListToString",
    "_meta"      : {
      "title" : "String List to String"
    }
  },
  "253"       : {
    "inputs"     : {
      "string"  : [
        "252",
        0
      ],
      "find"    : "_",
      "replace" : ","
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "254"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "__(.*)__",
      "mode"             : "All Groups",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "255"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "side",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "258"       : {
    "inputs"     : {
      "text_a"  : [
        "244",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "262"       : {
    "inputs"     : {
      "value" : ""
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "On False"
    }
  },
  "265"       : {
    "inputs"     : {
      "value" : "Photo taken from the side of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "266"       : {
    "inputs"     : {
      "boolean" : true
    },
    "class_type" : "Logic Boolean Primitive",
    "_meta"      : {
      "title" : "Red Lipstick?"
    }
  },
  "268"       : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "2110",
        0
      ],
      "b"          : [
        "1921",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "271"       : {
    "inputs"     : {
      "string"  : "the subject is portrayed at __{{ age }}__ years of age,  ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "272"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "\\((.*)\\)",
      "mode"             : "First Group",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "275"       : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "2544",
        0
      ],
      "b"          : [
        "1920",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "277"       : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "L"
    }
  },
  "278"       : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "283"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "284",
        0
      ],
      "text_b"           : [
        "272",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "284"       : {
    "inputs"     : {
      "value" : "0"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "285"       : {
    "inputs"     : {
      "value" : "+"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "286"       : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "288"       : {
    "inputs"     : {
      "text" : [
        "289",
        0
      ]
    },
    "class_type" : "ShowTextBridge|LP",
    "_meta"      : {
      "title" : "Show Text Bridge [LP]"
    }
  },
  "289"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\++)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "290"       : {
    "inputs"     : {
      "string" : [
        "296",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "293"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "500",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "294"       : {
    "inputs"     : {
      "string" : [
        "293",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "295"       : {
    "inputs"     : {
      "int" : 5
    },
    "class_type" : "Int Literal",
    "_meta"      : {
      "title" : "Int Literal"
    }
  },
  "296"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "289",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "322"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "sketch",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [sketch]"
    }
  },
  "325"       : {
    "inputs"     : {
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "Logic NOT"
    }
  },
  "331"       : {
    "inputs"     : {
      "select"   : 1,
      "sel_mode" : false,
      "input1"   : [
        "278",
        0
      ],
      "input2"   : [
        "334",
        0
      ],
      "input3"   : [
        "335",
        0
      ],
      "input4"   : [
        "277",
        0
      ]
    },
    "class_type" : "ImpactSwitch",
    "_meta"      : {
      "title" : "Switch (Any)"
    }
  },
  "334"       : {
    "inputs"     : {
      "value" : 2
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "S"
    }
  },
  "335"       : {
    "inputs"     : {
      "value" : 6
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "M"
    }
  },
  "339"       : {
    "inputs"     : {
      "noise_scale"   : [
        "622",
        0
      ],
      "blend_opacity" : 11,
      "image"         : [
        "363",
        0
      ],
      "mask"          : [
        "2193",
        0
      ]
    },
    "class_type" : "NoisePlusBlend",
    "_meta"      : {
      "title" : "Noise Plus Blend"
    }
  },
  "342"       : {
    "inputs"     : {
      "value1" : 0.72,
      "value2" : 0.56
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "0.72::0.56"
    }
  },
  "343"       : {
    "inputs"     : {
      "value1" : 0.52,
      "value2" : 0.37
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "Input+DetailerDenoise[0.62,0.56]"
    }
  },
  "356"       : {
    "inputs"     : {
      "image" : [
        "1848",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "362"       : {
    "inputs"     : {
      "value" : 24
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Age"
    }
  },
  "363"       : {
    "inputs"     : {
      "center_x"            : 0.3,
      "center_y"            : 0.5,
      "saturation"          : 0.9,
      "vignette_intensity"  : 0.010000000000000002,
      "grain_method"        : "filmgrainer",
      "grain_power"         : 0.08,
      "grain_scale"         : 0.4,
      "grain_sat"           : 0.3,
      "filmgrainer_shadows" : 0.15000000000000002,
      "filmgrainer_highs"   : 0.10000000000000002,
      "blur_strength"       : 1,
      "blur_focus_spread"   : 0.30000000000000004,
      "focal_depth"         : 0.10000000000000002,
      "image"               : [
        "482",
        0
      ],
      "depth_map"           : [
        "2727",
        0
      ]
    },
    "class_type" : "LayerFilter: FilmV2",
    "_meta"      : {
      "title" : "LayerFilter: Film V2"
    }
  },
  "389"       : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "394"       : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSize+",
    "_meta"      : {
      "title" : "üîß Get Image Size"
    }
  },
  "405"       : {
    "inputs"     : {
      "text" : "\n(dark pimple marks in the left cheek:0.8), tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3), and her hair is long, curly. She has minimal makeup, with a focus on sharp black eyeliner and nude matte warm brown lipstick on her sexy pouty lips.\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, cleavage.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "440"       : {
    "inputs"     : {
      "cyan_red"      : 0.01,
      "magenta_green" : 0,
      "yellow_blue"   : 0.02,
      "image"         : [
        "356",
        0
      ]
    },
    "class_type" : "LayerColor: ColorBalance",
    "_meta"      : {
      "title" : "LayerColor: ColorBalance"
    }
  },
  "441"       : {
    "inputs"     : {
      "expand"                 : 1,
      "incremental_expandrate" : 0,
      "tapered_corners"        : false,
      "flip_input"             : false,
      "blur_radius"            : 0,
      "lerp_alpha"             : 0,
      "decay_factor"           : 0,
      "fill_holes"             : false,
      "mask"                   : [
        "545",
        0
      ]
    },
    "class_type" : "GrowMaskWithBlur",
    "_meta"      : {
      "title" : "Grow Mask With Blur"
    }
  },
  "445"       : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "454"       : {
    "inputs"     : {
      "image" : [
        "440",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "455"       : {
    "inputs"     : {
      "x"           : 0,
      "y"           : 0,
      "operation"   : "or",
      "destination" : [
        "457",
        0
      ],
      "source"      : [
        "456",
        0
      ]
    },
    "class_type" : "MaskComposite",
    "_meta"      : {
      "title" : "MaskComposite"
    }
  },
  "456"       : {
    "inputs"     : {
      "shape"        : "square",
      "frames"       : 1,
      "location_x"   : 0,
      "location_y"   : 0,
      "grow"         : 1,
      "frame_width"  : [
        "445",
        1
      ],
      "frame_height" : [
        "445",
        2
      ],
      "shape_width"  : 16,
      "shape_height" : [
        "445",
        2
      ]
    },
    "class_type" : "CreateShapeMask",
    "_meta"      : {
      "title" : "Create Shape Mask"
    }
  },
  "457"       : {
    "inputs"     : {
      "red"       : 255,
      "green"     : 0,
      "blue"      : 207,
      "threshold" : 10,
      "image"     : [
        "454",
        0
      ]
    },
    "class_type" : "MaskFromColor+",
    "_meta"      : {
      "title" : "üîß Mask From Color"
    }
  },
  "459"       : {
    "inputs"     : {
      "mask" : [
        "455",
        0
      ]
    },
    "class_type" : "MaskToImage",
    "_meta"      : {
      "title" : "Convert Mask to Image"
    }
  },
  "461"       : {
    "inputs"     : {
      "op" : "IsZero",
      "a"  : 1
    },
    "class_type" : "CM_IntUnaryCondition",
    "_meta"      : {
      "title" : "IntUnaryCondition"
    }
  },
  "478"       : {
    "inputs"     : {
      "image" : [
        "2703",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "482"       : {
    "inputs"     : {
      "noise_radius"   : 1,
      "preserve_edges" : 1,
      "sharpen"        : 0.5,
      "ratio"          : 0.5,
      "image"          : [
        "478",
        0
      ]
    },
    "class_type" : "ImageSmartSharpen+",
    "_meta"      : {
      "title" : "üîß Image Smart Sharpen"
    }
  },
  "484"       : {
    "inputs"     : {
      "question"          : "Describe this photo in essential details concisely with detais about the background, camera angle of the shot, intrinsic details about accesories like glasses, hair style, jewelry and outfit. Also, describe about facial expression including the make-up, eyes and lipstick, avoid mentioning blurred and try to find details in the background. ",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 1024,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "485"       : {
    "inputs"     : {
      "question"          : "Describe the outfit in the photo in essential details with detais about the color, material, texture of the materials, fit etc.",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 768,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "494"       : {
    "inputs"     : {
      "text" : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry,\n\n\nnude, dark texture areola and erect nipples,  (nsfw:0.7),  \n\n\nsee-through blouse and saree, deep-cleavage, jewelry, (Hip-Chain:1.2), \n\ncolorful silk saree with expensive hand-made embroidery designs, backless blouse,\n\nsexy heart-shaped clothing cutout in the back revealing buttcrack,\n\nsee-through saree, Floral prints embroidery,    Belly Piercing,\n\nwearing Glasses\n\nSitting on the knees, in front of mirror,  Happy facial expression,colorful lace top with expensive hand-made embroidery designs backless blouse,  \n\nSexy Hip-Chain,Sexy Waist-Chain, Sexy crop-top made of jasmine flowers,\n\nA tattoo of a baby elephant is visible on the left chest area. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "495"       : {
    "inputs"     : {
      "text" : " hip chain, waist chain, hands behind the back, crop top overhang,\n\nand light freckles scattered across her cheeks and nose. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "496"       : {
    "inputs"     : {
      "text" : "fluxenhancer, aidmaimageupgrader"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "500"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\-\\-)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "511"       : {
    "inputs"     : {
      "text_0" : "The subject is having a aroused facial expression",
      "text"   : [
        "2555",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "513"       : {
    "inputs"     : {
      "text"   : "loving \npouting\nshy\nhappy\nvery happy\nsilly\naroused\nflirting\nseductive\nprovocative\nsurprised\nopen mouth",
      "amount" : 1,
      "seed"   : [
        "2240",
        0
      ]
    },
    "class_type" : "TextRandomMultiline",
    "_meta"      : {
      "title" : "Text Random Multiline"
    }
  },
  "514"       : {
    "inputs"     : {
      "text_0" : "the subject is portrayed at 24 years of age,  ",
      "text"   : [
        "271",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "515"       : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "1945",
        0
      ],
      "text_b"           : [
        "2555",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "516"       : {
    "inputs"     : {
      "text_0" : "She wears a fitted outfit tailored precisely to her form, clean elegant lines that contour her silhouette without feeling restrictive, vibrant refined colors that remain tasteful and balanced, smooth high quality fabric with a subtle sheen that responds beautifully to cinematic lighting, gentle highlights tracing the curves of the design, structured yet fluid tailoring that suggests confidence and poise, minimal but intentional detailing that enhances shape rather than overwhelming it, graceful sophistication with a modern feminine presence, sharper tailoring accents, confident color contrast that draws the eye without breaking elegance, \n Around her waist is a delicate waist chain, and a platinum diamond belly piercing. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 29-inch waist, and 36-inch hips. Her thighs are thick. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a aroused facial expression",
      "text"   : [
        "515",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "542"       : {
    "inputs"     : {
      "images" : [
        "1885",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "545"       : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.5,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "356",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "559"       : {
    "inputs"     : {
      "text" : "aidmafluxproultra, aidmaimageupgrader, sinfully stylish, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "560"       : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, moles, natural blemishes, Rough skin texture, Skin imperfections , "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "564"       : {
    "inputs"     : {
      "model_name" : "deepseek-ai/Janus-Pro-1B"
    },
    "class_type" : "JanusProModelLoader|Mie",
    "_meta"      : {
      "title" : "Janus Pro Model Loader üêë"
    }
  },
  "567"       : {
    "inputs"     : {
      "text" : "a professional digital Storybook Illustration art style of a shy and cute dark-skinned Indian v1dhya5 woman with  a extremely beautiful  face with (black bindi on the forehead:1.2), "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "568"       : {
    "inputs"     : {
      "text" : "A professionally color-graded RAW photograph of a shy sexy and alluring dark brown almond  skin tone Indian v1dhya5 woman with extremely beautiful face  with black bindi on the forehead, , photo taken using using a  high-end professional camera , posing glamorously like she is with her lover who is taking the photo,  \n\nThe makeup is minimal but bold and glamorous, featuring black bindi on the forehead and a dramatic eye makeup with dark eyeliner / kohl and mascara, along with defined eyebrows. Her sexy pouty lips are painted a vivid red   . Her lips are narrow, plump, and wet-looking, subtly curved for a sensual appearance., adding a touch of elegance and intensity to their appearance. The skin has a healthy glow, accentuated by subtle matte makeup techniques. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "570"       : {
    "inputs"     : {
      "text_0" : "Inputs/Next/IMG_20260102_110718_052.jpg",
      "text"   : [
        "1806",
        3
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "571"       : {
    "inputs"     : {
      "text1"     : "A dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.4), deep rich complexion with a scattering of freckles across cheeks and nose,",
      "text2"     : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry",
      "text3"     : "looking at the cameras,\ntranslucent   outfit with see though sleeves, showing the profile of the dark blue bra wearing with dark blue strap peeking outside.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "573"       : {
    "inputs"     : {
      "text_0" : "A professionally color-graded photograph of Indian v1dhya5 busty and curvy woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 24 years of age,,The photo shows a woman with long, wavy, dark hair wearing a sleeveless turquoise crop top. She is accessorized with a delicate gold chain necklace and a pair of glasses perched on her head. Her makeup is natural, highlighting her eyes and lips subtly. The background is neutral and blurred, focusing attention on the woman's attire and accessories.,Photograph of She wears a fitted outfit tailored precisely to her form, clean elegant lines that contour her silhouette without feeling restrictive, vibrant refined colors that remain tasteful and balanced, smooth high quality fabric with a subtle sheen that responds beautifully to cinematic lighting, gentle highlights tracing the curves of the design, structured yet fluid tailoring that suggests confidence and poise, minimal but intentional detailing that enhances shape rather than overwhelming it, graceful sophistication with a modern feminine presence, sharper tailoring accents, confident color contrast that draws the eye without breaking elegance, \n Around her waist is a delicate waist chain, and a platinum diamond belly piercing. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 29-inch waist, and 36-inch hips. Her thighs are thick. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a aroused facial expression. incorporating visible light sources within the scene. shot on Fujifilm X-T5. with highly saturated vivid colors",
      "text"   : [
        "788",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "581"       : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2609",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "832",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "622"       : {
    "inputs"     : {
      "float_value"    : [
        "2100",
        0
      ],
      "multiply_value" : 0.181818
    },
    "class_type" : "FloatMultiplication",
    "_meta"      : {
      "title" : "Float Multiplication"
    }
  },
  "623"       : {
    "inputs"     : {
      "value1" : 0.92,
      "value2" : 0.7
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "0.92::0.78"
    }
  },
  "650"       : {
    "inputs"     : {
      "text" : [
        "249",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "654"       : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2991:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "731"       : {
    "inputs"     : {
      "preprocessor" : "DWPreprocessor",
      "resolution"   : [
        "764",
        0
      ],
      "image"        : [
        "744",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "734"       : {
    "inputs"     : {
      "type"        : "openpose",
      "control_net" : [
        "2231",
        0
      ]
    },
    "class_type" : "SetUnionControlNetType",
    "_meta"      : {
      "title" : "SetUnionControlNetType"
    }
  },
  "735"       : {
    "inputs"     : {
      "conditioning" : [
        "736",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "736"       : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "CLIP Text Encode (Prompt)"
    }
  },
  "737"       : {
    "inputs"     : {
      "clip_l"   : [
        "2187",
        0
      ],
      "t5xxl"    : [
        "743",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "743"       : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "744"       : {
    "inputs"     : {
      "image" : [
        "2109",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "764"       : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "744",
        1
      ],
      "b"    : [
        "744",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "768"       : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.mp3",
      "any"    : [
        "122",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "788"       : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2105",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "826"       : {
    "inputs"     : {
      "mask" : [
        "829",
        1
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "828"       : {
    "inputs"     : {
      "width"  : 168,
      "height" : 38,
      "red"    : 0,
      "green"  : 0,
      "blue"   : 0
    },
    "class_type" : "Image Blank",
    "_meta"      : {
      "title" : "Image Blank"
    }
  },
  "829"       : {
    "inputs"     : {
      "text"             : [
        "1936",
        0
      ],
      "font"             : "SevenSegment.ttf",
      "size"             : 38,
      "color"            : "#b66244FF",
      "background_color" : "#00000000",
      "shadow_distance"  : 0,
      "shadow_blur"      : 0,
      "shadow_color"     : "#ADADAD",
      "horizontal_align" : "right",
      "vertical_align"   : "bottom",
      "offset_x"         : -4,
      "offset_y"         : -2,
      "direction"        : "ltr",
      "img_composite"    : [
        "828",
        0
      ]
    },
    "class_type" : "DrawText+",
    "_meta"      : {
      "title" : "üîß Draw Text"
    }
  },
  "832"       : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "bilinear",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : [
        "1937",
        0
      ],
      "y_offset"       : [
        "1938",
        0
      ],
      "rotation"       : -90,
      "opacity"        : 0,
      "base_image"     : [
        "1585",
        0
      ],
      "overlay_image"  : [
        "829",
        0
      ],
      "optional_mask"  : [
        "826",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "840"       : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1918",
        0
      ],
      "b"          : [
        "1595",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "897"       : {
    "inputs"     : {
      "text1"     : "detailed fabric texture",
      "text2"     : [
        "485",
        0
      ],
      "text3"     : "slightly translucent elements in the intricate outfit with see though sleeves, showing the profile of the 36DD Cup size  bra wearing underneath.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "898"       : {
    "inputs"     : {
      "invert_mask" : true,
      "grow"        : -5,
      "blur"        : 4,
      "mask"        : [
        "104",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "931"       : {
    "inputs"     : {
      "any_01" : [
        "2403",
        0
      ],
      "any_02" : [
        "2339",
        0
      ],
      "any_03" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "950"       : {
    "inputs"     : {
      "text" : "professionally color-graded RAW photograph, __AGE__ Indian v1dhya5  woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen, low muscle definition, soft natural curves  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "953"       : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2595",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1267"      : {
    "inputs"     : {
      "any_01" : [
        "2704",
        0
      ],
      "any_02" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1271"      : {
    "inputs"     : {
      "upscale_method"   : "lanczos",
      "megapixels"       : 1.5000000000000002,
      "resolution_steps" : 1,
      "image"            : [
        "2109",
        0
      ]
    },
    "class_type" : "ImageScaleToTotalPixels",
    "_meta"      : {
      "title" : "ImageScaleToTotalPixels"
    }
  },
  "1281"      : {
    "inputs"     : {
      "preview"     : "",
      "previewMode" : null,
      "source"      : [
        "245",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1282"      : {
    "inputs"     : {
      "preview"     : "",
      "previewMode" : null,
      "source"      : [
        "242",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1283"      : {
    "inputs"     : {
      "preview"     : "",
      "previewMode" : null,
      "source"      : [
        "249",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1284"      : {
    "inputs"     : {
      "preview"     : "",
      "previewMode" : null,
      "source"      : [
        "253",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1285"      : {
    "inputs"     : {
      "preview"     : "+",
      "previewMode" : null,
      "source"      : [
        "296",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1286"      : {
    "inputs"     : {
      "preview"     : "+",
      "previewMode" : null,
      "source"      : [
        "293",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1287"      : {
    "inputs"     : {
      "preview"     : "False",
      "previewMode" : null,
      "source"      : [
        "235",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1288"      : {
    "inputs"     : {
      "preview"     : "0.7",
      "previewMode" : null,
      "source"      : [
        "2100",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1289"      : {
    "inputs"     : {
      "preview"     : "0.56",
      "previewMode" : null,
      "source"      : [
        "2102",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1294"      : {
    "inputs"     : {
      "preview"     : "0.12727259999999999",
      "previewMode" : null,
      "source"      : [
        "622",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1295"      : {
    "inputs"     : {
      "preview"     : "0",
      "previewMode" : null,
      "source"      : [
        "2103",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1306"      : {
    "inputs"     : {
      "preview"     : "0",
      "previewMode" : null,
      "source"      : [
        "1595",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1318"      : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "897",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1331"      : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1343"      : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (vertical, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1344"      : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (horizontal, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1345"      : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "$$",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "1354"      : {
    "inputs"     : {
      "preview"     : "True",
      "previewMode" : null,
      "source"      : [
        "124",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1357"      : {
    "inputs"     : {
      "lut_name" : "Presetpro  - Kodacrome 64.cube",
      "strength" : 0.27,
      "log"      : true,
      "image"    : [
        "931",
        0
      ]
    },
    "class_type" : "ProPostApplyLUT",
    "_meta"      : {
      "title" : "ProPostApplyLUT"
    }
  },
  "1366"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pgabe_00001_.png&type=temp&subfolder=&rand=0.5069109285246239"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pgabe_00002_.png&type=temp&subfolder=&rand=0.8772520949476388"
          }
        ]
      },
      "image_a"          : [
        "1400",
        0
      ],
      "image_b"          : [
        "2675",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1386"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_cgexd_00001_.png&type=temp&subfolder=&rand=0.6684385287981397"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_cgexd_00002_.png&type=temp&subfolder=&rand=0.06410436140935738"
          }
        ]
      },
      "image_a"          : [
        "2930",
        0
      ],
      "image_b"          : [
        "1831",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1390"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zritr_00001_.png&type=temp&subfolder=&rand=0.0019372459279360932"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zritr_00002_.png&type=temp&subfolder=&rand=0.5635615166686277"
          }
        ]
      },
      "image_a"          : [
        "2675",
        0
      ],
      "image_b"          : [
        "1831",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1400"      : {
    "inputs"     : {
      "brightness" : 0.93,
      "contrast"   : 1.16,
      "saturation" : 1,
      "image"      : [
        "2675",
        0
      ]
    },
    "class_type" : "LayerColor: BrightnessContrastV2",
    "_meta"      : {
      "title" : "Brightness Contrast V2"
    }
  },
  "1405"      : {
    "inputs"     : {
      "value" : 1.2
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "<<Speed - Accuracy>> (default 0.9)"
    }
  },
  "1412"      : {
    "inputs"     : {
      "strength"      : 0.6,
      "start_percent" : 0,
      "end_percent"   : 0.6,
      "positive"      : [
        "737",
        0
      ],
      "negative"      : [
        "735",
        0
      ],
      "control_net"   : [
        "734",
        0
      ],
      "image"         : [
        "731",
        0
      ],
      "vae"           : [
        "2889",
        0
      ]
    },
    "class_type" : "ControlNetApplyAdvanced",
    "_meta"      : {
      "title" : "Apply ControlNet"
    }
  },
  "1479"      : {
    "inputs"     : {
      "text" : " , Skin imperfections ,    natural blemishes, Rough skin texture, d351 d4rk, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "1495"      : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1496"      : {
    "inputs"     : {
      "images" : [
        "2339",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1497"      : {
    "inputs"     : {
      "images" : [
        "2158",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1498"      : {
    "inputs"     : {
      "images" : [
        "2117",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1517"      : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "1566"      : {
    "inputs"     : {
      "any_01" : [
        "2321",
        0
      ],
      "any_02" : [
        "2930",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1585"      : {
    "inputs"     : {
      "radius"          : 0.7,
      "amount"          : 1.2,
      "reduce_noise"    : 0.15,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0.2,
      "image"           : [
        "1357",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "Nettet√© optimis√©e"
    }
  },
  "1595"      : {
    "inputs"     : {
      "expression" : "c*(a-b)",
      "a"          : [
        "290",
        0
      ],
      "b"          : [
        "294",
        0
      ],
      "c"          : [
        "295",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1611"      : {
    "inputs"     : {
      "any_01" : [
        "2849",
        0
      ],
      "any_02" : [
        "2339",
        0
      ],
      "any_03" : [
        "2065",
        0
      ],
      "any_04" : [
        "654",
        0
      ],
      "any_05" : [
        "2704",
        0
      ],
      "any_06" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1615"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_apmua_00001_.png&type=temp&subfolder=&rand=0.8002829878466371"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_apmua_00002_.png&type=temp&subfolder=&rand=0.3280859279487758"
          }
        ]
      },
      "image_a"          : [
        "2669",
        0
      ],
      "image_b"          : [
        "1837",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1616"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ppuzy_00001_.png&type=temp&subfolder=&rand=0.9922811887171574"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ppuzy_00002_.png&type=temp&subfolder=&rand=0.20915817364447198"
          }
        ]
      },
      "image_a"          : [
        "1831",
        0
      ],
      "image_b"          : [
        "356",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1617"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kzpia_00055_.png&type=temp&subfolder=&rand=0.9822139289141751"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_kzpia_00056_.png&type=temp&subfolder=&rand=0.29177771414006304"
          }
        ]
      },
      "image_a"          : [
        "3014:548",
        0
      ],
      "image_b"          : [
        "1611",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1619"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pjrbs_00061_.png&type=temp&subfolder=&rand=0.03940512681769548"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_pjrbs_00062_.png&type=temp&subfolder=&rand=0.2805135452457138"
          }
        ]
      },
      "image_a"          : [
        "832",
        0
      ],
      "image_b"          : [
        "2109",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1621"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yeiot_00001_.png&type=temp&subfolder=&rand=0.29326667562515407"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_yeiot_00002_.png&type=temp&subfolder=&rand=0.07565505672698969"
          }
        ]
      },
      "image_a"          : [
        "2991:548",
        0
      ],
      "image_b"          : [
        "1267",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1629"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_eojfn_00001_.png&type=temp&subfolder=&rand=0.8639337716055729"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_eojfn_00002_.png&type=temp&subfolder=&rand=0.46531344148419673"
          }
        ]
      },
      "image_a"          : [
        "2704",
        0
      ],
      "image_b"          : [
        "1885",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1636"      : {
    "inputs"     : {
      "image" : [
        "931",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1637"      : {
    "inputs"     : {
      "value" : 0.56
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Color_Correct"
    }
  },
  "1710"      : {
    "inputs"     : {
      "value" : 1.58
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1740"      : {
    "inputs"     : {
      "value" : 1.33
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1803"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : 1085808389286411
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1805"      : {
    "inputs"     : {
      "directory_path"    : "Inputs/Next",
      "patterns"          : "*.jpg|*.png|*.jpeg",
      "rescan_each_queue" : true
    },
    "class_type" : "FileCounter|LP",
    "_meta"      : {
      "title" : "File Counter [LP]"
    }
  },
  "1806"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -914014803932838
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1807"      : {
    "inputs"     : {
      "any" : [
        "1803",
        0
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "1812"      : {
    "inputs"     : {
      "boolean" : [
        "1807",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "1813"      : {
    "inputs"     : {
      "OutputDirectory" : "Inputs/Processed",
      "OverwriteFile"   : [
        "124",
        0
      ],
      "FilePaths"       : [
        "1838",
        0
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1814"      : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1805",
        0
      ],
      "b"          : [
        "1924",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1815"      : {
    "inputs"     : {
      "text_0" : "Inputs/Next",
      "text"   : [
        "1806",
        2
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1817"      : {
    "inputs"     : {
      "text_0" : "Inputs/Next/",
      "text"   : [
        "1818",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1818"      : {
    "inputs"     : {
      "string_a"  : "Inputs/Next",
      "string_b"  : [
        "1806",
        4
      ],
      "delimiter" : "/"
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "1819"      : {
    "inputs"     : {
      "condition"  : [
        "1814",
        0
      ],
      "when_true"  : [
        "1818",
        0
      ],
      "when_false" : [
        "1806",
        2
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1820"      : {
    "inputs"     : {
      "OutputDirectory" : [
        "1819",
        0
      ],
      "OverwriteFile"   : true,
      "FilePaths"       : [
        "1806",
        3
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1823"      : {
    "inputs"     : {
      "text_0" : "Inputs/Next/IMG_20260102_110920_132.jpg",
      "text"   : [
        "1803",
        3
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "1831"      : {
    "inputs"     : {
      "condition"  : [
        "193",
        0
      ],
      "when_true"  : [
        "1343",
        0
      ],
      "when_false" : [
        "1344",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1832"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "sequential_by_modified_date",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -617470038987938
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1835"      : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1941",
        0
      ],
      "b"          : [
        "1925",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1837"      : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        0
      ],
      "when_false" : [
        "1832",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1838"      : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        3
      ],
      "when_false" : [
        "1832",
        3
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1848"      : {
    "inputs"     : {
      "megapixel"     : "1.8",
      "divisible_by"  : "8",
      "mode"          : "pad",
      "delta_percent" : [
        "2532",
        0
      ],
      "image"         : [
        "1913",
        0
      ]
    },
    "class_type" : "Image_Preparations",
    "_meta"      : {
      "title" : "Image Preparations"
    }
  },
  "1855"      : {
    "inputs"     : {
      "expression" : "b+(a-0.46)*(24-b)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1856"      : {
    "inputs"     : {
      "expression" : "c+(a-0.46)*(35-c)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1857"      : {
    "inputs"     : {},
    "class_type" : "DisableNoise",
    "_meta"      : {
      "title" : "DisableNoise"
    }
  },
  "1858"      : {
    "inputs"     : {
      "noise_seed" : [
        "2240",
        0
      ]
    },
    "class_type" : "RandomNoise",
    "_meta"      : {
      "title" : "RandomNoise"
    }
  },
  "1859"      : {
    "inputs"     : {
      "model"        : [
        "1899",
        0
      ],
      "conditioning" : [
        "2108",
        0
      ]
    },
    "class_type" : "BasicGuider",
    "_meta"      : {
      "title" : "BasicGuider"
    }
  },
  "1860"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : [
        "1893",
        0
      ],
      "denoise"   : [
        "2541",
        0
      ],
      "model"     : [
        "1899",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "1863"      : {
    "inputs"     : {
      "noise"        : [
        "1858",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2957",
        0
      ],
      "sigmas"       : [
        "1877",
        0
      ],
      "latent_image" : [
        "1989",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler1"
    }
  },
  "1869"      : {
    "inputs"     : {
      "preview"     : "0.494",
      "previewMode" : null,
      "source"      : [
        "2541",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "1870"      : {
    "inputs"     : {
      "noise"        : [
        "1857",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2666",
        0
      ],
      "sigmas"       : [
        "1877",
        1
      ],
      "latent_image" : [
        "2964",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler2"
    }
  },
  "1871"      : {
    "inputs"     : {
      "noise_seed"     : [
        "2212",
        0
      ],
      "noise_strength" : 1.3,
      "normalize"      : "false",
      "latent"         : [
        "1863",
        0
      ]
    },
    "class_type" : "InjectLatentNoise+",
    "_meta"      : {
      "title" : "üîß Inject Latent Noise"
    }
  },
  "1877"      : {
    "inputs"     : {
      "denoise" : [
        "1944",
        0
      ],
      "sigmas"  : [
        "1860",
        0
      ]
    },
    "class_type" : "SplitSigmasDenoise",
    "_meta"      : {
      "title" : "SplitSigmasDenoise"
    }
  },
  "1885"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1934",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "3018",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "1888"      : {
    "inputs"     : {
      "samples" : [
        "1870",
        1
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "1889"      : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.wav",
      "any"    : [
        "1885",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "1892"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_apaxu_00001_.png&type=temp&subfolder=&rand=0.6527276417190424"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_apaxu_00002_.png&type=temp&subfolder=&rand=0.42533440583787385"
          }
        ]
      },
      "image_a"          : [
        "3018",
        0
      ],
      "image_b"          : [
        "2669",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "1893"      : {
    "inputs"     : {
      "expression" : "1.3*(a+c*(b-a))",
      "a"          : [
        "1855",
        0
      ],
      "b"          : [
        "1856",
        0
      ],
      "c"          : [
        "1405",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1899"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.45"
    }
  },
  "1902"      : {
    "inputs"     : {
      "value1" : 28,
      "value2" : 42
    },
    "class_type" : "SeargeIntegerPair",
    "_meta"      : {
      "title" : "Range (31:43)"
    }
  },
  "1909"      : {
    "inputs"     : {
      "dishonesty_factor" : -0.01,
      "start_percent"     : 0.25,
      "end_percent"       : 0.5,
      "sampler"           : [
        "2957",
        0
      ]
    },
    "class_type" : "LyingSigmaSampler",
    "_meta"      : {
      "title" : "Lying Sigma Sampler"
    }
  },
  "1913"      : {
    "inputs"     : {
      "image" : [
        "1837",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1918"      : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1919"      : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1920"      : {
    "inputs"     : {
      "value" : 1
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1921"      : {
    "inputs"     : {
      "value" : 20
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1922"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "1923",
        0
      ],
      "b"    : [
        "2544",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1923"      : {
    "inputs"     : {
      "value" : 15
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "15"
    }
  },
  "1924"      : {
    "inputs"     : {
      "value" : -268
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "One"
    }
  },
  "1925"      : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1926"      : {
    "inputs"     : {
      "value" : 1024
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1927"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "389",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1928"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "146",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1930"      : {
    "inputs"     : {
      "file_prefix"   : [
        "1932",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1931"      : {
    "inputs"     : {
      "int_" : [
        "143",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "1932"      : {
    "inputs"     : {
      "text1" : "Detailed_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1933"      : {
    "inputs"     : {
      "text1" : "AfterPass02_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1934"      : {
    "inputs"     : {
      "file_prefix"   : [
        "1933",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1936"      : {
    "inputs"     : {
      "file_prefix"   : "",
      "time_format"   : "%-d %-m %y",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1937"      : {
    "inputs"     : {
      "a"         : [
        "1636",
        1
      ],
      "b"         : -38,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1938"      : {
    "inputs"     : {
      "a"         : [
        "1636",
        2
      ],
      "b"         : -168,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1941"      : {
    "inputs"     : {
      "min" : 1,
      "max" : 10
    },
    "class_type" : "RandomInt",
    "_meta"      : {
      "title" : "Random Int"
    }
  },
  "1942"      : {
    "inputs"     : {
      "mode" : false,
      "a"    : [
        "478",
        1
      ],
      "b"    : [
        "478",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1944"      : {
    "inputs"     : {
      "float_1" : 0.58,
      "float_2" : 0.9992
    },
    "class_type" : "TwoFloats",
    "_meta"      : {
      "title" : "<<Rough - Smooth>> (default 0.58)"
    }
  },
  "1945"      : {
    "inputs"     : {
      "text" : "She wears a fitted outfit tailored precisely to her form, clean elegant lines that contour her silhouette without feeling restrictive, vibrant refined colors that remain tasteful and balanced, smooth high quality fabric with a subtle sheen that responds beautifully to cinematic lighting, gentle highlights tracing the curves of the design, structured yet fluid tailoring that suggests confidence and poise, minimal but intentional detailing that enhances shape rather than overwhelming it, graceful sophistication with a modern feminine presence, sharper tailoring accents, confident color contrast that draws the eye without breaking elegance, \n Around her waist is a delicate waist chain, and a platinum diamond belly piercing. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 29-inch waist, and 36-inch hips. Her thighs are thick. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "1948"      : {
    "inputs"     : {
      "images" : [
        "731",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1955"      : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.98,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "1978"      : {
    "inputs"     : {
      "max_shift"  : 1.5,
      "base_shift" : 0.5,
      "width"      : [
        "445",
        1
      ],
      "height"     : [
        "445",
        2
      ],
      "model"      : [
        "2939",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "1988"      : {
    "inputs"     : {
      "clip_l"   : "captivating professional photo of v1dhya5 woman in a serene outdoor setting, the overall mood of the photograph is calm and introspective, capturing a moment of introspection or contemplation, \n\n32F_Cup",
      "t5xxl"    : [
        "788",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2936",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "1989"      : {
    "inputs"     : {
      "sampler_name" : "heun",
      "scheduler"    : "simple",
      "steps"        : 32,
      "denoise"      : [
        "1999",
        0
      ],
      "noise_seed"   : [
        "2240",
        0
      ],
      "model"        : [
        "1978",
        0
      ],
      "conditioning" : [
        "1988",
        0
      ],
      "latent_image" : [
        "154",
        0
      ]
    },
    "class_type" : "FluxSampler",
    "_meta"      : {
      "title" : "Flux Sampler : Pass 01"
    }
  },
  "1999"      : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.49,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2011"      : {
    "inputs"     : {
      "text" : "aidmaimageupgrader"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2034"      : {
    "inputs"     : {
      "any_01" : [
        "2065",
        0
      ],
      "any_02" : [
        "654",
        0
      ],
      "any_03" : [
        "2704",
        0
      ],
      "any_04" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2035"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2034",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2038"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_uuocm_00055_.png&type=temp&subfolder=&rand=0.9465659376093697"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_uuocm_00056_.png&type=temp&subfolder=&rand=0.7103740921436956"
          }
        ]
      },
      "image_a"          : [
        "2995:548",
        0
      ],
      "image_b"          : [
        "2034",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2047"      : {
    "inputs"     : {
      "conditioning" : [
        "2048",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2048"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2890",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2053"      : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "496",
        0
      ],
      "text2"     : [
        "2054",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2054"      : {
    "inputs"     : {
      "string_a"  : [
        "788",
        0
      ],
      "string_b"  : [
        "1318",
        0
      ],
      "delimiter" : ","
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "2058"      : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "2060"      : {
    "inputs"     : {
      "strength"           : 0.8,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "2067",
        0
      ],
      "style_model"        : [
        "2058",
        0
      ],
      "clip_vision_output" : [
        "2063",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "2062"      : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "2063"      : {
    "inputs"     : {
      "crop"        : "none",
      "clip_vision" : [
        "2062",
        0
      ],
      "image"       : [
        "2925",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "2065"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2085",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2066"      : {
    "inputs"     : {
      "any_01" : [
        "654",
        0
      ],
      "any_02" : [
        "2704",
        0
      ],
      "any_03" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2067"      : {
    "inputs"     : {
      "clip_l"   : [
        "2088",
        0
      ],
      "t5xxl"    : [
        "2053",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2890",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2072"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : true,
      "hair_mask"       : true,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2066",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2073"      : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskPreview+",
    "_meta"      : {
      "title" : "üîß Mask Preview"
    }
  },
  "2074"      : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2079"      : {
    "inputs"     : {
      "invert_mask" : true,
      "grow"        : -8,
      "blur"        : 5,
      "mask"        : [
        "2072",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2080"      : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2081"      : {
    "inputs"     : {
      "opacity"         : 50,
      "image"           : [
        "2066",
        0
      ],
      "color_ref_image" : [
        "2930",
        0
      ]
    },
    "class_type" : "LayerColor: ColorAdapter",
    "_meta"      : {
      "title" : "LayerColor: ColorAdapter"
    }
  },
  "2083"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_feeny_00003_.png&type=temp&subfolder=&rand=0.7797524098346647"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_feeny_00004_.png&type=temp&subfolder=&rand=0.9225440441173179"
          }
        ]
      },
      "image_a"          : [
        "2085",
        0
      ],
      "image_b"          : [
        "2066",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2085"      : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : true,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 26,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.37,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 1,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2081",
        0
      ],
      "segs"               : [
        "2074",
        0
      ],
      "model"              : [
        "2086",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2060",
        0
      ],
      "negative"           : [
        "2047",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Clothing Detailer)"
    }
  },
  "2086"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.75,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.5"
    }
  },
  "2088"      : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "496",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2100"      : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "343",
        0
      ],
      "when_false" : [
        "2101",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2101"      : {
    "inputs"     : {
      "condition"  : [
        "233",
        0
      ],
      "when_true"  : [
        "623",
        0
      ],
      "when_false" : [
        "623",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2102"      : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "342",
        0
      ],
      "when_false" : [
        "342",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2103"      : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1919",
        0
      ],
      "when_false" : [
        "2104",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2104"      : {
    "inputs"     : {
      "condition"  : [
        "840",
        0
      ],
      "when_true"  : [
        "331",
        0
      ],
      "when_false" : [
        "1595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2105"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "26",
        0
      ],
      "when_false" : [
        "2581",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2106"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "953",
        0
      ],
      "when_false" : [
        "2595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2108"      : {
    "inputs"     : {
      "condition"  : [
        "235",
        0
      ],
      "when_true"  : [
        "44",
        0
      ],
      "when_false" : [
        "1412",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2109"      : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1837",
        0
      ],
      "when_false" : [
        "1566",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2110"      : {
    "inputs"     : {
      "condition"  : [
        "275",
        0
      ],
      "when_true"  : [
        "362",
        0
      ],
      "when_false" : [
        "1922",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2111"      : {
    "inputs"     : {
      "condition"  : [
        "325",
        0
      ],
      "when_true"  : [
        "2164",
        0
      ],
      "when_false" : [
        "567",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2117"      : {
    "inputs"     : {
      "any_01" : [
        "654",
        0
      ],
      "any_02" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2152"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2153"      : {
    "inputs"     : {
      "mask" : [
        "2152",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2154"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2153",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2158"      : {
    "inputs"     : {
      "any_01" : [
        "2065",
        0
      ],
      "any_02" : [
        "2117",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2164"      : {
    "inputs"     : {
      "text" : "A professionally color-graded photograph of Indian v1dhya5 busty and curvy woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2178"      : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "2187"      : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : "(aidmarealisticskin:0.5)",
      "text3"     : " ",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2193"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 1,
      "blur"        : 0,
      "mask"        : [
        "55",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2197"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1400",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2198"      : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "nearest-exact",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : 0,
      "y_offset"       : 0,
      "rotation"       : 0,
      "opacity"        : 100,
      "base_image"     : [
        "2570",
        0
      ],
      "overlay_image"  : [
        "1400",
        0
      ],
      "optional_mask"  : [
        "2197",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "2200"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2201"      : {
    "inputs"     : {
      "mask" : [
        "2200",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2202"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2201",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2203"      : {
    "inputs"     : {
      "image" : [
        "2202",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2204"      : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2212"      : {
    "inputs"     : {
      "input1" : [
        "2240",
        0
      ],
      "input2" : 2048
    },
    "class_type" : "LogicUtil_LogicGateBitwiseXor",
    "_meta"      : {
      "title" : "LogicUtil_Bitwise Xor"
    }
  },
  "2213"      : {
    "inputs"     : {
      "clip_a"  : [
        "2644",
        1
      ],
      "clip_b"  : [
        "2276",
        1
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2224"      : {
    "inputs"     : {
      "model_a" : [
        "2254",
        0
      ],
      "model_b" : [
        "2276",
        0
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2226"      : {
    "inputs"     : {
      "preview"     : "True",
      "previewMode" : null,
      "source"      : [
        "325",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2231"      : {
    "inputs"     : {
      "control_net_name" : "flux_shakker_labs_union_pro-fp8_e4m3fn.safetensors"
    },
    "class_type" : "ControlNetLoader",
    "_meta"      : {
      "title" : "Load ControlNet Model"
    }
  },
  "2233"      : {
    "inputs"     : {
      "preview"     : "1112934668650393",
      "previewMode" : null,
      "source"      : [
        "2240",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2237"      : {
    "inputs"     : {
      "model_name" : "4x-UltraSharpV2.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2240"      : {
    "inputs"     : {
      "mode"       : true,
      "seed"       : 505696333836155,
      "fixed_seed" : 0
    },
    "class_type" : "SeedSelector",
    "_meta"      : {
      "title" : "Seed Selector"
    }
  },
  "2245"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2246"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2247"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2250"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2253"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2296",
        0
      ],
      "clip"           : [
        "2296",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2254"      : {
    "inputs"     : {
      "img_in."           : 1,
      "time_in."          : 1,
      "guidance_in"       : 1,
      "vector_in."        : 1,
      "txt_in."           : 1,
      "double_blocks.0."  : 1,
      "double_blocks.1."  : 1,
      "double_blocks.2."  : 1,
      "double_blocks.3."  : 1,
      "double_blocks.4."  : 1,
      "double_blocks.5."  : 1,
      "double_blocks.6."  : 1,
      "double_blocks.7."  : 1,
      "double_blocks.8."  : 1,
      "double_blocks.9."  : 1,
      "double_blocks.10." : 1,
      "double_blocks.11." : 1,
      "double_blocks.12." : 1,
      "double_blocks.13." : 1,
      "double_blocks.14." : 1,
      "double_blocks.15." : 1,
      "double_blocks.16." : 1,
      "double_blocks.17." : 1,
      "double_blocks.18." : 1,
      "single_blocks.0."  : 1,
      "single_blocks.1."  : 1,
      "single_blocks.2."  : 1,
      "single_blocks.3."  : 1,
      "single_blocks.4."  : 1,
      "single_blocks.5."  : 1,
      "single_blocks.6."  : 1,
      "single_blocks.7."  : 1,
      "single_blocks.8."  : 1,
      "single_blocks.9."  : 1,
      "single_blocks.10." : 1,
      "single_blocks.11." : 1,
      "single_blocks.12." : 1,
      "single_blocks.13." : 1,
      "single_blocks.14." : 1,
      "single_blocks.15." : 1,
      "single_blocks.16." : 1,
      "single_blocks.17." : 1,
      "single_blocks.18." : 1,
      "single_blocks.19." : 0,
      "single_blocks.20." : 0,
      "single_blocks.21." : 0,
      "single_blocks.22." : 0,
      "single_blocks.23." : 0,
      "single_blocks.24." : 0,
      "single_blocks.25." : 0,
      "single_blocks.26." : 0,
      "single_blocks.27." : 0,
      "single_blocks.28." : 0,
      "single_blocks.29." : 0,
      "single_blocks.30." : 0,
      "single_blocks.31." : 0,
      "single_blocks.32." : 0,
      "single_blocks.33." : 0,
      "single_blocks.34." : 0,
      "single_blocks.35." : 0,
      "single_blocks.36." : 0,
      "single_blocks.37." : 0,
      "final_layer."      : 1,
      "model1"            : [
        "2908",
        0
      ],
      "model2"            : [
        "2644",
        0
      ]
    },
    "class_type" : "ModelMergeFlux1",
    "_meta"      : {
      "title" : "ModelMergeFlux1"
    }
  },
  "2257"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.1,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2262"      : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.8000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2250",
        0
      ],
      "clip"           : [
        "2250",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2268"      : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 1.8,
      "strength_clip"  : 0.6,
      "model"          : [
        "2952",
        0
      ],
      "clip"           : [
        "2953",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2 [3.80::3.80]"
    }
  },
  "2269"      : {
    "inputs"     : {
      "lora_name"      : "aidmaImageUprader-FLUX-v0.3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2270",
        0
      ],
      "clip"           : [
        "2270",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2270"      : {
    "inputs"     : {
      "lora_name"      : "AntiBlur.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1.0000000000000002,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2273"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA ::0.8:0.2"
    }
  },
  "2275"      : {
    "inputs"     : {
      "lora_name"      : "flux_vividizer.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmafluxproultra"
    }
  },
  "2276"      : {
    "inputs"     : {
      "lora_name"      : "Illustration Comic book_(FLUX)_06.safetensors",
      "strength_model" : 0.66,
      "strength_clip"  : 1.0000000000000002,
      "model"          : [
        "2262",
        0
      ],
      "clip"           : [
        "2262",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2277"      : {
    "inputs"     : {
      "lora_name"      : "aidmaImageUprader-FLUX-v0.3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2275",
        0
      ],
      "clip"           : [
        "2275",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2291"      : {
    "inputs"     : {
      "clip_a"  : [
        "2293",
        1
      ],
      "clip_b"  : [
        "2729",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2292"      : {
    "inputs"     : {
      "model_a" : [
        "2293",
        0
      ],
      "model_b" : [
        "2729",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2293"      : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.8,
      "model"          : [
        "2246",
        0
      ],
      "clip"           : [
        "2246",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2296"      : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2247",
        0
      ],
      "clip"           : [
        "2247",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2300"      : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.2,
      "strength_clip"  : 1,
      "model"          : [
        "3007",
        0
      ],
      "clip"           : [
        "3007",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2 [3.80::3.80]"
    }
  },
  "2302"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 0.7,
      "model"          : [
        "2245",
        0
      ],
      "clip"           : [
        "2245",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Realism"
    }
  },
  "2304"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2305"      : {
    "inputs"     : {
      "conditioning" : [
        "2304",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2316"      : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2317",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2317"      : {
    "inputs"     : {
      "text1"     : "masterpiece professional potrait photograph of v1dhya5 indian",
      "text2"     : [
        "1479",
        0
      ],
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2319"      : {
    "inputs"     : {
      "max_shift"  : 1.15,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2875",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2320"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_mtaut_00001_.png&type=temp&subfolder=&rand=0.8460450637537089"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_mtaut_00002_.png&type=temp&subfolder=&rand=0.8286197319962696"
          }
        ]
      },
      "image_a"          : [
        "2321",
        0
      ],
      "image_b"          : [
        "2930",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2321"      : {
    "inputs"     : {
      "radius"          : 4,
      "amount"          : 0.8,
      "reduce_noise"    : 0.01,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0,
      "image"           : [
        "2332",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "SharpnessPro ¬∑ Nettet√© optimis√©e"
    }
  },
  "2325"      : {
    "inputs"     : {
      "detail_amount"      : 0.32,
      "start"              : 0.2,
      "end"                : 0.8,
      "bias"               : 0.5,
      "exponent"           : 1,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : false,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "2957",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2331"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 18,
      "denoise"   : 0.26,
      "model"     : [
        "2875",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2332"      : {
    "inputs"     : {
      "upscale_by"          : 1,
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 18,
      "cfg"                 : 1,
      "sampler_name"        : "euler",
      "scheduler"           : "beta",
      "denoise"             : 0.26,
      "mode_type"           : "Linear",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : false,
      "tiled_decode"        : false,
      "image"               : [
        "2930",
        0
      ],
      "model"               : [
        "2319",
        0
      ],
      "positive"            : [
        "2316",
        0
      ],
      "negative"            : [
        "2305",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2961",
        0
      ],
      "custom_sampler"      : [
        "2325",
        0
      ],
      "custom_sigmas"       : [
        "2331",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2339"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2996:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2345"      : {
    "inputs"     : {
      "any_01" : [
        "2987",
        0
      ],
      "any_02" : [
        "2065",
        0
      ],
      "any_03" : [
        "654",
        0
      ],
      "any_04" : [
        "2704",
        0
      ],
      "any_05" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2348"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_frsgj_00055_.png&type=temp&subfolder=&rand=0.4268260565118278"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_frsgj_00056_.png&type=temp&subfolder=&rand=0.9322961098429424"
          }
        ]
      },
      "image_a"          : [
        "2996:548",
        0
      ],
      "image_b"          : [
        "2345",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2355"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 2,
      "compute_device"  : "auto",
      "images"          : [
        "2345",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2365"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2403",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2371"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2372"      : {
    "inputs"     : {
      "conditioning" : [
        "2371",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2377"      : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2404",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2384"      : {
    "inputs"     : {
      "any_01" : [
        "3011",
        0
      ],
      "any_02" : [
        "2849",
        0
      ],
      "any_03" : [
        "2339",
        0
      ],
      "any_04" : [
        "2987",
        0
      ],
      "any_05" : [
        "2065",
        0
      ],
      "any_06" : [
        "654",
        0
      ],
      "any_07" : [
        "2704",
        0
      ],
      "any_08" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2390"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ocklz_00061_.png&type=temp&subfolder=&rand=0.2246351876570386"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_ocklz_00062_.png&type=temp&subfolder=&rand=0.2725785034559558"
          }
        ]
      },
      "image_a"          : [
        "2403",
        0
      ],
      "image_b"          : [
        "2384",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2393"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 18,
      "denoise"   : 0.24,
      "model"     : [
        "2224",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2398"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2403"      : {
    "inputs"     : {
      "upscale_by"          : [
        "1740",
        0
      ],
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 16,
      "cfg"                 : 1,
      "sampler_name"        : "euler_ancestral",
      "scheduler"           : "beta",
      "denoise"             : 0.26,
      "mode_type"           : "Chess",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : true,
      "tiled_decode"        : false,
      "image"               : [
        "2384",
        0
      ],
      "model"               : [
        "2398",
        0
      ],
      "positive"            : [
        "2377",
        0
      ],
      "negative"            : [
        "2372",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2961",
        0
      ],
      "custom_sampler"      : [
        "2957",
        0
      ],
      "custom_sigmas"       : [
        "2393",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2404"      : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2529"      : {
    "inputs"     : {
      "expression" : "max(a,b)/min(a,b)",
      "a"          : [
        "1913",
        1
      ],
      "b"          : [
        "1913",
        2
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "2532"      : {
    "inputs"     : {
      "condition"  : [
        "2535",
        0
      ],
      "when_true"  : [
        "2534",
        0
      ],
      "when_false" : [
        "2103",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2534"      : {
    "inputs"     : {
      "a"         : [
        "2103",
        0
      ],
      "b"         : 0.5,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2535"      : {
    "inputs"     : {
      "comparison" : "a >= b",
      "a"          : [
        "2529",
        0
      ],
      "b"          : [
        "2536",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "2536"      : {
    "inputs"     : {
      "value" : 1.72
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Float Constant"
    }
  },
  "2541"      : {
    "inputs"     : {
      "a"         : [
        "1955",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "0.72"
    }
  },
  "2543"      : {
    "inputs"     : {
      "int_" : [
        "2110",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "2544"      : {
    "inputs"     : {
      "text" : [
        "283",
        0
      ]
    },
    "class_type" : "JWStringToInteger",
    "_meta"      : {
      "title" : "String to Integer"
    }
  },
  "2545"      : {
    "inputs"     : {
      "strings"   : "Inputs/Next/Best\nInputs/Next/best",
      "multiline" : false,
      "select"    : 0
    },
    "class_type" : "ImpactStringSelector",
    "_meta"      : {
      "title" : "String Selector"
    }
  },
  "2552"      : {
    "inputs"     : {
      "preview"     : "Inputs/Next/Best",
      "previewMode" : null,
      "source"      : [
        "2545",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2553"      : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2555"      : {
    "inputs"     : {
      "text1"     : "The subject is having a ",
      "text2"     : [
        "513",
        0
      ],
      "text3"     : " facial expression",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2560"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2257",
        0
      ],
      "clip"           : [
        "2257",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Pandora-RAWr"
    }
  },
  "2567"      : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "TT",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [TT]"
    }
  },
  "2570"      : {
    "inputs"     : {
      "condition"  : [
        "2567",
        0
      ],
      "when_true"  : [
        "2154",
        0
      ],
      "when_false" : [
        "1831",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2579"      : {
    "inputs"     : {
      "preview"     : "_2 1 26",
      "previewMode" : null,
      "source"      : [
        "1936",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2580"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "249",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2581"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2580",
        0
      ],
      "text_b"           : [
        "484",
        0
      ],
      "text_c"           : [
        "2590",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2590"      : {
    "inputs"     : {
      "prompt"           : [
        "515",
        0
      ],
      "camera"           : "Fujifilm X-T5",
      "composition_shot" : "None",
      "time_of_day"      : "None",
      "color_grading"    : "Vivid",
      "lighting"         : "Practical Lighting",
      "environment"      : "None"
    },
    "class_type" : "Magic Photo Prompter ü™Ñ",
    "_meta"      : {
      "title" : "Magic Photo Prompter ü™Ñ"
    }
  },
  "2595"      : {
    "inputs"     : {
      "find"    : "__AGE__",
      "replace" : [
        "2598",
        0
      ],
      "text"    : [
        "950",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2598"      : {
    "inputs"     : {
      "string"  : "__{{ age }}__ years old ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "2599"      : {
    "inputs"     : {
      "text_0" : "professionally color-graded RAW photograph, 24 years old  Indian v1dhya5  woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen, low muscle definition, soft natural curves  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, ",
      "text"   : [
        "2106",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2605"      : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "788",
        0
      ],
      "text3"     : [
        "1318",
        0
      ],
      "delimiter" : "/n_________________________/n"
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "2608"      : {
    "inputs"     : {
      "text_0" : "professionally color-graded RAW photograph, 24 years old  Indian v1dhya5  woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen, low muscle definition, soft natural curves  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, /n_________________________/nA professionally color-graded photograph of Indian v1dhya5 busty and curvy woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 24 years of age,,The photo shows a woman wearing a traditional Indian saree with a white blouse. She has long, dark hair and is adorned with elaborate jewelry, including a necklace, earrings, bracelets, and a bangles. Her makeup is detailed, with dark eyeliner and lipstick. She is holding a small mirror and appears to be in the process of checking her hair or makeup. The background is a solid brown color, and the camera angle is slightly low and directed towards her, giving a close-up view of her outfit and accessories.,Photograph of She wears a fitted outfit tailored precisely to her form, clean elegant lines that contour her silhouette without feeling restrictive, vibrant refined colors that remain tasteful and balanced, smooth high quality fabric with a subtle sheen that responds beautifully to cinematic lighting, gentle highlights tracing the curves of the design, structured yet fluid tailoring that suggests confidence and poise, minimal but intentional detailing that enhances shape rather than overwhelming it, graceful sophistication with a modern feminine presence, sharper tailoring accents, confident color contrast that draws the eye without breaking elegance, \n Around her waist is a delicate waist chain, and a platinum diamond belly piercing. She is wearing a pendant with letter \"V\".\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 29-inch waist, and 36-inch hips. Her thighs are thick. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,,The subject is having a loving facial expression. incorporating visible light sources within the scene. shot on Fujifilm X-T5. with highly saturated vivid colors/n_________________________/ndetailed fabric texture,The outfit in the photo is a traditional Indian saree. It is primarily cream-colored with a reddish-brown border. The saree is draped elegantly, with the blouse visible. The blouse is white and appears to be a strapless design. The saree has a traditional embroidered pattern. The outfit is accessorized with large, intricately designed earrings and multiple bangles on the wrist. The jewelry and adornments add a touch of elegance and cultural significance to the attire.,slightly translucent elements in the intricate outfit with see though sleeves, showing the profile of the 36DD Cup size  bra wearing underneath.",
      "text"   : [
        "2605",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2609"      : {
    "inputs"     : {
      "file_prefix"   : [
        "2611",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2611"      : {
    "inputs"     : {
      "text1" : "Generated_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2612"      : {
    "inputs"     : {
      "file_prefix"   : [
        "2614",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2614"      : {
    "inputs"     : {
      "text1" : "Prompt_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2615"      : {
    "inputs"     : {
      "path"                    : "./output/[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2612",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "file_extension"          : ".txt",
      "encoding"                : "utf-8",
      "filename_suffix"         : "",
      "text"                    : [
        "2605",
        0
      ]
    },
    "class_type" : "Save Text File",
    "_meta"      : {
      "title" : "Save Text File"
    }
  },
  "2618"      : {
    "inputs"     : {
      "lora_name"      : "BreastShaper_splendid_droplets_Flux_v3.0-000009.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.2,
      "model"          : [
        "2253",
        0
      ],
      "clip"           : [
        "2253",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2644"      : {
    "inputs"     : {
      "lora_name"      : "Flux_Lora_32F_Breasts.safetensors",
      "strength_model" : 0.5,
      "strength_clip"  : 0.7,
      "model"          : [
        "2300",
        0
      ],
      "clip"           : [
        "2300",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Flux_Lora_32F_Breasts"
    }
  },
  "2652"      : {
    "inputs"     : {
      "text" : "aidmaimageupgrader, fluxenhancer, detailed hands, Perfect hand"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2655"      : {
    "inputs"     : {
      "lora_name"      : "Detailed_Hands-000001.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2224",
        0
      ],
      "clip"           : [
        "2213",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2656"      : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, slicked back hairstyle:1.2, high ponytail:1.3, pulled back hairstyle:1.2, Skin imperfections , Freckles, moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2666"      : {
    "inputs"     : {
      "detail_amount"      : 0.08,
      "start"              : 0.33,
      "end"                : 0.66,
      "bias"               : 0.5,
      "exponent"           : 0.8,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : true,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "1909",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2669"      : {
    "inputs"     : {
      "image" : [
        "2670",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2670"      : {
    "inputs"     : {
      "samples" : [
        "1989",
        0
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "2671"      : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2672"      : {
    "inputs"     : {
      "shadow_brightness"      : 0.88,
      "shadow_saturation"      : 1,
      "shadow_hue"             : 0,
      "shadow_level_offset"    : 0,
      "shadow_range"           : 0.25,
      "highlight_brightness"   : 0.97,
      "highlight_saturation"   : 1,
      "highlight_hue"          : 0,
      "highlight_level_offset" : 0,
      "highlight_range"        : 0.25,
      "image"                  : [
        "2198",
        0
      ]
    },
    "class_type" : "LayerColor: Color of Shadow & Highlight",
    "_meta"      : {
      "title" : "LayerColor: Color of Shadow & Highlight"
    }
  },
  "2675"      : {
    "inputs"     : {
      "strength"   : 100,
      "brightness" : 0,
      "contrast"   : 0,
      "saturation" : 0,
      "red"        : 27,
      "green"      : 17,
      "blue"       : 0,
      "mode"       : "RGB",
      "image"      : [
        "2570",
        0
      ]
    },
    "class_type" : "LayerColor: AutoAdjustV2",
    "_meta"      : {
      "title" : "LayerColor: AutoAdjust V2"
    }
  },
  "2695"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2273",
        0
      ],
      "clip"           : [
        "2273",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2703"      : {
    "inputs"     : {
      "image" : [
        "1885",
        0
      ]
    },
    "class_type" : "ImpactImageBatchToImageList",
    "_meta"      : {
      "title" : "Image Batch to Image List"
    }
  },
  "2704"      : {
    "inputs"     : {
      "images" : [
        "339",
        0
      ]
    },
    "class_type" : "ImageListToImageBatch",
    "_meta"      : {
      "title" : "Image List to Image Batch"
    }
  },
  "2715"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "3015",
        1
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2727"      : {
    "inputs"     : {
      "preprocessor" : "DepthAnythingPreprocessor",
      "resolution"   : [
        "1942",
        0
      ],
      "image"        : [
        "2703",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "2728"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zcpnk_00001_.png&type=temp&subfolder=&rand=0.7760729530277544"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_zcpnk_00002_.png&type=temp&subfolder=&rand=0.6444718839316198"
          }
        ]
      },
      "image_a"          : [
        "2727",
        0
      ],
      "image_b"          : [
        "482",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2729"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2302",
        0
      ],
      "clip"           : [
        "2302",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2734"      : {
    "inputs"     : {
      "question"          : "Describe the Facial expression of the subject, hair style, jewelry and outfit. Also, describe about  the make-up, eyes and lipstick",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 512,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "2736"      : {
    "inputs"     : {
      "text_0" : "The subject has a gentle and warm facial expression, with soft eyes and a subtle smile. Her hair is long and slightly wavy, falling over her shoulders. She is wearing a sleeveless turquoise crop top, accessorizing with a layered gold necklace and subtle makeup. Her lips are painted a light, glossy pink lipstick, complementing her overall look.",
      "text"   : [
        "2734",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2751"      : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2756",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2753"      : {
    "inputs"     : {
      "text_0" : "A professionally color-graded photograph of Indian v1dhya5 busty and curvy woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,,the subject is portrayed at 24 years of age,,The subject's facial expression is neutral and composed, with a slight smile. The eyes are almond-shaped and have a natural, slightly enhanced look, complemented by well-defined eyebrows. The lips are painted with a glossy, dark lipstick, adding a touch of elegance. The makeup is subtle yet polished, with emphasis on the eyes and lips.",
      "text"   : [
        "2754",
        0
      ]
    },
    "class_type" : "ShowText|pysssss",
    "_meta"      : {
      "title" : "Show Text üêç"
    }
  },
  "2754"      : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2755",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2755"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "2751",
        0
      ],
      "when_false" : [
        "2756",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2756"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "2734",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2797"      : {
    "inputs"     : {
      "any_01" : [
        "2339",
        0
      ],
      "any_02" : [
        "2065",
        0
      ],
      "any_03" : [
        "654",
        0
      ],
      "any_04" : [
        "2704",
        0
      ],
      "any_05" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2814"      : {
    "inputs"     : {
      "image" : [
        "2797",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2815"      : {
    "inputs"     : {
      "face"            : false,
      "left_eyebrow"    : true,
      "right_eyebrow"   : true,
      "left_eye"        : true,
      "right_eye"       : true,
      "left_pupil"      : false,
      "right_pupil"     : false,
      "lips"            : true,
      "number_of_faces" : 1,
      "confidence"      : 0.3,
      "refine_mask"     : false,
      "images"          : [
        "2826",
        0
      ]
    },
    "class_type" : "APersonFaceLandmarkMaskGenerator",
    "_meta"      : {
      "title" : "Face Landmark Mask"
    }
  },
  "2816"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 2,
      "compute_device"  : "auto",
      "images"          : [
        "2797",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2818"      : {
    "inputs"     : {
      "mask_opacity" : 0.6,
      "mask_color"   : "255, 0, 25507",
      "pass_through" : false,
      "image"        : [
        "2826",
        0
      ],
      "mask"         : [
        "2830",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2819"      : {
    "inputs"     : {
      "images" : [
        "2820",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2820"      : {
    "inputs"     : {
      "mask" : [
        "2830",
        0
      ]
    },
    "class_type" : "MaskToImage",
    "_meta"      : {
      "title" : "Convert Mask to Image"
    }
  },
  "2822"      : {
    "inputs"     : {
      "padding"        : 0,
      "blur"           : 0,
      "mask"           : [
        "2816",
        0
      ],
      "image_optional" : [
        "2797",
        0
      ]
    },
    "class_type" : "MaskBoundingBox+",
    "_meta"      : {
      "title" : "üîß Mask Bounding Box"
    }
  },
  "2823"      : {
    "inputs"     : {
      "images" : [
        "2824",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2824"      : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "nearest-exact",
      "rescale_factor" : 1,
      "width"          : [
        "2822",
        4
      ],
      "height"         : [
        "2822",
        5
      ],
      "x_offset"       : [
        "2822",
        2
      ],
      "y_offset"       : [
        "2822",
        3
      ],
      "rotation"       : 0,
      "opacity"        : 0,
      "base_image"     : [
        "2825",
        0
      ],
      "overlay_image"  : [
        "2820",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "2825"      : {
    "inputs"     : {
      "width"  : [
        "2814",
        1
      ],
      "height" : [
        "2814",
        2
      ],
      "red"    : 0,
      "green"  : 0,
      "blue"   : 0
    },
    "class_type" : "Image Blank",
    "_meta"      : {
      "title" : "Image Blank"
    }
  },
  "2826"      : {
    "inputs"     : {
      "padding_left"   : 0,
      "padding_right"  : 0,
      "padding_top"    : 0,
      "padding_bottom" : 0,
      "return_list"    : false,
      "image"          : [
        "2797",
        0
      ],
      "mask"           : [
        "2816",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2827"      : {
    "inputs"     : {
      "mask_opacity" : 0.58,
      "mask_color"   : "255, 0, 25507",
      "pass_through" : false,
      "image"        : [
        "2797",
        0
      ],
      "mask"         : [
        "2829",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2829"      : {
    "inputs"     : {
      "red"       : 255,
      "green"     : 255,
      "blue"      : 255,
      "threshold" : 0,
      "image"     : [
        "2824",
        0
      ]
    },
    "class_type" : "MaskFromColor+",
    "_meta"      : {
      "title" : "üîß Mask From Color"
    }
  },
  "2830"      : {
    "inputs"     : {
      "expand"          : 8,
      "tapered_corners" : true,
      "mask"            : [
        "2815",
        0
      ]
    },
    "class_type" : "GrowMask",
    "_meta"      : {
      "title" : "Grow Mask"
    }
  },
  "2843"      : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 0.62,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2846"      : {
    "inputs"     : {
      "text1"     : [
        "2754",
        0
      ],
      "text2"     : "Her lips glisten softly with moisture, her eyes luminous and tender, as if holding a quiet breath between them.Red Lipstick, well-defined eyebrows, long eyelashes, (aidmarealisticskin:0.5)",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2847"      : {
    "inputs"     : {
      "text1"     : [
        "2754",
        0
      ],
      "text2"     : "well-defined eyebrows, long eyelashes, , Her lips glisten softly with moisture, her eyes luminous and tender, as if holding a quiet breath between them.",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2849"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2998:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2855"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_uxkga_00003_.png&type=temp&subfolder=&rand=0.027893837236416363"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_uxkga_00004_.png&type=temp&subfolder=&rand=0.563728378176338"
          }
        ]
      },
      "image_a"          : [
        "2998:548",
        0
      ],
      "image_b"          : [
        "2797",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "2862"      : {
    "inputs"     : {
      "text" : "aidmafluxproultra, fluxenhancer, Skin imperfections ,   moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2866"      : {
    "inputs"     : {
      "model_a" : [
        "2952",
        0
      ],
      "model_b" : [
        "2268",
        0
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2867"      : {
    "inputs"     : {
      "clip_a"  : [
        "2953",
        0
      ],
      "clip_b"  : [
        "2268",
        1
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2869"      : {
    "inputs"     : {
      "preview"     : "False",
      "previewMode" : null,
      "source"      : [
        "241",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2874"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2277",
        0
      ],
      "clip"           : [
        "2277",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2875"      : {
    "inputs"     : {
      "lora_name"      : "d351_Coffee_Krea_Kohya_V1_Unchained_prodigy-000012.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2618",
        0
      ],
      "clip"           : [
        "2618",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2881"      : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 2.6,
      "strength_clip"  : 1,
      "model"          : [
        "2695",
        0
      ],
      "clip"           : [
        "2695",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2 [3.20::3.20]"
    }
  },
  "2888"      : {
    "inputs"     : {
      "stop_at_clip_layer" : -3,
      "clip"               : [
        "2893",
        0
      ]
    },
    "class_type" : "CLIPSetLastLayer",
    "_meta"      : {
      "title" : "CLIP Set Last Layer"
    }
  },
  "2889"      : {
    "inputs"     : {
      "vae_name" : "ae.safetensors"
    },
    "class_type" : "VAELoader",
    "_meta"      : {
      "title" : "FLUX VAE"
    }
  },
  "2890"      : {
    "inputs"     : {
      "q"    : 1.2,
      "k"    : 1.1,
      "v"    : 0.8,
      "out"  : 1.25,
      "clip" : [
        "2888",
        0
      ]
    },
    "class_type" : "CLIPAttentionMultiply",
    "_meta"      : {
      "title" : "CLIPAttentionMultiply"
    }
  },
  "2891"      : {
    "inputs"     : {
      "block_number"         : 4,
      "downscale_factor"     : 2,
      "start_percent"        : 0,
      "end_percent"          : 0.5,
      "downscale_after_skip" : true,
      "downscale_method"     : "bislerp",
      "upscale_method"       : "bislerp",
      "model"                : [
        "2894",
        0
      ]
    },
    "class_type" : "PatchModelAddDownscale",
    "_meta"      : {
      "title" : "PatchModelAddDownscale"
    }
  },
  "2892"      : {
    "inputs"     : {
      "sampler_name" : "euler_ancestral"
    },
    "class_type" : "KSamplerSelect",
    "_meta"      : {
      "title" : "KSamplerSelect"
    }
  },
  "2893"      : {
    "inputs"     : {
      "clip_name1" : "clip_l.safetensors",
      "clip_name2" : "t5xxl_fp16.safetensors",
      "type"       : "flux",
      "device"     : "cpu"
    },
    "class_type" : "DualCLIPLoader",
    "_meta"      : {
      "title" : "DualCLIPLoader"
    }
  },
  "2894"      : {
    "inputs"     : {
      "unet_name"    : "flux1-dev.safetensors",
      "weight_dtype" : "fp8_e4m3fn"
    },
    "class_type" : "UNETLoader",
    "_meta"      : {
      "title" : "Load Diffusion Model"
    }
  },
  "2901"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2904"      : {
    "inputs"     : {
      "preview"     : "1032",
      "previewMode" : null,
      "source"      : [
        "394",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2905"      : {
    "inputs"     : {
      "preview"     : "1816",
      "previewMode" : null,
      "source"      : [
        "394",
        1
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2908"      : {
    "inputs"     : {
      "lora_name"      : "SameFace_Fix.safetensors",
      "strength_model" : -0.6,
      "strength_clip"  : 1,
      "model"          : [
        "2560",
        0
      ],
      "clip"           : [
        "2560",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "SameFaceNegatice"
    }
  },
  "2919"      : {
    "inputs"     : {
      "preview"     : "0",
      "previewMode" : null,
      "source"      : [
        "2532",
        0
      ]
    },
    "class_type" : "PreviewAny",
    "_meta"      : {
      "title" : "Preview as Text"
    }
  },
  "2922"      : {
    "inputs"     : {
      "images" : [
        "2925",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2925"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1837",
        0
      ],
      "mask"           : [
        "2927",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2927"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : true,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1837",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2929"      : {
    "inputs"     : {
      "channel"            : "RGB",
      "input_black_point"  : 0,
      "input_gamma"        : 1.1,
      "input_white_point"  : 1,
      "output_black_point" : 0,
      "output_white_point" : 1,
      "image"              : [
        "2672",
        0
      ]
    },
    "class_type" : "Levels",
    "_meta"      : {
      "title" : "Levels"
    }
  },
  "2930"      : {
    "inputs"     : {
      "brightness_target"   : 0.5,
      "cyan_red"            : 0.02,
      "magenta_green"       : 0,
      "yellow_blue"         : 0.05,
      "preserve_luminosity" : true,
      "image"               : [
        "2929",
        0
      ]
    },
    "class_type" : "ColorBalanceAdvanced",
    "_meta"      : {
      "title" : "Color Balance Advanced"
    }
  },
  "2931"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "3020",
        0
      ],
      "clip"           : [
        "3020",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2936"      : {
    "inputs"     : {
      "clip_a"  : [
        "2940",
        1
      ],
      "clip_b"  : [
        "2931",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2939"      : {
    "inputs"     : {
      "model_a" : [
        "2940",
        0
      ],
      "model_b" : [
        "2931",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2940"      : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.8,
      "model"          : [
        "2941",
        0
      ],
      "clip"           : [
        "2941",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2941"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA ::0.8:0.2"
    }
  },
  "2945"      : {
    "inputs"     : {
      "model_a" : [
        "2277",
        0
      ],
      "model_b" : [
        "2874",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2946"      : {
    "inputs"     : {
      "clip_a"  : [
        "2277",
        1
      ],
      "clip_b"  : [
        "2874",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2952"      : {
    "inputs"     : {
      "model_a" : [
        "2954",
        0
      ],
      "model_b" : [
        "2901",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2953"      : {
    "inputs"     : {
      "clip_a"  : [
        "2954",
        1
      ],
      "clip_b"  : [
        "2901",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2954"      : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2957"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "2959",
        0
      ],
      "when_false" : [
        "2892",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2959"      : {
    "inputs"     : {
      "sampler_name" : "euler"
    },
    "class_type" : "KSamplerSelect",
    "_meta"      : {
      "title" : "KSamplerSelect"
    }
  },
  "2961"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "2237",
        0
      ],
      "when_false" : [
        "2963",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2963"      : {
    "inputs"     : {
      "model_name" : "4xPurePhoto-Span.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2964"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "1863",
        0
      ],
      "when_false" : [
        "1871",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2970"      : {
    "inputs"     : {
      "text" : ""
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2973"      : {
    "inputs"     : {
      "text" : "aidmarealisticskin, Skin imperfections,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2975"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2355",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2978"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2035",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2983"      : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2987"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2995:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2989"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "1267",
        0
      ],
      "mask"         : [
        "898",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2993"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "2034",
        0
      ],
      "mask"         : [
        "2978",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2997"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "2345",
        0
      ],
      "mask"         : [
        "2975",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "2999"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "2797",
        0
      ],
      "mask"         : [
        "2829",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "3001"      : {
    "inputs"     : {
      "rgthree_comparer" : {
        "images" : [
          {
            "name"     : "A",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_gxtbd_00001_.png&type=temp&subfolder=&rand=0.1590875800103928"
          },
          {
            "name"     : "B",
            "selected" : true,
            "url"      : "/api/view?filename=rgthree.compare._temp_gxtbd_00002_.png&type=temp&subfolder=&rand=0.6339522817992669"
          }
        ]
      },
      "image_a"          : [
        "2670",
        0
      ],
      "image_b"          : [
        "2109",
        0
      ]
    },
    "class_type" : "Image Comparer (rgthree)",
    "_meta"      : {
      "title" : "Image Comparer (rgthree)"
    }
  },
  "3003"      : {
    "inputs"     : {
      "level" : 1.2
    },
    "class_type" : "ImageSaturation",
    "_meta"      : {
      "title" : "Adjust Saturation"
    }
  },
  "3007"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2908",
        0
      ],
      "clip"           : [
        "2908",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "3011"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "3014:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "3013"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "1611",
        0
      ],
      "mask"         : [
        "2715",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "3015"      : {
    "inputs"     : {
      "method"          : "human_parsing_lip",
      "confidence"      : 0.4,
      "crop_multi"      : 0,
      "mask_components" : {
        "__value__" : [
          14,
          15
        ]
      },
      "image"           : [
        "1611",
        0
      ]
    },
    "class_type" : "easy humanSegmentation",
    "_meta"      : {
      "title" : "Human Segmentation"
    }
  },
  "3018"      : {
    "inputs"     : {
      "opacity"         : 50,
      "image"           : [
        "1888",
        0
      ],
      "color_ref_image" : [
        "2669",
        0
      ]
    },
    "class_type" : "LayerColor: ColorAdapter",
    "_meta"      : {
      "title" : "LayerColor: ColorAdapter"
    }
  },
  "3020"      : {
    "inputs"     : {
      "lora_name"      : "Flux_Lora_32F_Breasts.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 1,
      "model"          : [
        "2881",
        0
      ],
      "clip"           : [
        "2881",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "3023"      : {
    "inputs"     : {
      "any_01" : [
        "2339",
        0
      ],
      "any_02" : [
        "2158",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2991:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "2991:2975",
        0
      ],
      "t5xxl"    : [
        "2991:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2269",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2991:113"  : {
    "inputs"     : {
      "max_shift"  : 1.35,
      "base_shift" : 0.15,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2269",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "2991:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "898",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2991:54"   : {
    "inputs"     : {
      "conditioning" : [
        "2991:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2991:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2269",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2991:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "2991:2973",
        0
      ],
      "text_c"           : [
        "2011",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2991:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2106",
        0
      ],
      "text_b"           : [
        "2991:2972",
        0
      ],
      "text_c"           : [
        "2011",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2991:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "2991:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "2991:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 24,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.42,
      "feather"            : 6,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 1,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "1267",
        0
      ],
      "segs"               : [
        "2991:88",
        0
      ],
      "model"              : [
        "2991:113",
        0
      ],
      "clip"               : [
        "2269",
        1
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2991:506",
        0
      ],
      "negative"           : [
        "2991:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  },
  "2996:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "2996:2975",
        0
      ],
      "t5xxl"    : [
        "2996:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2996:113"  : {
    "inputs"     : {
      "max_shift"  : 1.55,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "2996:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2975",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2996:54"   : {
    "inputs"     : {
      "conditioning" : [
        "2996:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2996:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2996:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "2996:2973",
        0
      ],
      "text_c"           : [
        "2973",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2996:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2106",
        0
      ],
      "text_b"           : [
        "2996:2972",
        0
      ],
      "text_c"           : [
        "2973",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2996:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "2996:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "2996:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 23,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : [
        "2983",
        0
      ],
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 1,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2345",
        0
      ],
      "segs"               : [
        "2996:88",
        0
      ],
      "model"              : [
        "2996:113",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2996:506",
        0
      ],
      "negative"           : [
        "2996:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  },
  "2995:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "2995:2975",
        0
      ],
      "t5xxl"    : [
        "2995:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2867",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2995:113"  : {
    "inputs"     : {
      "max_shift"  : 1.3,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2866",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "2995:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2978",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2995:54"   : {
    "inputs"     : {
      "conditioning" : [
        "2995:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2995:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2867",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2995:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "2995:2973",
        0
      ],
      "text_c"           : [
        "2970",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2995:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2106",
        0
      ],
      "text_b"           : [
        "2995:2972",
        0
      ],
      "text_c"           : [
        "2970",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2995:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "Natural breast shape, Perfect hand and fingers and nails with pastel nail polish,wearing thin golden necklace,\n\nsmooth midriff,low muscle definition, soft natural curves",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "2995:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "Natural breast shape, Perfect hand and fingers and nails with pastel nail polish,wearing thin golden necklace,",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "2995:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 16,
      "cfg"                : 1,
      "sampler_name"       : "heun",
      "scheduler"          : "simple",
      "denoise"            : 0.18,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 1,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2034",
        0
      ],
      "segs"               : [
        "2995:88",
        0
      ],
      "model"              : [
        "2995:113",
        0
      ],
      "clip"               : [
        "2867",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2995:506",
        0
      ],
      "negative"           : [
        "2995:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  },
  "2998:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "2998:2975",
        0
      ],
      "t5xxl"    : [
        "2998:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2291",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2998:113"  : {
    "inputs"     : {
      "max_shift"  : 1.55,
      "base_shift" : 0.55,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2292",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "2998:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2829",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2998:54"   : {
    "inputs"     : {
      "conditioning" : [
        "2998:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2998:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2291",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2998:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2847",
        0
      ],
      "text_b"           : [
        "2998:2973",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2998:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2846",
        0
      ],
      "text_b"           : [
        "2998:2972",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2998:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "2998:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "2998:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 23,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : [
        "2843",
        0
      ],
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2797",
        0
      ],
      "segs"               : [
        "2998:88",
        0
      ],
      "model"              : [
        "2998:113",
        0
      ],
      "clip"               : [
        "2291",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2998:506",
        0
      ],
      "negative"           : [
        "2998:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  },
  "3014:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "3014:2975",
        0
      ],
      "t5xxl"    : [
        "3014:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2655",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "3014:113"  : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2655",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "3014:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2715",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "3014:54"   : {
    "inputs"     : {
      "conditioning" : [
        "3014:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "3014:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2655",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "3014:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "3014:2973",
        0
      ],
      "text_c"           : [
        "2652",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "3014:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_b"           : [
        "3014:2972",
        0
      ],
      "text_c"           : [
        "2652",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "3014:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "Detailed female hands, Diamond ring in one finger. No Nailpolish,",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "3014:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "3014:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 23,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.42,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "1611",
        0
      ],
      "segs"               : [
        "3014:88",
        0
      ],
      "model"              : [
        "3014:113",
        0
      ],
      "clip"               : [
        "2655",
        1
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "3014:506",
        0
      ],
      "negative"           : [
        "3014:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  }
}