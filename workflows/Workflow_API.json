{
  "26"        : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2581",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "30"        : {
    "inputs"     : {
      "text" : "A closeup professional photoshoot analog photograph of a shy and alluring dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.2), deep rich complexion with a scattering of freckles across cheeks and nose, \n\nfilm, film grain, kdkpt400, kodak, portra400, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "41"        : {
    "inputs"     : {
      "crop"        : "center",
      "clip_vision" : [
        "1517",
        0
      ],
      "image"       : [
        "2109",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "42"        : {
    "inputs"     : {
      "strength"           : 0.48,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "1412",
        0
      ],
      "style_model"        : [
        "43",
        0
      ],
      "clip_vision_output" : [
        "41",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "43"        : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "44"        : {
    "inputs"     : {
      "conditioning_to_strength" : 0.5000000000000001,
      "conditioning_to"          : [
        "1412",
        0
      ],
      "conditioning_from"        : [
        "42",
        0
      ]
    },
    "class_type" : "ConditioningAverage",
    "_meta"      : {
      "title" : "ConditioningAverage"
    }
  },
  "55"        : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2703",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "122"       : {
    "inputs"     : {
      "any" : [
        "581",
        1
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "124"       : {
    "inputs"     : {
      "boolean" : [
        "122",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "143"       : {
    "inputs"     : {
      "images" : [
        "1831",
        0
      ]
    },
    "class_type" : "Image to Seed",
    "_meta"      : {
      "title" : "Image to Seed"
    }
  },
  "146"       : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "154"       : {
    "inputs"     : {
      "pixels" : [
        "2109",
        0
      ],
      "vae"    : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEEncode",
    "_meta"      : {
      "title" : "VAE Encode"
    }
  },
  "193"       : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "195"       : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1331",
        1
      ],
      "b"          : [
        "1331",
        2
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Orientation P or L"
    }
  },
  "232"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "##",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "233"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "**",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [**]"
    }
  },
  "235"       : {
    "inputs"     : {
      "boolean_a" : [
        "286",
        0
      ],
      "boolean_b" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic Comparison OR",
    "_meta"      : {
      "title" : "Logic Comparison OR"
    }
  },
  "240"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "saree",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [Saree]"
    }
  },
  "241"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "back",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "242"       : {
    "inputs"     : {
      "text_a"  : [
        "247",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "240",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "243"       : {
    "inputs"     : {
      "text_a"  : [
        "265",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "255",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "244"       : {
    "inputs"     : {
      "value" : "Photo taken from the back of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "245"       : {
    "inputs"     : {
      "string_a"  : [
        "243",
        0
      ],
      "string_b"  : [
        "258",
        0
      ],
      "delimiter" : ""
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "247"       : {
    "inputs"     : {
      "value" : "wearing indian saree with intricate details"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "249"       : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "245",
        0
      ],
      "text_b"           : [
        "242",
        0
      ],
      "text_c"           : [
        "253",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "251"       : {
    "inputs"     : {
      "text" : [
        "254",
        0
      ]
    },
    "class_type" : "ShowText|LP",
    "_meta"      : {
      "title" : "Show Text [LP]"
    }
  },
  "252"       : {
    "inputs"     : {
      "join_with"   : ",",
      "string_list" : [
        "251",
        0
      ]
    },
    "class_type" : "StringListToString",
    "_meta"      : {
      "title" : "String List to String"
    }
  },
  "253"       : {
    "inputs"     : {
      "string"  : [
        "252",
        0
      ],
      "find"    : "_",
      "replace" : ","
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "254"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "__(.*)__",
      "mode"             : "All Groups",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "255"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "side",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Text Contains [back]"
    }
  },
  "258"       : {
    "inputs"     : {
      "text_a"  : [
        "244",
        0
      ],
      "text_b"  : [
        "262",
        0
      ],
      "boolean" : [
        "241",
        0
      ]
    },
    "class_type" : "Text Input Switch",
    "_meta"      : {
      "title" : "Text Input Switch"
    }
  },
  "262"       : {
    "inputs"     : {
      "value" : ""
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "On False"
    }
  },
  "265"       : {
    "inputs"     : {
      "value" : "Photo taken from the side of the subject,"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "OnTrue"
    }
  },
  "266"       : {
    "inputs"     : {
      "boolean" : true
    },
    "class_type" : "Logic Boolean Primitive",
    "_meta"      : {
      "title" : "Red Lipstick?"
    }
  },
  "268"       : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "2110",
        0
      ],
      "b"          : [
        "1921",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "271"       : {
    "inputs"     : {
      "string"  : "the subject is portrayed at __{{ age }}__ years of age,  ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "272"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "\\((.*)\\)",
      "mode"             : "First Group",
      "case_insensitive" : false,
      "multiline"        : false,
      "dotall"           : false,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "275"       : {
    "inputs"     : {
      "comparison" : "a < b",
      "a"          : [
        "2544",
        0
      ],
      "b"          : [
        "1920",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "277"       : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "L"
    }
  },
  "278"       : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "283"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "284",
        0
      ],
      "text_b"           : [
        "272",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "284"       : {
    "inputs"     : {
      "value" : "0"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "285"       : {
    "inputs"     : {
      "value" : "+"
    },
    "class_type" : "PrimitiveString",
    "_meta"      : {
      "title" : "String"
    }
  },
  "286"       : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "288"       : {
    "inputs"     : {
      "text" : [
        "289",
        0
      ]
    },
    "class_type" : "ShowTextBridge|LP",
    "_meta"      : {
      "title" : "Show Text Bridge [LP]"
    }
  },
  "289"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\++)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "290"       : {
    "inputs"     : {
      "string" : [
        "296",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "293"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "500",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "294"       : {
    "inputs"     : {
      "string" : [
        "293",
        0
      ]
    },
    "class_type" : "StringLength",
    "_meta"      : {
      "title" : "Length"
    }
  },
  "295"       : {
    "inputs"     : {
      "int" : 5
    },
    "class_type" : "Int Literal",
    "_meta"      : {
      "title" : "Int Literal"
    }
  },
  "296"       : {
    "inputs"     : {
      "delimiter"        : "",
      "clean_whitespace" : "true",
      "text_a"           : [
        "285",
        0
      ],
      "text_b"           : [
        "289",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "322"       : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "sketch",
      "case_insensitive" : true
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [sketch]"
    }
  },
  "325"       : {
    "inputs"     : {
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "Logic NOT"
    }
  },
  "331"       : {
    "inputs"     : {
      "select"   : 1,
      "sel_mode" : false,
      "input1"   : [
        "278",
        0
      ],
      "input2"   : [
        "334",
        0
      ],
      "input3"   : [
        "335",
        0
      ],
      "input4"   : [
        "277",
        0
      ]
    },
    "class_type" : "ImpactSwitch",
    "_meta"      : {
      "title" : "Switch (Any)"
    }
  },
  "334"       : {
    "inputs"     : {
      "value" : 2
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "S"
    }
  },
  "335"       : {
    "inputs"     : {
      "value" : 6
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "M"
    }
  },
  "339"       : {
    "inputs"     : {
      "noise_scale"   : [
        "622",
        0
      ],
      "blend_opacity" : 11,
      "image"         : [
        "363",
        0
      ],
      "mask"          : [
        "2193",
        0
      ]
    },
    "class_type" : "NoisePlusBlend",
    "_meta"      : {
      "title" : "Noise Plus Blend"
    }
  },
  "342"       : {
    "inputs"     : {
      "value1" : 0.72,
      "value2" : 0.56
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "0.72::0.56"
    }
  },
  "343"       : {
    "inputs"     : {
      "value1" : 0.52,
      "value2" : 0.37
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "Input+DetailerDenoise[0.62,0.56]"
    }
  },
  "356"       : {
    "inputs"     : {
      "image" : [
        "1848",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "362"       : {
    "inputs"     : {
      "value" : 24
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Age"
    }
  },
  "363"       : {
    "inputs"     : {
      "center_x"            : 0.3,
      "center_y"            : 0.5,
      "saturation"          : 0.9,
      "vignette_intensity"  : 0.010000000000000002,
      "grain_method"        : "filmgrainer",
      "grain_power"         : 0.08,
      "grain_scale"         : 0.4,
      "grain_sat"           : 0.3,
      "filmgrainer_shadows" : 0.15000000000000002,
      "filmgrainer_highs"   : 0.10000000000000002,
      "blur_strength"       : 1,
      "blur_focus_spread"   : 0.30000000000000004,
      "focal_depth"         : 0.10000000000000002,
      "image"               : [
        "482",
        0
      ],
      "depth_map"           : [
        "2727",
        0
      ]
    },
    "class_type" : "LayerFilter: FilmV2",
    "_meta"      : {
      "title" : "LayerFilter: Film V2"
    }
  },
  "389"       : {
    "inputs"     : {
      "expression" : "(a * b / 2 + 32)-((a * b / 2 + 32)%64)",
      "a"          : [
        "1740",
        0
      ],
      "b"          : [
        "394",
        0
      ],
      "c"          : [
        "394",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "tile height (Math Expression üêç)"
    }
  },
  "394"       : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSize+",
    "_meta"      : {
      "title" : "üîß Get Image Size"
    }
  },
  "405"       : {
    "inputs"     : {
      "text" : "\n(dark pimple marks in the left cheek:0.8), tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3), and her hair is long, curly. She has minimal makeup, with a focus on sharp black eyeliner and nude matte warm brown lipstick on her sexy pouty lips.\n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 28-inch waist, and 36-inch hips. Her thighs are thick, and her posture confident yet relaxed. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, cleavage.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "440"       : {
    "inputs"     : {
      "cyan_red"      : 0.01,
      "magenta_green" : 0,
      "yellow_blue"   : 0.02,
      "image"         : [
        "356",
        0
      ]
    },
    "class_type" : "LayerColor: ColorBalance",
    "_meta"      : {
      "title" : "LayerColor: ColorBalance"
    }
  },
  "441"       : {
    "inputs"     : {
      "expand"                 : 1,
      "incremental_expandrate" : 0,
      "tapered_corners"        : false,
      "flip_input"             : false,
      "blur_radius"            : 0,
      "lerp_alpha"             : 0,
      "decay_factor"           : 0,
      "fill_holes"             : false,
      "mask"                   : [
        "545",
        0
      ]
    },
    "class_type" : "GrowMaskWithBlur",
    "_meta"      : {
      "title" : "Grow Mask With Blur"
    }
  },
  "445"       : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "454"       : {
    "inputs"     : {
      "image" : [
        "440",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "455"       : {
    "inputs"     : {
      "x"           : 0,
      "y"           : 0,
      "operation"   : "or",
      "destination" : [
        "457",
        0
      ],
      "source"      : [
        "456",
        0
      ]
    },
    "class_type" : "MaskComposite",
    "_meta"      : {
      "title" : "MaskComposite"
    }
  },
  "456"       : {
    "inputs"     : {
      "shape"        : "square",
      "frames"       : 1,
      "location_x"   : 0,
      "location_y"   : 0,
      "grow"         : 1,
      "frame_width"  : [
        "445",
        1
      ],
      "frame_height" : [
        "445",
        2
      ],
      "shape_width"  : 16,
      "shape_height" : [
        "445",
        2
      ]
    },
    "class_type" : "CreateShapeMask",
    "_meta"      : {
      "title" : "Create Shape Mask"
    }
  },
  "457"       : {
    "inputs"     : {
      "red"       : 255,
      "green"     : 0,
      "blue"      : 207,
      "threshold" : 10,
      "image"     : [
        "454",
        0
      ]
    },
    "class_type" : "MaskFromColor+",
    "_meta"      : {
      "title" : "üîß Mask From Color"
    }
  },
  "459"       : {
    "inputs"     : {
      "mask" : [
        "455",
        0
      ]
    },
    "class_type" : "MaskToImage",
    "_meta"      : {
      "title" : "Convert Mask to Image"
    }
  },
  "461"       : {
    "inputs"     : {
      "op" : "IsZero",
      "a"  : 1
    },
    "class_type" : "CM_IntUnaryCondition",
    "_meta"      : {
      "title" : "IntUnaryCondition"
    }
  },
  "478"       : {
    "inputs"     : {
      "image" : [
        "2703",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "482"       : {
    "inputs"     : {
      "noise_radius"   : 1,
      "preserve_edges" : 1,
      "sharpen"        : 0.5,
      "ratio"          : 0.5,
      "image"          : [
        "478",
        0
      ]
    },
    "class_type" : "ImageSmartSharpen+",
    "_meta"      : {
      "title" : "üîß Image Smart Sharpen"
    }
  },
  "484"       : {
    "inputs"     : {
      "question"          : "Describe this photo in essential details concisely with detais about the background, camera angle of the shot, intrinsic details about accesories like glasses, hair style, jewelry and outfit. Also, describe about facial expression including the make-up, eyes and lipstick, avoid mentioning blurred and try to find details in the background. ",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 1024,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "485"       : {
    "inputs"     : {
      "question"          : "Describe the outfit in the photo in essential details with detais about the color, material, texture of the materials, fit etc.",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 768,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "494"       : {
    "inputs"     : {
      "text" : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry,\n\n\nnude, dark texture areola and erect nipples,  (nsfw:0.7),  \n\n\nsee-through blouse and saree, deep-cleavage, jewelry, (Hip-Chain:1.2), \n\ncolorful silk saree with expensive hand-made embroidery designs, backless blouse,\n\nsexy heart-shaped clothing cutout in the back revealing buttcrack,\n\nsee-through saree, Floral prints embroidery,    Belly Piercing,\n\nwearing Glasses\n\nSitting on the knees, in front of mirror,  Happy facial expression,colorful lace top with expensive hand-made embroidery designs backless blouse,  \n\nSexy Hip-Chain,Sexy Waist-Chain, Sexy crop-top made of jasmine flowers,\n\nA tattoo of a baby elephant is visible on the left chest area. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "495"       : {
    "inputs"     : {
      "text" : " hip chain, waist chain, hands behind the back, crop top overhang,\n\nand light freckles scattered across her cheeks and nose. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "496"       : {
    "inputs"     : {
      "text" : "fluxenhancer, aidmaimageupgrader"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "500"       : {
    "inputs"     : {
      "string"           : [
        "1838",
        0
      ],
      "regex_pattern"    : "(\\-\\-)",
      "mode"             : "All Matches",
      "case_insensitive" : false,
      "multiline"        : true,
      "dotall"           : true,
      "group_index"      : 1
    },
    "class_type" : "RegexExtract",
    "_meta"      : {
      "title" : "Regex Extract"
    }
  },
  "513"       : {
    "inputs"     : {
      "text"   : "loving \npouting\nshy\nhappy\nvery happy\nsilly\naroused\nflirting\nseductive\nprovocative\nsurprised\nopen mouth",
      "amount" : 1,
      "seed"   : [
        "2240",
        0
      ]
    },
    "class_type" : "TextRandomMultiline",
    "_meta"      : {
      "title" : "Text Random Multiline"
    }
  },
  "515"       : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "1945",
        0
      ],
      "text_b"           : [
        "2555",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "542"       : {
    "inputs"     : {
      "images" : [
        "1885",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "545"       : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.5,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "356",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "559"       : {
    "inputs"     : {
      "text" : "aidmafluxproultra, aidmaimageupgrader, sinfully stylish, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "560"       : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, moles, natural blemishes, Rough skin texture, Skin imperfections , "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "564"       : {
    "inputs"     : {
      "model_name" : "deepseek-ai/Janus-Pro-1B"
    },
    "class_type" : "JanusProModelLoader|Mie",
    "_meta"      : {
      "title" : "Janus Pro Model Loader üêë"
    }
  },
  "567"       : {
    "inputs"     : {
      "text" : "a professional digital Storybook Illustration art style of a shy and cute dark-skinned Indian v1dhya5 woman with  a extremely beautiful  face with (black bindi on the forehead:1.2), "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "568"       : {
    "inputs"     : {
      "text" : "A professionally color-graded RAW photograph of a shy sexy and alluring dark brown almond  skin tone Indian v1dhya5 woman with extremely beautiful face  with black bindi on the forehead, , photo taken using using a  high-end professional camera , posing glamorously like she is with her lover who is taking the photo,  \n\nThe makeup is minimal but bold and glamorous, featuring black bindi on the forehead and a dramatic eye makeup with dark eyeliner / kohl and mascara, along with defined eyebrows. Her sexy pouty lips are painted a vivid red   . Her lips are narrow, plump, and wet-looking, subtly curved for a sensual appearance., adding a touch of elegance and intensity to their appearance. The skin has a healthy glow, accentuated by subtle matte makeup techniques. "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "571"       : {
    "inputs"     : {
      "text1"     : "A dark-skinned Indian v1dhya5 woman with extremely beautiful face with (black bindi on the forehead:1.4), deep rich complexion with a scattering of freckles across cheeks and nose,",
      "text2"     : "nude, dark textured large areola and medium-sized  erect nipples,  (nsfw:0.8),   jewelry",
      "text3"     : "looking at the cameras,\ntranslucent   outfit with see though sleeves, showing the profile of the dark blue bra wearing with dark blue strap peeking outside.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "581"       : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2609",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "832",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "622"       : {
    "inputs"     : {
      "float_value"    : [
        "2100",
        0
      ],
      "multiply_value" : 0.181818
    },
    "class_type" : "FloatMultiplication",
    "_meta"      : {
      "title" : "Float Multiplication"
    }
  },
  "623"       : {
    "inputs"     : {
      "value1" : 0.92,
      "value2" : 0.72
    },
    "class_type" : "SeargeFloatPair",
    "_meta"      : {
      "title" : "0.92::0.78"
    }
  },
  "731"       : {
    "inputs"     : {
      "preprocessor" : "DWPreprocessor",
      "resolution"   : [
        "764",
        0
      ],
      "image"        : [
        "744",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "734"       : {
    "inputs"     : {
      "type"        : "openpose",
      "control_net" : [
        "2231",
        0
      ]
    },
    "class_type" : "SetUnionControlNetType",
    "_meta"      : {
      "title" : "SetUnionControlNetType"
    }
  },
  "735"       : {
    "inputs"     : {
      "conditioning" : [
        "736",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "736"       : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "CLIP Text Encode (Prompt)"
    }
  },
  "737"       : {
    "inputs"     : {
      "clip_l"   : [
        "2187",
        0
      ],
      "t5xxl"    : [
        "743",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "743"       : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "744"       : {
    "inputs"     : {
      "image" : [
        "2109",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "764"       : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "744",
        1
      ],
      "b"    : [
        "744",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "768"       : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.mp3",
      "any"    : [
        "122",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "788"       : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2105",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "826"       : {
    "inputs"     : {
      "mask" : [
        "829",
        1
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "828"       : {
    "inputs"     : {
      "width"  : 168,
      "height" : 38,
      "red"    : 0,
      "green"  : 0,
      "blue"   : 0
    },
    "class_type" : "Image Blank",
    "_meta"      : {
      "title" : "Image Blank"
    }
  },
  "829"       : {
    "inputs"     : {
      "text"             : [
        "1936",
        0
      ],
      "font"             : "SevenSegment.ttf",
      "size"             : 38,
      "color"            : "#b66244FF",
      "background_color" : "#00000000",
      "shadow_distance"  : 0,
      "shadow_blur"      : 0,
      "shadow_color"     : "#ADADAD",
      "horizontal_align" : "right",
      "vertical_align"   : "bottom",
      "offset_x"         : -4,
      "offset_y"         : -2,
      "direction"        : "ltr",
      "img_composite"    : [
        "828",
        0
      ]
    },
    "class_type" : "DrawText+",
    "_meta"      : {
      "title" : "üîß Draw Text"
    }
  },
  "832"       : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "bilinear",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : [
        "1937",
        0
      ],
      "y_offset"       : [
        "1938",
        0
      ],
      "rotation"       : -90,
      "opacity"        : 0,
      "base_image"     : [
        "1585",
        0
      ],
      "overlay_image"  : [
        "829",
        0
      ],
      "optional_mask"  : [
        "826",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "840"       : {
    "inputs"     : {
      "comparison" : "a == b",
      "a"          : [
        "1918",
        0
      ],
      "b"          : [
        "1595",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "897"       : {
    "inputs"     : {
      "text1"     : "detailed fabric texture",
      "text2"     : [
        "485",
        0
      ],
      "text3"     : "slightly translucent elements in the intricate outfit with see though sleeves, showing the profile of the 36DD Cup size  bra wearing underneath.",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "931"       : {
    "inputs"     : {
      "any_01" : [
        "2403",
        0
      ],
      "any_02" : [
        "2339",
        0
      ],
      "any_03" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "950"       : {
    "inputs"     : {
      "text" : "professionally color-graded RAW photograph, __AGE__ Indian v1dhya5  woman,  beautiful face kohl-lined almond eyes with serene gaze, (bindi on the forehead:1.2) ,detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness, alluring almond skintone with subtle micro-hairs and soft sheen, low muscle definition, soft natural curves  \nadorning warm red lipstick ,high-end professional camera ,  glamorous , serene  setting,  sharp focus, detailed fabric texture,   intricate details, detailed background, \n"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "953"       : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2595",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1271"      : {
    "inputs"     : {
      "upscale_method"   : "lanczos",
      "megapixels"       : 1.5000000000000002,
      "resolution_steps" : 1,
      "image"            : [
        "2109",
        0
      ]
    },
    "class_type" : "ImageScaleToTotalPixels",
    "_meta"      : {
      "title" : "ImageScaleToTotalPixels"
    }
  },
  "1318"      : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "897",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "1331"      : {
    "inputs"     : {
      "image" : [
        "356",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1343"      : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (vertical, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1344"      : {
    "inputs"     : {
      "makeTileable"          : false,
      "context"               : "Directional (horizontal, outward)",
      "mapWeight"             : 0.5,
      "sensitivityToOutliers" : 0.117,
      "patchSize"             : 30,
      "maxProbeCount"         : 200,
      "image"                 : [
        "440",
        0
      ],
      "mask"                  : [
        "455",
        0
      ]
    },
    "class_type" : "Resynthesize",
    "_meta"      : {
      "title" : "Resynthesize"
    }
  },
  "1345"      : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "$$",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [##]"
    }
  },
  "1357"      : {
    "inputs"     : {
      "lut_name" : "Presetpro  - Kodacrome 64.cube",
      "strength" : 0.27,
      "log"      : true,
      "image"    : [
        "931",
        0
      ]
    },
    "class_type" : "ProPostApplyLUT",
    "_meta"      : {
      "title" : "ProPostApplyLUT"
    }
  },
  "1400"      : {
    "inputs"     : {
      "brightness" : 0.93,
      "contrast"   : 1.16,
      "saturation" : 1,
      "image"      : [
        "2675",
        0
      ]
    },
    "class_type" : "LayerColor: BrightnessContrastV2",
    "_meta"      : {
      "title" : "Brightness Contrast V2"
    }
  },
  "1405"      : {
    "inputs"     : {
      "value" : 1.2
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "<<Speed - Accuracy>> (default 0.9)"
    }
  },
  "1412"      : {
    "inputs"     : {
      "strength"      : 0.6,
      "start_percent" : 0,
      "end_percent"   : 0.6,
      "positive"      : [
        "737",
        0
      ],
      "negative"      : [
        "735",
        0
      ],
      "control_net"   : [
        "734",
        0
      ],
      "image"         : [
        "731",
        0
      ],
      "vae"           : [
        "2889",
        0
      ]
    },
    "class_type" : "ControlNetApplyAdvanced",
    "_meta"      : {
      "title" : "Apply ControlNet"
    }
  },
  "1479"      : {
    "inputs"     : {
      "text" : " , Skin imperfections ,    natural blemishes, Rough skin texture, d351 d4rk, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "1495"      : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1496"      : {
    "inputs"     : {
      "images" : [
        "2339",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1497"      : {
    "inputs"     : {
      "images" : [
        "2158",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1498"      : {
    "inputs"     : {
      "images" : [
        "2117",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1517"      : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "1566"      : {
    "inputs"     : {
      "any_01" : [
        "2321",
        0
      ],
      "any_02" : [
        "2930",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1585"      : {
    "inputs"     : {
      "radius"          : 0.7,
      "amount"          : 1.2,
      "reduce_noise"    : 0.15,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0.2,
      "image"           : [
        "1357",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "Nettet√© optimis√©e"
    }
  },
  "1595"      : {
    "inputs"     : {
      "expression" : "c*(a-b)",
      "a"          : [
        "290",
        0
      ],
      "b"          : [
        "294",
        0
      ],
      "c"          : [
        "295",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1611"      : {
    "inputs"     : {
      "any_02" : [
        "2339",
        0
      ],
      "any_03" : [
        "2065",
        0
      ],
      "any_05" : [
        "2704",
        0
      ],
      "any_06" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "1636"      : {
    "inputs"     : {
      "image" : [
        "931",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1637"      : {
    "inputs"     : {
      "value" : 0.56
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Color_Correct"
    }
  },
  "1710"      : {
    "inputs"     : {
      "value" : 1.58
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1740"      : {
    "inputs"     : {
      "value" : 1.33
    },
    "class_type" : "easy float",
    "_meta"      : {
      "title" : "upscale by"
    }
  },
  "1803"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -1
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1805"      : {
    "inputs"     : {
      "directory_path"    : "Inputs/Next",
      "patterns"          : "*.jpg|*.png|*.jpeg",
      "rescan_each_queue" : true
    },
    "class_type" : "FileCounter|LP",
    "_meta"      : {
      "title" : "File Counter [LP]"
    }
  },
  "1806"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "random",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -1
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1807"      : {
    "inputs"     : {
      "any" : [
        "1803",
        0
      ]
    },
    "class_type" : "easy isNone",
    "_meta"      : {
      "title" : "Is None"
    }
  },
  "1812"      : {
    "inputs"     : {
      "boolean" : [
        "1807",
        0
      ]
    },
    "class_type" : "Logic NOT",
    "_meta"      : {
      "title" : "NOT"
    }
  },
  "1813"      : {
    "inputs"     : {
      "OutputDirectory" : "Inputs/Processed",
      "OverwriteFile"   : [
        "124",
        0
      ],
      "FilePaths"       : [
        "1838",
        0
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1814"      : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1805",
        0
      ],
      "b"          : [
        "1924",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1818"      : {
    "inputs"     : {
      "string_a"  : "Inputs/Next",
      "string_b"  : [
        "1806",
        4
      ],
      "delimiter" : "/"
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "1819"      : {
    "inputs"     : {
      "condition"  : [
        "1814",
        0
      ],
      "when_true"  : [
        "1818",
        0
      ],
      "when_false" : [
        "1806",
        2
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1820"      : {
    "inputs"     : {
      "OutputDirectory" : [
        "1819",
        0
      ],
      "OverwriteFile"   : true,
      "FilePaths"       : [
        "1806",
        3
      ]
    },
    "class_type" : "JDCN_FileMover",
    "_meta"      : {
      "title" : "JDCN_FileMover"
    }
  },
  "1831"      : {
    "inputs"     : {
      "condition"  : [
        "193",
        0
      ],
      "when_true"  : [
        "1343",
        0
      ],
      "when_false" : [
        "1344",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1832"      : {
    "inputs"     : {
      "directory_1"            : [
        "2545",
        0
      ],
      "directory_2"            : "Inputs/Next",
      "directory_3"            : "Inputs/Downloaded",
      "ordering_mode"          : "sequential_by_modified_date",
      "include_subdirectories" : "yes",
      "index"                  : 0,
      "seed"                   : -1
    },
    "class_type" : "Input_Image",
    "_meta"      : {
      "title" : "Input Image"
    }
  },
  "1835"      : {
    "inputs"     : {
      "comparison" : "a <= b",
      "a"          : [
        "1941",
        0
      ],
      "b"          : [
        "1925",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : ">0"
    }
  },
  "1837"      : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        0
      ],
      "when_false" : [
        "1832",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1838"      : {
    "inputs"     : {
      "condition"  : [
        "1835",
        0
      ],
      "when_true"  : [
        "1803",
        3
      ],
      "when_false" : [
        "1832",
        3
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "1848"      : {
    "inputs"     : {
      "megapixel"     : "2.0",
      "divisible_by"  : "8",
      "mode"          : "pad",
      "delta_percent" : [
        "2532",
        0
      ],
      "image"         : [
        "1913",
        0
      ]
    },
    "class_type" : "Image_Preparations",
    "_meta"      : {
      "title" : "Image Preparations"
    }
  },
  "1855"      : {
    "inputs"     : {
      "expression" : "b+(a-0.46)*(24-b)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1856"      : {
    "inputs"     : {
      "expression" : "c+(a-0.46)*(35-c)/(0.72-0.46)",
      "a"          : [
        "1955",
        0
      ],
      "b"          : [
        "1902",
        0
      ],
      "c"          : [
        "1902",
        1
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1857"      : {
    "inputs"     : {},
    "class_type" : "DisableNoise",
    "_meta"      : {
      "title" : "DisableNoise"
    }
  },
  "1858"      : {
    "inputs"     : {
      "noise_seed" : [
        "2240",
        0
      ]
    },
    "class_type" : "RandomNoise",
    "_meta"      : {
      "title" : "RandomNoise"
    }
  },
  "1859"      : {
    "inputs"     : {
      "model"        : [
        "1899",
        0
      ],
      "conditioning" : [
        "2108",
        0
      ]
    },
    "class_type" : "BasicGuider",
    "_meta"      : {
      "title" : "BasicGuider"
    }
  },
  "1860"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : [
        "1893",
        0
      ],
      "denoise"   : [
        "2541",
        0
      ],
      "model"     : [
        "1899",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "1863"      : {
    "inputs"     : {
      "noise"        : [
        "1858",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2957",
        0
      ],
      "sigmas"       : [
        "1877",
        0
      ],
      "latent_image" : [
        "1989",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler1"
    }
  },
  "1870"      : {
    "inputs"     : {
      "noise"        : [
        "1857",
        0
      ],
      "guider"       : [
        "1859",
        0
      ],
      "sampler"      : [
        "2666",
        0
      ],
      "sigmas"       : [
        "1877",
        1
      ],
      "latent_image" : [
        "2964",
        0
      ]
    },
    "class_type" : "SamplerCustomAdvanced",
    "_meta"      : {
      "title" : "Pass02:Sampler2"
    }
  },
  "1871"      : {
    "inputs"     : {
      "noise_seed"     : [
        "2212",
        0
      ],
      "noise_strength" : 1.3,
      "normalize"      : "false",
      "latent"         : [
        "1863",
        0
      ]
    },
    "class_type" : "InjectLatentNoise+",
    "_meta"      : {
      "title" : "üîß Inject Latent Noise"
    }
  },
  "1877"      : {
    "inputs"     : {
      "denoise" : [
        "1944",
        0
      ],
      "sigmas"  : [
        "1860",
        0
      ]
    },
    "class_type" : "SplitSigmasDenoise",
    "_meta"      : {
      "title" : "SplitSigmasDenoise"
    }
  },
  "1885"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1934",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "3018",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "1888"      : {
    "inputs"     : {
      "samples" : [
        "1870",
        1
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "1889"      : {
    "inputs"     : {
      "mode"   : "always",
      "volume" : 1,
      "file"   : "notify.wav",
      "any"    : [
        "1885",
        0
      ]
    },
    "class_type" : "PlaySound|pysssss",
    "_meta"      : {
      "title" : "PlaySound üêç"
    }
  },
  "1893"      : {
    "inputs"     : {
      "expression" : "1.3*(a+c*(b-a))",
      "a"          : [
        "1855",
        0
      ],
      "b"          : [
        "1856",
        0
      ],
      "c"          : [
        "1405",
        0
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "1899"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.45"
    }
  },
  "1902"      : {
    "inputs"     : {
      "value1" : 28,
      "value2" : 42
    },
    "class_type" : "SeargeIntegerPair",
    "_meta"      : {
      "title" : "Range (31:43)"
    }
  },
  "1909"      : {
    "inputs"     : {
      "dishonesty_factor" : -0.02,
      "start_percent"     : 0.25,
      "end_percent"       : 0.5,
      "sampler"           : [
        "2957",
        0
      ]
    },
    "class_type" : "LyingSigmaSampler",
    "_meta"      : {
      "title" : "Lying Sigma Sampler"
    }
  },
  "1913"      : {
    "inputs"     : {
      "image" : [
        "1837",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "1918"      : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1919"      : {
    "inputs"     : {
      "value" : 0
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1920"      : {
    "inputs"     : {
      "value" : 1
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1921"      : {
    "inputs"     : {
      "value" : 20
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1922"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "1923",
        0
      ],
      "b"    : [
        "2544",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1923"      : {
    "inputs"     : {
      "value" : 15
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "15"
    }
  },
  "1924"      : {
    "inputs"     : {
      "value" : -268
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "One"
    }
  },
  "1925"      : {
    "inputs"     : {
      "value" : 10
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1926"      : {
    "inputs"     : {
      "value" : 1024
    },
    "class_type" : "easy int",
    "_meta"      : {
      "title" : "Zero"
    }
  },
  "1927"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "389",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1928"      : {
    "inputs"     : {
      "mode" : true,
      "a"    : [
        "146",
        0
      ],
      "b"    : [
        "1926",
        0
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1930"      : {
    "inputs"     : {
      "file_prefix"   : [
        "1932",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1931"      : {
    "inputs"     : {
      "int_" : [
        "143",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "1932"      : {
    "inputs"     : {
      "text1" : "Detailed_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1933"      : {
    "inputs"     : {
      "text1" : "AfterPass02_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "1934"      : {
    "inputs"     : {
      "file_prefix"   : [
        "1933",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1936"      : {
    "inputs"     : {
      "file_prefix"   : "",
      "time_format"   : "%-d %-m %y",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "1937"      : {
    "inputs"     : {
      "a"         : [
        "1636",
        1
      ],
      "b"         : -38,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1938"      : {
    "inputs"     : {
      "a"         : [
        "1636",
        2
      ],
      "b"         : -168,
      "operation" : "add"
    },
    "class_type" : "easy mathInt",
    "_meta"      : {
      "title" : "Math Int"
    }
  },
  "1941"      : {
    "inputs"     : {
      "min" : 1,
      "max" : 10
    },
    "class_type" : "RandomInt",
    "_meta"      : {
      "title" : "Random Int"
    }
  },
  "1942"      : {
    "inputs"     : {
      "mode" : false,
      "a"    : [
        "478",
        1
      ],
      "b"    : [
        "478",
        2
      ]
    },
    "class_type" : "ImpactMinMax",
    "_meta"      : {
      "title" : "ImpactMinMax"
    }
  },
  "1944"      : {
    "inputs"     : {
      "float_1" : 0.58,
      "float_2" : 0.9992
    },
    "class_type" : "TwoFloats",
    "_meta"      : {
      "title" : "<<Rough - Smooth>> (default 0.58)"
    }
  },
  "1945"      : {
    "inputs"     : {
      "text" : "She wears a form fitted outfit tailored precisely to her form, clean elegant lines that contour her silhouette without feeling restrictive, vibrant refined colors that remain tasteful and balanced, smooth high quality fabric with a subtle sheen that responds beautifully to cinematic lighting, gentle highlights tracing the curves of the design, structured yet fluid tailoring that suggests confidence and poise, minimal but intentional detailing that enhances shape rather than overwhelming it, graceful sophistication with a modern feminine presence, sharper tailoring accents, confident color contrast that draws the eye without breaking elegance, \n\nShe has an hourglass figure: 5'8\" tall, weighing approximately 160 lbs or 72 kilograms, with a 36-inch bust, 29-inch waist, and 36-inch hips. Her thighs are thick. In this portrait, there is an emphasis on the realistic representation of the subject's curvy body type, including Large breasts size that remains aesthetically pleasing while being in line with a natural aging process, along with minimal sagging breasts, beautiful cleavage.\n  tiny black mole in the chin,(She has dark supple non-oily skin with micro-hairs:1.3),  \n \n\nHer hair is long, black, and curly, with a few natural gray strands subtly visible. Her teeth are aligned, but one upper canine tooth is slightly twisted for a natural, imperfect charm.\n\nDetailed female hands, Diamond ring in one finger. No Nailpolish,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Prompt Extras"
    }
  },
  "1948"      : {
    "inputs"     : {
      "images" : [
        "731",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "1955"      : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.98,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "1978"      : {
    "inputs"     : {
      "max_shift"  : 1.5,
      "base_shift" : 0.5,
      "width"      : [
        "445",
        1
      ],
      "height"     : [
        "445",
        2
      ],
      "model"      : [
        "2939",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "1988"      : {
    "inputs"     : {
      "clip_l"   : "captivating professional photo of v1dhya5 woman in a serene outdoor setting, the overall mood of the photograph is calm and introspective, capturing a moment of introspection or contemplation, \n\n32F_Cup",
      "t5xxl"    : [
        "788",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2936",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "1989"      : {
    "inputs"     : {
      "sampler_name" : "euler",
      "scheduler"    : "beta",
      "steps"        : 24,
      "denoise"      : [
        "1999",
        0
      ],
      "noise_seed"   : [
        "2240",
        0
      ],
      "model"        : [
        "1978",
        0
      ],
      "conditioning" : [
        "1988",
        0
      ],
      "latent_image" : [
        "154",
        0
      ]
    },
    "class_type" : "FluxSampler",
    "_meta"      : {
      "title" : "Flux Sampler : Pass 01"
    }
  },
  "1999"      : {
    "inputs"     : {
      "a"         : [
        "2100",
        0
      ],
      "b"         : 0.49,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2047"      : {
    "inputs"     : {
      "conditioning" : [
        "2048",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2048"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2890",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2053"      : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "496",
        0
      ],
      "text2"     : [
        "2054",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2054"      : {
    "inputs"     : {
      "string_a"  : [
        "788",
        0
      ],
      "string_b"  : [
        "1318",
        0
      ],
      "delimiter" : ","
    },
    "class_type" : "StringConcatenate",
    "_meta"      : {
      "title" : "Concatenate"
    }
  },
  "2058"      : {
    "inputs"     : {
      "style_model_name" : "flex1_redux_siglip2_512.safetensors"
    },
    "class_type" : "StyleModelLoader",
    "_meta"      : {
      "title" : "Load Style Model"
    }
  },
  "2060"      : {
    "inputs"     : {
      "strength"           : 0.8,
      "strength_type"      : "multiply",
      "conditioning"       : [
        "2067",
        0
      ],
      "style_model"        : [
        "2058",
        0
      ],
      "clip_vision_output" : [
        "2063",
        0
      ]
    },
    "class_type" : "StyleModelApply",
    "_meta"      : {
      "title" : "Apply Style Model"
    }
  },
  "2062"      : {
    "inputs"     : {
      "clip_name" : "siglip2_so400m_patch16_512.safetensors"
    },
    "class_type" : "AdvancedVisionLoader",
    "_meta"      : {
      "title" : "Load Advanced Vision Model"
    }
  },
  "2063"      : {
    "inputs"     : {
      "crop"        : "none",
      "clip_vision" : [
        "2062",
        0
      ],
      "image"       : [
        "2925",
        0
      ]
    },
    "class_type" : "CLIPVisionEncode",
    "_meta"      : {
      "title" : "CLIP Vision Encode"
    }
  },
  "2065"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2085",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2066"      : {
    "inputs"     : {
      "any_02" : [
        "2704",
        0
      ],
      "any_03" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2067"      : {
    "inputs"     : {
      "clip_l"   : [
        "2088",
        0
      ],
      "t5xxl"    : [
        "2053",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2890",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2072"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : true,
      "hair_mask"       : true,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "2066",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2073"      : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskPreview+",
    "_meta"      : {
      "title" : "üîß Mask Preview"
    }
  },
  "2074"      : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : false,
      "mask"         : [
        "2079",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2079"      : {
    "inputs"     : {
      "invert_mask" : true,
      "grow"        : -8,
      "blur"        : 5,
      "mask"        : [
        "2072",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2080"      : {
    "inputs"     : {
      "mask" : [
        "2079",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2081"      : {
    "inputs"     : {
      "opacity"         : 50,
      "image"           : [
        "2066",
        0
      ],
      "color_ref_image" : [
        "2930",
        0
      ]
    },
    "class_type" : "LayerColor: ColorAdapter",
    "_meta"      : {
      "title" : "LayerColor: ColorAdapter"
    }
  },
  "2085"      : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : true,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 26,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.37,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 1,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2081",
        0
      ],
      "segs"               : [
        "2074",
        0
      ],
      "model"              : [
        "2086",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2060",
        0
      ],
      "negative"           : [
        "2047",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (Clothing Detailer)"
    }
  },
  "2086"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.75,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.45::0.5"
    }
  },
  "2088"      : {
    "inputs"     : {
      "separator" : ",",
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "496",
        0
      ]
    },
    "class_type" : "CR Text Concatenate",
    "_meta"      : {
      "title" : "üî§ CR Text Concatenate"
    }
  },
  "2100"      : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "343",
        0
      ],
      "when_false" : [
        "2101",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2101"      : {
    "inputs"     : {
      "condition"  : [
        "233",
        0
      ],
      "when_true"  : [
        "623",
        0
      ],
      "when_false" : [
        "623",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2102"      : {
    "inputs"     : {
      "condition"  : [
        "232",
        0
      ],
      "when_true"  : [
        "342",
        0
      ],
      "when_false" : [
        "342",
        1
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2103"      : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1919",
        0
      ],
      "when_false" : [
        "2104",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2104"      : {
    "inputs"     : {
      "condition"  : [
        "840",
        0
      ],
      "when_true"  : [
        "331",
        0
      ],
      "when_false" : [
        "1595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2105"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "26",
        0
      ],
      "when_false" : [
        "2581",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2106"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "953",
        0
      ],
      "when_false" : [
        "2595",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2108"      : {
    "inputs"     : {
      "condition"  : [
        "235",
        0
      ],
      "when_true"  : [
        "44",
        0
      ],
      "when_false" : [
        "1412",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2109"      : {
    "inputs"     : {
      "condition"  : [
        "1345",
        0
      ],
      "when_true"  : [
        "1837",
        0
      ],
      "when_false" : [
        "1566",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2110"      : {
    "inputs"     : {
      "condition"  : [
        "275",
        0
      ],
      "when_true"  : [
        "362",
        0
      ],
      "when_false" : [
        "1922",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2111"      : {
    "inputs"     : {
      "condition"  : [
        "325",
        0
      ],
      "when_true"  : [
        "2164",
        0
      ],
      "when_false" : [
        "567",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2117"      : {
    "inputs"     : {
      "any_02" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2152"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2153"      : {
    "inputs"     : {
      "mask" : [
        "2152",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2154"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2153",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2158"      : {
    "inputs"     : {
      "any_01" : [
        "2065",
        0
      ],
      "any_02" : [
        "2117",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2164"      : {
    "inputs"     : {
      "text" : "A professionally color-graded photograph of Indian v1dhya5 busty and curvy woman with extremely beautiful face with black bindi on the forehead, detailed natural skin texture, visible pores, soft peach fuzz, tiny vellus hairs illuminated by side lighting, faint acne marks and mild unevenness,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2178"      : {
    "inputs"     : {
      "value" : false
    },
    "class_type" : "PrimitiveBoolean",
    "_meta"      : {
      "title" : "Boolean"
    }
  },
  "2187"      : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : "(aidmarealisticskin:0.5)",
      "text3"     : " ",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2193"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 1,
      "blur"        : 0,
      "mask"        : [
        "55",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2197"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : true,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1400",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2198"      : {
    "inputs"     : {
      "overlay_resize" : "None",
      "resize_method"  : "nearest-exact",
      "rescale_factor" : 1,
      "width"          : 512,
      "height"         : 512,
      "x_offset"       : 0,
      "y_offset"       : 0,
      "rotation"       : 0,
      "opacity"        : 100,
      "base_image"     : [
        "2570",
        0
      ],
      "overlay_image"  : [
        "1400",
        0
      ],
      "optional_mask"  : [
        "2197",
        0
      ]
    },
    "class_type" : "Image Overlay",
    "_meta"      : {
      "title" : "Image Overlay"
    }
  },
  "2200"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : true,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : false,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1831",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2201"      : {
    "inputs"     : {
      "mask" : [
        "2200",
        0
      ]
    },
    "class_type" : "InvertMask",
    "_meta"      : {
      "title" : "InvertMask"
    }
  },
  "2202"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1831",
        0
      ],
      "mask"           : [
        "2201",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2203"      : {
    "inputs"     : {
      "image" : [
        "2202",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2204"      : {
    "inputs"     : {
      "image" : [
        "1831",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2212"      : {
    "inputs"     : {
      "input1" : [
        "2240",
        0
      ],
      "input2" : 2048
    },
    "class_type" : "LogicUtil_LogicGateBitwiseXor",
    "_meta"      : {
      "title" : "LogicUtil_Bitwise Xor"
    }
  },
  "2213"      : {
    "inputs"     : {
      "clip_a"  : [
        "2644",
        1
      ],
      "clip_b"  : [
        "2276",
        1
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2224"      : {
    "inputs"     : {
      "model_a" : [
        "2254",
        0
      ],
      "model_b" : [
        "2276",
        0
      ],
      "boolean" : [
        "325",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2231"      : {
    "inputs"     : {
      "control_net_name" : "flux_shakker_labs_union_pro-fp8_e4m3fn.safetensors"
    },
    "class_type" : "ControlNetLoader",
    "_meta"      : {
      "title" : "Load ControlNet Model"
    }
  },
  "2237"      : {
    "inputs"     : {
      "model_name" : "4x-UltraSharpV2.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2240"      : {
    "inputs"     : {
      "mode"       : true,
      "seed"       : -1,
      "fixed_seed" : 0
    },
    "class_type" : "SeedSelector",
    "_meta"      : {
      "title" : "Seed Selector"
    }
  },
  "2245"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2246"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1.0000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2247"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2250"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2253"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2296",
        0
      ],
      "clip"           : [
        "2296",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2254"      : {
    "inputs"     : {
      "img_in."           : 1,
      "time_in."          : 1,
      "guidance_in"       : 1,
      "vector_in."        : 1,
      "txt_in."           : 1,
      "double_blocks.0."  : 1,
      "double_blocks.1."  : 1,
      "double_blocks.2."  : 1,
      "double_blocks.3."  : 1,
      "double_blocks.4."  : 1,
      "double_blocks.5."  : 1,
      "double_blocks.6."  : 1,
      "double_blocks.7."  : 1,
      "double_blocks.8."  : 1,
      "double_blocks.9."  : 1,
      "double_blocks.10." : 1,
      "double_blocks.11." : 1,
      "double_blocks.12." : 1,
      "double_blocks.13." : 1,
      "double_blocks.14." : 1,
      "double_blocks.15." : 1,
      "double_blocks.16." : 1,
      "double_blocks.17." : 1,
      "double_blocks.18." : 1,
      "single_blocks.0."  : 1,
      "single_blocks.1."  : 1,
      "single_blocks.2."  : 1,
      "single_blocks.3."  : 1,
      "single_blocks.4."  : 1,
      "single_blocks.5."  : 1,
      "single_blocks.6."  : 1,
      "single_blocks.7."  : 1,
      "single_blocks.8."  : 1,
      "single_blocks.9."  : 1,
      "single_blocks.10." : 1,
      "single_blocks.11." : 1,
      "single_blocks.12." : 1,
      "single_blocks.13." : 1,
      "single_blocks.14." : 1,
      "single_blocks.15." : 1,
      "single_blocks.16." : 1,
      "single_blocks.17." : 1,
      "single_blocks.18." : 1,
      "single_blocks.19." : 0,
      "single_blocks.20." : 0,
      "single_blocks.21." : 0,
      "single_blocks.22." : 0,
      "single_blocks.23." : 0,
      "single_blocks.24." : 0,
      "single_blocks.25." : 0,
      "single_blocks.26." : 0,
      "single_blocks.27." : 0,
      "single_blocks.28." : 0,
      "single_blocks.29." : 0,
      "single_blocks.30." : 0,
      "single_blocks.31." : 0,
      "single_blocks.32." : 0,
      "single_blocks.33." : 0,
      "single_blocks.34." : 0,
      "single_blocks.35." : 0,
      "single_blocks.36." : 0,
      "single_blocks.37." : 0,
      "final_layer."      : 1,
      "model1"            : [
        "2908",
        0
      ],
      "model2"            : [
        "2644",
        0
      ]
    },
    "class_type" : "ModelMergeFlux1",
    "_meta"      : {
      "title" : "ModelMergeFlux1"
    }
  },
  "2257"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.1,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "v1dhya5"
    }
  },
  "2262"      : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.8000000000000002,
      "strength_clip"  : 0.8,
      "model"          : [
        "2250",
        0
      ],
      "clip"           : [
        "2250",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2273"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA ::0.8:0.2"
    }
  },
  "2275"      : {
    "inputs"     : {
      "lora_name"      : "flux_vividizer.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmafluxproultra"
    }
  },
  "2276"      : {
    "inputs"     : {
      "lora_name"      : "Illustration Comic book_(FLUX)_06.safetensors",
      "strength_model" : 0.66,
      "strength_clip"  : 1.0000000000000002,
      "model"          : [
        "2262",
        0
      ],
      "clip"           : [
        "2262",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2277"      : {
    "inputs"     : {
      "lora_name"      : "aidmaImageUprader-FLUX-v0.3.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "2275",
        0
      ],
      "clip"           : [
        "2275",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2291"      : {
    "inputs"     : {
      "clip_a"  : [
        "2293",
        1
      ],
      "clip_b"  : [
        "2729",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2292"      : {
    "inputs"     : {
      "model_a" : [
        "2293",
        0
      ],
      "model_b" : [
        "2729",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2293"      : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.8,
      "model"          : [
        "2246",
        0
      ],
      "clip"           : [
        "2246",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2296"      : {
    "inputs"     : {
      "lora_name"      : "aidmaFluxProUltra-FLUX-v0.1.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2247",
        0
      ],
      "clip"           : [
        "2247",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2300"      : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 3.2,
      "strength_clip"  : 1,
      "model"          : [
        "3007",
        0
      ],
      "clip"           : [
        "3007",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2 [3.80::3.80]"
    }
  },
  "2302"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 0.7,
      "model"          : [
        "2245",
        0
      ],
      "clip"           : [
        "2245",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Realism"
    }
  },
  "2304"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2305"      : {
    "inputs"     : {
      "conditioning" : [
        "2304",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2316"      : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2317",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2875",
        1
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2317"      : {
    "inputs"     : {
      "text1"     : "masterpiece professional potrait photograph of v1dhya5 indian",
      "text2"     : [
        "1479",
        0
      ],
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2319"      : {
    "inputs"     : {
      "max_shift"  : 1.15,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2875",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2321"      : {
    "inputs"     : {
      "radius"          : 4,
      "amount"          : 0.8,
      "reduce_noise"    : 0.01,
      "fade_shadows"    : 0.2,
      "fade_highlights" : 0,
      "image"           : [
        "2332",
        0
      ]
    },
    "class_type" : "SmartSharpen",
    "_meta"      : {
      "title" : "SharpnessPro ¬∑ Nettet√© optimis√©e"
    }
  },
  "2325"      : {
    "inputs"     : {
      "detail_amount"      : 0.32,
      "start"              : 0.2,
      "end"                : 0.8,
      "bias"               : 0.5,
      "exponent"           : 1,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : false,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "2957",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2331"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 18,
      "denoise"   : 0.26,
      "model"     : [
        "2875",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2332"      : {
    "inputs"     : {
      "upscale_by"          : 1,
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 18,
      "cfg"                 : 1,
      "sampler_name"        : "euler",
      "scheduler"           : "beta",
      "denoise"             : 0.26,
      "mode_type"           : "Linear",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : false,
      "tiled_decode"        : false,
      "image"               : [
        "2930",
        0
      ],
      "model"               : [
        "2319",
        0
      ],
      "positive"            : [
        "2316",
        0
      ],
      "negative"            : [
        "2305",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2961",
        0
      ],
      "custom_sampler"      : [
        "2325",
        0
      ],
      "custom_sigmas"       : [
        "2331",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2339"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2996:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2345"      : {
    "inputs"     : {
      "any_02" : [
        "2065",
        0
      ],
      "any_04" : [
        "2704",
        0
      ],
      "any_05" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2355"      : {
    "inputs"     : {
      "face_mask"       : true,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : false,
      "confidence"      : 0.4,
      "refine_mask"     : true,
      "batch_size"      : 2,
      "compute_device"  : "auto",
      "images"          : [
        "2345",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2365"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "2403",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "2371"      : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2372"      : {
    "inputs"     : {
      "conditioning" : [
        "2371",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2377"      : {
    "inputs"     : {
      "clip_l"   : [
        "2106",
        0
      ],
      "t5xxl"    : [
        "2404",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2384"      : {
    "inputs"     : {
      "any_01" : [
        "3011",
        0
      ],
      "any_03" : [
        "2339",
        0
      ],
      "any_05" : [
        "2065",
        0
      ],
      "any_07" : [
        "2704",
        0
      ],
      "any_08" : [
        "1885",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "2393"      : {
    "inputs"     : {
      "scheduler" : "beta",
      "steps"     : 18,
      "denoise"   : 0.24,
      "model"     : [
        "2224",
        0
      ]
    },
    "class_type" : "BasicScheduler",
    "_meta"      : {
      "title" : "BasicScheduler"
    }
  },
  "2398"      : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.45,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "ModelSamplingFlux"
    }
  },
  "2403"      : {
    "inputs"     : {
      "upscale_by"          : [
        "1740",
        0
      ],
      "seed"                : [
        "2212",
        0
      ],
      "steps"               : 28,
      "cfg"                 : 1,
      "sampler_name"        : "heun",
      "scheduler"           : "beta",
      "denoise"             : 0.26,
      "mode_type"           : "Chess",
      "tile_width"          : 1024,
      "tile_height"         : 1024,
      "mask_blur"           : 32,
      "tile_padding"        : 64,
      "seam_fix_mode"       : "None",
      "seam_fix_denoise"    : 1,
      "seam_fix_width"      : 64,
      "seam_fix_mask_blur"  : 8,
      "seam_fix_padding"    : 16,
      "force_uniform_tiles" : true,
      "tiled_decode"        : false,
      "image"               : [
        "2384",
        0
      ],
      "model"               : [
        "2398",
        0
      ],
      "positive"            : [
        "2377",
        0
      ],
      "negative"            : [
        "2372",
        0
      ],
      "vae"                 : [
        "2889",
        0
      ],
      "upscale_model"       : [
        "2961",
        0
      ],
      "custom_sampler"      : [
        "2957",
        0
      ],
      "custom_sigmas"       : [
        "2393",
        0
      ]
    },
    "class_type" : "UltimateSDUpscaleCustomSample",
    "_meta"      : {
      "title" : "Ultimate SD Upscale (Custom Sample)"
    }
  },
  "2404"      : {
    "inputs"     : {
      "text1"     : [
        "788",
        0
      ],
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2529"      : {
    "inputs"     : {
      "expression" : "max(a,b)/min(a,b)",
      "a"          : [
        "1913",
        1
      ],
      "b"          : [
        "1913",
        2
      ]
    },
    "class_type" : "MathExpression|pysssss",
    "_meta"      : {
      "title" : "Math Expression üêç"
    }
  },
  "2532"      : {
    "inputs"     : {
      "condition"  : [
        "2535",
        0
      ],
      "when_true"  : [
        "2534",
        0
      ],
      "when_false" : [
        "2103",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2534"      : {
    "inputs"     : {
      "a"         : [
        "2103",
        0
      ],
      "b"         : 0.5,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2535"      : {
    "inputs"     : {
      "comparison" : "a >= b",
      "a"          : [
        "2529",
        0
      ],
      "b"          : [
        "2536",
        0
      ]
    },
    "class_type" : "easy compare",
    "_meta"      : {
      "title" : "Compare"
    }
  },
  "2536"      : {
    "inputs"     : {
      "value" : 1.72
    },
    "class_type" : "FloatConstant",
    "_meta"      : {
      "title" : "Float Constant"
    }
  },
  "2541"      : {
    "inputs"     : {
      "a"         : [
        "1955",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "0.72"
    }
  },
  "2543"      : {
    "inputs"     : {
      "int_" : [
        "2110",
        0
      ]
    },
    "class_type" : "CR Integer To String",
    "_meta"      : {
      "title" : "üîß CR Integer To String"
    }
  },
  "2544"      : {
    "inputs"     : {
      "text" : [
        "283",
        0
      ]
    },
    "class_type" : "JWStringToInteger",
    "_meta"      : {
      "title" : "String to Integer"
    }
  },
  "2545"      : {
    "inputs"     : {
      "strings"   : "Inputs/Next/Best\nInputs/Next/best",
      "multiline" : false,
      "select"    : 0
    },
    "class_type" : "ImpactStringSelector",
    "_meta"      : {
      "title" : "String Selector"
    }
  },
  "2553"      : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2555"      : {
    "inputs"     : {
      "text1"     : "The subject is having a ",
      "text2"     : [
        "513",
        0
      ],
      "text3"     : " facial expression",
      "delimiter" : ""
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "textConcat"
    }
  },
  "2560"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2257",
        0
      ],
      "clip"           : [
        "2257",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Pandora-RAWr"
    }
  },
  "2567"      : {
    "inputs"     : {
      "text"             : [
        "1838",
        0
      ],
      "sub_text"         : "TT",
      "case_insensitive" : false
    },
    "class_type" : "Text Contains",
    "_meta"      : {
      "title" : "Contains [TT]"
    }
  },
  "2570"      : {
    "inputs"     : {
      "condition"  : [
        "2567",
        0
      ],
      "when_true"  : [
        "2154",
        0
      ],
      "when_false" : [
        "1831",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2580"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "249",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2581"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2580",
        0
      ],
      "text_b"           : [
        "484",
        0
      ],
      "text_c"           : [
        "2590",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2590"      : {
    "inputs"     : {
      "prompt"           : [
        "515",
        0
      ],
      "camera"           : "Fujifilm X-T5",
      "composition_shot" : "None",
      "time_of_day"      : "None",
      "color_grading"    : "Vivid",
      "lighting"         : "Practical Lighting",
      "environment"      : "None"
    },
    "class_type" : "Magic Photo Prompter ü™Ñ",
    "_meta"      : {
      "title" : "Magic Photo Prompter ü™Ñ"
    }
  },
  "2595"      : {
    "inputs"     : {
      "find"    : "__AGE__",
      "replace" : [
        "2598",
        0
      ],
      "text"    : [
        "950",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2598"      : {
    "inputs"     : {
      "string"  : "__{{ age }}__ years old ",
      "find"    : "__{{ age }}__",
      "replace" : [
        "2543",
        0
      ]
    },
    "class_type" : "StringReplace",
    "_meta"      : {
      "title" : "Replace"
    }
  },
  "2605"      : {
    "inputs"     : {
      "text1"     : [
        "2106",
        0
      ],
      "text2"     : [
        "788",
        0
      ],
      "text3"     : [
        "1318",
        0
      ],
      "delimiter" : "/n_________________________/n"
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Positive"
    }
  },
  "2609"      : {
    "inputs"     : {
      "file_prefix"   : [
        "2611",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2611"      : {
    "inputs"     : {
      "text1" : "Generated_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2612"      : {
    "inputs"     : {
      "file_prefix"   : [
        "2614",
        0
      ],
      "time_format"   : "%Y%m%dT%H%M",
      "output_folder" : "",
      "filetype"      : ""
    },
    "class_type" : "FilePathCreator",
    "_meta"      : {
      "title" : "File Path Creator"
    }
  },
  "2614"      : {
    "inputs"     : {
      "text1" : "Prompt_",
      "text2" : [
        "1931",
        0
      ]
    },
    "class_type" : "TextCombinerTwo",
    "_meta"      : {
      "title" : "Text Combiner 2"
    }
  },
  "2615"      : {
    "inputs"     : {
      "path"                    : "./output/[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "2612",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "file_extension"          : ".txt",
      "encoding"                : "utf-8",
      "filename_suffix"         : "",
      "text"                    : [
        "2605",
        0
      ]
    },
    "class_type" : "Save Text File",
    "_meta"      : {
      "title" : "Save Text File"
    }
  },
  "2618"      : {
    "inputs"     : {
      "lora_name"      : "BreastShaper_splendid_droplets_Flux_v3.0-000009.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.2,
      "model"          : [
        "2253",
        0
      ],
      "clip"           : [
        "2253",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2644"      : {
    "inputs"     : {
      "lora_name"      : "Flux_Lora_32F_Breasts.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 1,
      "model"          : [
        "2300",
        0
      ],
      "clip"           : [
        "2300",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Flux_Lora_32F_Breasts"
    }
  },
  "2652"      : {
    "inputs"     : {
      "text" : "aidmaimageupgrader, fluxenhancer, detailed hands, Perfect hand"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2655"      : {
    "inputs"     : {
      "lora_name"      : "Detailed_Hands-000001.safetensors",
      "strength_model" : 0.4,
      "strength_clip"  : 0.4,
      "model"          : [
        "3030",
        0
      ],
      "clip"           : [
        "3030",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "fluxenhancer"
    }
  },
  "2656"      : {
    "inputs"     : {
      "text" : "fluxenhancer,aidmaimageupgrader, d351 d4rk, aidmarealisticskin, aidmafluxproultra, slicked back hairstyle:1.2, high ponytail:1.3, pulled back hairstyle:1.2, Skin imperfections , Freckles, moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2666"      : {
    "inputs"     : {
      "detail_amount"      : 0.08,
      "start"              : 0.33,
      "end"                : 0.66,
      "bias"               : 0.5,
      "exponent"           : 0.8,
      "start_offset"       : 0,
      "end_offset"         : 0,
      "fade"               : 0,
      "smooth"             : true,
      "cfg_scale_override" : 1,
      "sampler"            : [
        "1909",
        0
      ]
    },
    "class_type" : "DetailDaemonSamplerNode",
    "_meta"      : {
      "title" : "Detail Daemon Sampler"
    }
  },
  "2669"      : {
    "inputs"     : {
      "image" : [
        "2670",
        0
      ]
    },
    "class_type" : "GetImageSizeAndCount",
    "_meta"      : {
      "title" : "Get Image Size & Count"
    }
  },
  "2670"      : {
    "inputs"     : {
      "samples" : [
        "1989",
        0
      ],
      "vae"     : [
        "2889",
        0
      ]
    },
    "class_type" : "VAEDecode",
    "_meta"      : {
      "title" : "VAE Decode"
    }
  },
  "2671"      : {
    "inputs"     : {
      "images" : [
        "832",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2672"      : {
    "inputs"     : {
      "shadow_brightness"      : 0.88,
      "shadow_saturation"      : 1,
      "shadow_hue"             : 0,
      "shadow_level_offset"    : 0,
      "shadow_range"           : 0.25,
      "highlight_brightness"   : 0.97,
      "highlight_saturation"   : 1,
      "highlight_hue"          : 0,
      "highlight_level_offset" : 0,
      "highlight_range"        : 0.25,
      "image"                  : [
        "2198",
        0
      ]
    },
    "class_type" : "LayerColor: Color of Shadow & Highlight",
    "_meta"      : {
      "title" : "LayerColor: Color of Shadow & Highlight"
    }
  },
  "2675"      : {
    "inputs"     : {
      "strength"   : 100,
      "brightness" : 0,
      "contrast"   : 0,
      "saturation" : 0,
      "red"        : 27,
      "green"      : 17,
      "blue"       : 0,
      "mode"       : "RGB",
      "image"      : [
        "2570",
        0
      ]
    },
    "class_type" : "LayerColor: AutoAdjustV2",
    "_meta"      : {
      "title" : "LayerColor: AutoAdjust V2"
    }
  },
  "2695"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2273",
        0
      ],
      "clip"           : [
        "2273",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2703"      : {
    "inputs"     : {
      "image" : [
        "1885",
        0
      ]
    },
    "class_type" : "ImpactImageBatchToImageList",
    "_meta"      : {
      "title" : "Image Batch to Image List"
    }
  },
  "2704"      : {
    "inputs"     : {
      "images" : [
        "339",
        0
      ]
    },
    "class_type" : "ImageListToImageBatch",
    "_meta"      : {
      "title" : "Image List to Image Batch"
    }
  },
  "2715"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "3015",
        1
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2727"      : {
    "inputs"     : {
      "preprocessor" : "DepthAnythingPreprocessor",
      "resolution"   : [
        "1942",
        0
      ],
      "image"        : [
        "2703",
        0
      ]
    },
    "class_type" : "AIO_Preprocessor",
    "_meta"      : {
      "title" : "AIO Aux Preprocessor"
    }
  },
  "2729"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2302",
        0
      ],
      "clip"           : [
        "2302",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2734"      : {
    "inputs"     : {
      "question"          : "Describe the Facial expression of the subject, hair style, jewelry and outfit. Also, describe about  the make-up, eyes and lipstick",
      "seed"              : [
        "2240",
        0
      ],
      "temperature"       : 0.6,
      "top_p"             : 0.95,
      "max_new_tokens"    : 512,
      "keep_model_loaded" : [
        "2178",
        0
      ],
      "model"             : [
        "564",
        0
      ],
      "image"             : [
        "1271",
        0
      ]
    },
    "class_type" : "JanusProDescribeImage|Mie",
    "_meta"      : {
      "title" : "Janus Pro Describe Image üêë"
    }
  },
  "2751"      : {
    "inputs"     : {
      "find"    : "woman",
      "replace" : "young girl",
      "text"    : [
        "2756",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2754"      : {
    "inputs"     : {
      "find"    : "image",
      "replace" : "photo",
      "text"    : [
        "2755",
        0
      ]
    },
    "class_type" : "Text Find and Replace",
    "_meta"      : {
      "title" : "Text Find and Replace"
    }
  },
  "2755"      : {
    "inputs"     : {
      "condition"  : [
        "268",
        0
      ],
      "when_true"  : [
        "2751",
        0
      ],
      "when_false" : [
        "2756",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2756"      : {
    "inputs"     : {
      "delimiter"        : ",",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2111",
        0
      ],
      "text_b"           : [
        "271",
        0
      ],
      "text_c"           : [
        "2734",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2862"      : {
    "inputs"     : {
      "text" : "aidmafluxproultra, fluxenhancer, Skin imperfections ,   moles, natural blemishes, Rough skin texture, "
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2874"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2277",
        0
      ],
      "clip"           : [
        "2277",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2875"      : {
    "inputs"     : {
      "lora_name"      : "d351_Coffee_Krea_Kohya_V1_Unchained_prodigy-000012.safetensors",
      "strength_model" : 1,
      "strength_clip"  : 1,
      "model"          : [
        "2618",
        0
      ],
      "clip"           : [
        "2618",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2881"      : {
    "inputs"     : {
      "lora_name"      : "breast-size2.safetensors",
      "strength_model" : 2.6,
      "strength_clip"  : 1,
      "model"          : [
        "2695",
        0
      ],
      "clip"           : [
        "2695",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "breast-size2 [3.20::3.20]"
    }
  },
  "2888"      : {
    "inputs"     : {
      "stop_at_clip_layer" : -3,
      "clip"               : [
        "2893",
        0
      ]
    },
    "class_type" : "CLIPSetLastLayer",
    "_meta"      : {
      "title" : "CLIP Set Last Layer"
    }
  },
  "2889"      : {
    "inputs"     : {
      "vae_name" : "ae.safetensors"
    },
    "class_type" : "VAELoader",
    "_meta"      : {
      "title" : "FLUX VAE"
    }
  },
  "2890"      : {
    "inputs"     : {
      "q"    : 1.2,
      "k"    : 1.1,
      "v"    : 0.8,
      "out"  : 1.25,
      "clip" : [
        "2888",
        0
      ]
    },
    "class_type" : "CLIPAttentionMultiply",
    "_meta"      : {
      "title" : "CLIPAttentionMultiply"
    }
  },
  "2891"      : {
    "inputs"     : {
      "block_number"         : 4,
      "downscale_factor"     : 2,
      "start_percent"        : 0,
      "end_percent"          : 0.5,
      "downscale_after_skip" : true,
      "downscale_method"     : "bislerp",
      "upscale_method"       : "bislerp",
      "model"                : [
        "2894",
        0
      ]
    },
    "class_type" : "PatchModelAddDownscale",
    "_meta"      : {
      "title" : "PatchModelAddDownscale"
    }
  },
  "2892"      : {
    "inputs"     : {
      "sampler_name" : "euler_ancestral"
    },
    "class_type" : "KSamplerSelect",
    "_meta"      : {
      "title" : "KSamplerSelect"
    }
  },
  "2893"      : {
    "inputs"     : {
      "clip_name1" : "clip_l.safetensors",
      "clip_name2" : "t5xxl_fp16.safetensors",
      "type"       : "flux",
      "device"     : "cpu"
    },
    "class_type" : "DualCLIPLoader",
    "_meta"      : {
      "title" : "DualCLIPLoader"
    }
  },
  "2894"      : {
    "inputs"     : {
      "unet_name"    : "flux1-dev.safetensors",
      "weight_dtype" : "fp8_e4m3fn"
    },
    "class_type" : "UNETLoader",
    "_meta"      : {
      "title" : "Load Diffusion Model"
    }
  },
  "2908"      : {
    "inputs"     : {
      "lora_name"      : "SameFace_Fix.safetensors",
      "strength_model" : -0.6,
      "strength_clip"  : 1,
      "model"          : [
        "2560",
        0
      ],
      "clip"           : [
        "2560",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "SameFaceNegatice"
    }
  },
  "2922"      : {
    "inputs"     : {
      "images" : [
        "2925",
        0
      ]
    },
    "class_type" : "PreviewImage",
    "_meta"      : {
      "title" : "Preview Image"
    }
  },
  "2925"      : {
    "inputs"     : {
      "padding_left"   : 32,
      "padding_right"  : 32,
      "padding_top"    : 72,
      "padding_bottom" : 64,
      "return_list"    : false,
      "image"          : [
        "1837",
        0
      ],
      "mask"           : [
        "2927",
        0
      ]
    },
    "class_type" : "Bounded Image Crop with Mask",
    "_meta"      : {
      "title" : "Bounded Image Crop with Mask"
    }
  },
  "2927"      : {
    "inputs"     : {
      "face_mask"       : false,
      "background_mask" : false,
      "hair_mask"       : false,
      "body_mask"       : false,
      "clothes_mask"    : true,
      "confidence"      : 0.54,
      "refine_mask"     : true,
      "batch_size"      : 8,
      "compute_device"  : "auto",
      "images"          : [
        "1837",
        0
      ]
    },
    "class_type" : "APersonMaskGenerator",
    "_meta"      : {
      "title" : "A Person Mask Generator"
    }
  },
  "2929"      : {
    "inputs"     : {
      "channel"            : "RGB",
      "input_black_point"  : 0,
      "input_gamma"        : 1.1,
      "input_white_point"  : 1,
      "output_black_point" : 0,
      "output_white_point" : 1,
      "image"              : [
        "2672",
        0
      ]
    },
    "class_type" : "Levels",
    "_meta"      : {
      "title" : "Levels"
    }
  },
  "2930"      : {
    "inputs"     : {
      "brightness_target"   : 0.5,
      "cyan_red"            : 0.02,
      "magenta_green"       : 0,
      "yellow_blue"         : 0.05,
      "preserve_luminosity" : true,
      "image"               : [
        "2929",
        0
      ]
    },
    "class_type" : "ColorBalanceAdvanced",
    "_meta"      : {
      "title" : "Color Balance Advanced"
    }
  },
  "2931"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "3020",
        0
      ],
      "clip"           : [
        "3020",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2936"      : {
    "inputs"     : {
      "clip_a"  : [
        "2940",
        1
      ],
      "clip_b"  : [
        "2931",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2939"      : {
    "inputs"     : {
      "model_a" : [
        "2940",
        0
      ],
      "model_b" : [
        "2931",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2940"      : {
    "inputs"     : {
      "lora_name"      : "ILLUSTRATION (FLUX) - V3.1.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.21,
      "model"          : [
        "2941",
        0
      ],
      "clip"           : [
        "2941",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA"
    }
  },
  "2941"      : {
    "inputs"     : {
      "lora_name"      : "vidhyas_lora_v3.safetensors",
      "strength_model" : 0.8,
      "strength_clip"  : 0.2,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "Load LoRA ::0.8:0.2"
    }
  },
  "2945"      : {
    "inputs"     : {
      "model_a" : [
        "2277",
        0
      ],
      "model_b" : [
        "2874",
        0
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "Model Input Switch",
    "_meta"      : {
      "title" : "Model Input Switch"
    }
  },
  "2946"      : {
    "inputs"     : {
      "clip_a"  : [
        "2277",
        1
      ],
      "clip_b"  : [
        "2874",
        1
      ],
      "boolean" : [
        "322",
        0
      ]
    },
    "class_type" : "CLIP Input Switch",
    "_meta"      : {
      "title" : "CLIP Input Switch"
    }
  },
  "2957"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "2959",
        0
      ],
      "when_false" : [
        "2892",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2959"      : {
    "inputs"     : {
      "sampler_name" : "euler"
    },
    "class_type" : "KSamplerSelect",
    "_meta"      : {
      "title" : "KSamplerSelect"
    }
  },
  "2961"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "2237",
        0
      ],
      "when_false" : [
        "2963",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2963"      : {
    "inputs"     : {
      "model_name" : "4xPurePhoto-Span.pth"
    },
    "class_type" : "UpscaleModelLoader",
    "_meta"      : {
      "title" : "Load Upscale Model"
    }
  },
  "2964"      : {
    "inputs"     : {
      "condition"  : [
        "322",
        0
      ],
      "when_true"  : [
        "1863",
        0
      ],
      "when_false" : [
        "1871",
        0
      ]
    },
    "class_type" : "InputSelector",
    "_meta"      : {
      "title" : "Input Selector"
    }
  },
  "2973"      : {
    "inputs"     : {
      "text" : "aidmarealisticskin, Skin imperfections,"
    },
    "class_type" : "Text Multiline",
    "_meta"      : {
      "title" : "Text Multiline"
    }
  },
  "2975"      : {
    "inputs"     : {
      "invert_mask" : false,
      "grow"        : 2,
      "blur"        : 4,
      "mask"        : [
        "2355",
        0
      ]
    },
    "class_type" : "LayerMask: MaskGrow",
    "_meta"      : {
      "title" : "LayerMask: MaskGrow"
    }
  },
  "2983"      : {
    "inputs"     : {
      "a"         : [
        "2102",
        0
      ],
      "b"         : 0.72,
      "operation" : "multiply"
    },
    "class_type" : "easy mathFloat",
    "_meta"      : {
      "title" : "Math Float"
    }
  },
  "2997"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "2345",
        0
      ],
      "mask"         : [
        "2975",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "3003"      : {
    "inputs"     : {
      "level" : 1.2
    },
    "class_type" : "ImageSaturation",
    "_meta"      : {
      "title" : "Adjust Saturation"
    }
  },
  "3007"      : {
    "inputs"     : {
      "lora_name"      : "aidmaRealisticSkin-FLUX-v0.1.safetensors",
      "strength_model" : 0.6,
      "strength_clip"  : 0.1,
      "model"          : [
        "2908",
        0
      ],
      "clip"           : [
        "2908",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "3011"      : {
    "inputs"     : {
      "output_path"             : "[time(%Y-%m-%d)]",
      "filename_prefix"         : [
        "1930",
        0
      ],
      "filename_delimiter"      : "_",
      "filename_number_padding" : 4,
      "filename_number_start"   : "false",
      "extension"               : "png",
      "dpi"                     : 300,
      "quality"                 : 100,
      "optimize_image"          : "true",
      "lossless_webp"           : "false",
      "overwrite_mode"          : "prefix_as_filename",
      "show_history"            : "false",
      "show_history_by_prefix"  : "false",
      "embed_workflow"          : "true",
      "show_previews"           : "false",
      "images"                  : [
        "3014:548",
        0
      ]
    },
    "class_type" : "Image Save",
    "_meta"      : {
      "title" : "Image Save"
    }
  },
  "3013"      : {
    "inputs"     : {
      "mask_opacity" : 0.3,
      "mask_color"   : "255, 0, 207",
      "pass_through" : false,
      "image"        : [
        "1611",
        0
      ],
      "mask"         : [
        "2715",
        0
      ]
    },
    "class_type" : "ImageAndMaskPreview",
    "_meta"      : {
      "title" : "ImageAndMaskPreview"
    }
  },
  "3015"      : {
    "inputs"     : {
      "method"          : "human_parsing_lip",
      "confidence"      : 0.4,
      "crop_multi"      : 0,
      "mask_components" : {
        "__value__" : [
          14,
          15
        ]
      },
      "image"           : [
        "1611",
        0
      ]
    },
    "class_type" : "easy humanSegmentation",
    "_meta"      : {
      "title" : "Human Segmentation"
    }
  },
  "3018"      : {
    "inputs"     : {
      "opacity"         : 50,
      "image"           : [
        "1888",
        0
      ],
      "color_ref_image" : [
        "2669",
        0
      ]
    },
    "class_type" : "LayerColor: ColorAdapter",
    "_meta"      : {
      "title" : "LayerColor: ColorAdapter"
    }
  },
  "3020"      : {
    "inputs"     : {
      "lora_name"      : "Flux_Lora_32F_Breasts.safetensors",
      "strength_model" : 0.7,
      "strength_clip"  : 1,
      "model"          : [
        "2881",
        0
      ],
      "clip"           : [
        "2881",
        1
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "3023"      : {
    "inputs"     : {
      "any_01" : [
        "2339",
        0
      ],
      "any_02" : [
        "2158",
        0
      ]
    },
    "class_type" : "Any Switch (rgthree)",
    "_meta"      : {
      "title" : "Any Switch (rgthree)"
    }
  },
  "3030"      : {
    "inputs"     : {
      "lora_name"      : "Pandora-RAWr.safetensors",
      "strength_model" : 0.65,
      "strength_clip"  : 0.65,
      "model"          : [
        "2891",
        0
      ],
      "clip"           : [
        "2890",
        0
      ]
    },
    "class_type" : "LoraLoader",
    "_meta"      : {
      "title" : "aidmarealisticskin"
    }
  },
  "2996:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "2996:2975",
        0
      ],
      "t5xxl"    : [
        "2996:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "2996:113"  : {
    "inputs"     : {
      "max_shift"  : 1.55,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "2996:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2975",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "2996:54"   : {
    "inputs"     : {
      "conditioning" : [
        "2996:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "2996:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "2996:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "2996:2973",
        0
      ],
      "text_c"           : [
        "2973",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2996:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "2106",
        0
      ],
      "text_b"           : [
        "2996:2972",
        0
      ],
      "text_c"           : [
        "2973",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "2996:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "2996:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "Happy, cheerfull facial expression, ",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "2996:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 23,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : [
        "2983",
        0
      ],
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "2345",
        0
      ],
      "segs"               : [
        "2996:88",
        0
      ],
      "model"              : [
        "2996:113",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "2996:506",
        0
      ],
      "negative"           : [
        "2996:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  },
  "3014:506"  : {
    "inputs"     : {
      "clip_l"   : [
        "3014:2975",
        0
      ],
      "t5xxl"    : [
        "3014:2976",
        0
      ],
      "guidance" : 3.5,
      "clip"     : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncodeFlux",
    "_meta"      : {
      "title" : "CLIPTextEncodeFlux"
    }
  },
  "3014:113"  : {
    "inputs"     : {
      "max_shift"  : 1.45,
      "base_shift" : 0.5,
      "width"      : 1024,
      "height"     : 1024,
      "model"      : [
        "2224",
        0
      ]
    },
    "class_type" : "ModelSamplingFlux",
    "_meta"      : {
      "title" : "1.35::0.50"
    }
  },
  "3014:88"   : {
    "inputs"     : {
      "combined"     : true,
      "crop_factor"  : 3,
      "bbox_fill"    : false,
      "drop_size"    : 10,
      "contour_fill" : true,
      "mask"         : [
        "2715",
        0
      ]
    },
    "class_type" : "MaskToSEGS",
    "_meta"      : {
      "title" : "MASK to SEGS"
    }
  },
  "3014:54"   : {
    "inputs"     : {
      "conditioning" : [
        "3014:53",
        0
      ]
    },
    "class_type" : "ConditioningZeroOut",
    "_meta"      : {
      "title" : "ConditioningZeroOut"
    }
  },
  "3014:53"   : {
    "inputs"     : {
      "text" : "",
      "clip" : [
        "2213",
        0
      ]
    },
    "class_type" : "CLIPTextEncode",
    "_meta"      : {
      "title" : "Negative Prompt"
    }
  },
  "3014:2976" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_a"           : [
        "788",
        0
      ],
      "text_b"           : [
        "3014:2973",
        0
      ],
      "text_c"           : [
        "2652",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "3014:2975" : {
    "inputs"     : {
      "delimiter"        : ", ",
      "clean_whitespace" : "true",
      "text_b"           : [
        "3014:2972",
        0
      ],
      "text_c"           : [
        "2652",
        0
      ]
    },
    "class_type" : "Text Concatenate",
    "_meta"      : {
      "title" : "Text Concatenate"
    }
  },
  "3014:2972" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "Detailed female hands, Diamond ring in one finger. No Nailpolish,",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt ClipL Additional"
    }
  },
  "3014:2973" : {
    "inputs"     : {
      "text1"     : "",
      "text2"     : "",
      "text3"     : "",
      "delimiter" : ","
    },
    "class_type" : "ttN concat",
    "_meta"      : {
      "title" : "Prompt t5xxl Additional"
    }
  },
  "3014:548"  : {
    "inputs"     : {
      "guide_size"         : 1024,
      "guide_size_for"     : false,
      "max_size"           : 1024,
      "seed"               : [
        "2212",
        0
      ],
      "steps"              : 23,
      "cfg"                : 1,
      "sampler_name"       : "euler",
      "scheduler"          : "beta",
      "denoise"            : 0.42,
      "feather"            : 5,
      "noise_mask"         : true,
      "force_inpaint"      : true,
      "wildcard"           : "",
      "cycle"              : 2,
      "inpaint_model"      : false,
      "noise_mask_feather" : 20,
      "tiled_encode"       : false,
      "tiled_decode"       : false,
      "image"              : [
        "1611",
        0
      ],
      "segs"               : [
        "3014:88",
        0
      ],
      "model"              : [
        "3014:113",
        0
      ],
      "clip"               : [
        "2213",
        0
      ],
      "vae"                : [
        "2889",
        0
      ],
      "positive"           : [
        "3014:506",
        0
      ],
      "negative"           : [
        "3014:54",
        0
      ]
    },
    "class_type" : "DetailerForEach",
    "_meta"      : {
      "title" : "Detailer (BG Detailer)"
    }
  }
}
